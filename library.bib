
@article{schoffelen_204-subject_2019,
	title = {A 204-subject multimodal neuroimaging dataset to study language processing},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0020-y},
	doi = {10.1038/s41597-019-0020-y},
	abstract = {This dataset, colloquially known as the Mother Of Unification Studies (MOUS) dataset, contains multimodal neuroimaging data that has been acquired from 204 healthy human subjects. The neuroimaging protocol consisted of magnetic resonance imaging (MRI) to derive information at high spatial resolution about brain anatomy and structural connections, and functional data during task, and at rest. In addition, magnetoencephalography (MEG) was used to obtain high temporal resolution electrophysiological measurements during task, and at rest. All subjects performed a language task, during which they processed linguistic utterances that either consisted of normal or scrambled sentences. Half of the subjects were reading the stimuli, the other half listened to the stimuli. The resting state measurements consisted of 5 minutes eyes-open for the MEG and 7 minutes eyes-closed for fMRI. The neuroimaging data, as well as the information about the experimental events are shared according to the Brain Imaging Data Structure (BIDS) format. This unprecedented neuroimaging language data collection allows for the investigation of various aspects of the neurobiological correlates of language.},
	language = {en},
	number = {1},
	urldate = {2022-01-24},
	journal = {Scientific Data},
	author = {Schoffelen, Jan-Mathijs and Oostenveld, Robert and Lam, Nietzsche H. L. and Uddén, Julia and Hultén, Annika and Hagoort, Peter},
	month = apr,
	year = {2019},
	keywords = {Electrophysiology, Functional magnetic resonance imaging, Language, Psychology},
	pages = {17},
}

@article{kriegeskorte_cognitive_2018,
	title = {Cognitive computational neuroscience},
	volume = {21},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-018-0210-5},
	doi = {10.1038/s41593-018-0210-5},
	language = {en},
	number = {9},
	urldate = {2018-09-01},
	journal = {Nature Neuroscience},
	author = {Kriegeskorte, Nikolaus and Douglas, Pamela K.},
	month = sep,
	year = {2018},
	keywords = {explanation, computation, model-based, theory},
	pages = {1148--1160},
}

@article{naselaris_encoding_2011,
	series = {Multivariate {Decoding} and {Brain} {Reading}},
	title = {Encoding and decoding in {fMRI}},
	volume = {56},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910010657},
	doi = {10.1016/j.neuroimage.2010.07.073},
	abstract = {Over the past decade fMRI researchers have developed increasingly sensitive techniques for analyzing the information represented in BOLD activity. The most popular of these techniques is linear classification, a simple technique for decoding information about experimental stimuli or tasks from patterns of activity across an array of voxels. A more recent development is the voxel-based encoding model, which describes the information about the stimulus or task that is represented in the activity of single voxels. Encoding and decoding are complementary operations: encoding uses stimuli to predict activity while decoding uses activity to predict information about the stimuli. However, in practice these two operations are often confused, and their respective strengths and weaknesses have not been made clear. Here we use the concept of a linearizing feature space to clarify the relationship between encoding and decoding. We show that encoding and decoding operations can both be used to investigate some of the most common questions about how information is represented in the brain. However, focusing on encoding models offers two important advantages over decoding. First, an encoding model can in principle provide a complete functional description of a region of interest, while a decoding model can provide only a partial description. Second, while it is straightforward to derive an optimal decoding model from an encoding model it is much more difficult to derive an encoding model from a decoding model. We propose a systematic modeling approach that begins by estimating an encoding model for every voxel in a scan and ends by using the estimated encoding models to perform decoding.},
	number = {2},
	urldate = {2018-02-16},
	journal = {NeuroImage},
	author = {Naselaris, Thomas and Kay, Kendrick N. and Nishimoto, Shinji and Gallant, Jack L.},
	month = may,
	year = {2011},
	keywords = {fMRI, project.lstmMEG, computational neuroscience, decoding, encoding},
	pages = {400--410},
}

@article{holdgraf_encoding_2017,
	title = {Encoding and decoding models in cognitive electrophysiology},
	volume = {11},
	issn = {1662-5137},
	url = {http://journal.frontiersin.org/article/10.3389/fnsys.2017.00061/full},
	doi = {10.3389/fnsys.2017.00061},
	urldate = {2018-06-25},
	journal = {Frontiers in Systems Neuroscience},
	author = {Holdgraf, Christopher R. and Rieger, Jochem W. and Micheli, Cristiano and Martin, Stephanie and Knight, Robert T. and Theunissen, Frederic E.},
	month = sep,
	year = {2017},
	keywords = {MEG, EEG, project.lstmMEG, project.vsmMEG, decoding models, ecoding models},
}

@article{van_gerven_primer_2017,
	title = {A primer on encoding models in sensory neuroscience},
	volume = {76},
	issn = {00222496},
	doi = {10.1016/j.jmp.2016.06.009},
	language = {en},
	urldate = {2018-06-25},
	journal = {Journal of Mathematical Psychology},
	author = {van Gerven, Marcel A.J.},
	month = feb,
	year = {2017},
	keywords = {project.lstmMEG, project.vsmMEG, neural networks, ANN, encoding models, model-based},
	pages = {172--183},
}

@article{huth_natural_2016,
	title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	volume = {532},
	copyright = {2016 Nature Publishing Group},
	issn = {1476-4687},
	doi = {10.1038/nature17637},
	abstract = {{\textless}p{\textgreater}It has been proposed that language meaning is represented throughout the cerebral cortex in a distributed ‘semantic system’, but little is known about the details of this network; here, voxel-wise modelling of functional MRI data collected while subjects listened to natural stories is used to create a detailed atlas that maps representations of word meaning in the human brain.{\textless}/p{\textgreater}},
	language = {En},
	number = {7600},
	urldate = {2018-01-08},
	journal = {Nature},
	author = {Huth, Alexander G. and Heer, Wendy A. de and Griffiths, Thomas L. and Theunissen, Frédéric E. and Gallant, Jack L.},
	month = apr,
	year = {2016},
	keywords = {fMRI, project.lstmMEG, project.vsmMEG, computational neuroscience, semantics},
	pages = {453},
	file = {Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:/Volumes/GoogleDrive-100121059175283315603/My Drive/zotero/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:application/pdf},
}

@article{naselaris_cognitive_2018,
	title = {Cognitive computational neuroscience: {A} new conference for an emerging discipline},
	issn = {13646613},
	shorttitle = {Cognitive {Computational} {Neuroscience}},
	doi = {10.1016/j.tics.2018.02.008},
	language = {en},
	urldate = {2018-03-24},
	journal = {Trends in Cognitive Sciences},
	author = {Naselaris, Thomas and Bassett, Danielle S. and Fletcher, Alyson K. and Kording, Konrad and Kriegeskorte, Nikolaus and Nienborg, Hendrikje and Poldrack, Russell A. and Shohamy, Daphna and Kay, Kendrick},
	month = feb,
	year = {2018},
}

@article{sandve_ten_2013,
	title = {Ten simple rules for reproducible computational research},
	volume = {9},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	language = {en},
	number = {10},
	urldate = {2019-12-06},
	journal = {PLoS Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	editor = {Bourne, Philip E.},
	month = oct,
	year = {2013},
	pages = {e1003285},
}

@book{forstmann_introduction_2015,
	address = {New York, NY},
	title = {An {Introduction} to model-based cognitive neuroscience},
	isbn = {978-1-4939-2235-2 978-1-4939-2236-9},
	url = {http://link.springer.com/10.1007/978-1-4939-2236-9},
	language = {en},
	urldate = {2019-07-04},
	publisher = {Springer New York},
	editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
	year = {2015},
	doi = {10.1007/978-1-4939-2236-9},
	keywords = {computational cognitive neuroscience, model-based},
}

@article{poldrack_computational_2019,
	title = {Computational and informatic advances for reproducible data analysis in neuroimaging},
	volume = {2},
	url = {https://doi.org/10.1146/annurev-biodatasci-072018-021237},
	doi = {10.1146/annurev-biodatasci-072018-021237},
	abstract = {The reproducibility of scientific research has become a point of critical concern. We argue that openness and transparency are critical for reproducibility, and we outline an ecosystem for open and transparent science that has emerged within the human neuroimaging community. We discuss the range of open data-sharing resources that have been developed for neuroimaging data, as well as the role of data standards (particularly the brain imaging data structure) in enabling the automated sharing, processing, and reuse of large neuroimaging data sets. We outline how the open source Python language has provided the basis for a data science platform that enables reproducible data analysis and visualization. We also discuss how new advances in software engineering, such as containerization, provide the basis for greater reproducibility in data analysis. The emergence of this new ecosystem provides an example for many areas of science that are currently struggling with reproducibility.},
	number = {1},
	urldate = {2020-06-02},
	journal = {Annual Review of Biomedical Data Science},
	author = {Poldrack, Russell A. and Gorgolewski, Krzysztof J. and Varoquaux, Gaël},
	year = {2019},
	keywords = {data sharing, open science, reproducibility},
	pages = {119--138},
}

@article{poldrack_making_2014,
	title = {Making big data open: data sharing in neuroimaging},
	volume = {17},
	issn = {1097-6256, 1546-1726},
	shorttitle = {Making big data open},
	url = {http://www.nature.com/articles/nn.3818},
	doi = {10.1038/nn.3818},
	language = {en},
	number = {11},
	urldate = {2020-05-23},
	journal = {Nature Neuroscience},
	author = {Poldrack, Russell A and Gorgolewski, Krzysztof J},
	month = nov,
	year = {2014},
	keywords = {open science, data sharing},
	pages = {1510--1517},
}

@article{gorgolewski_brain_2016,
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201644},
	doi = {10.1038/sdata.2016.44},
	abstract = {The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.},
	language = {en},
	number = {1},
	urldate = {2020-05-01},
	journal = {Scientific Data},
	author = {Gorgolewski, Krzysztof J. and Auer, Tibor and Calhoun, Vince D. and Craddock, R. Cameron and Das, Samir and Duff, Eugene P. and Flandin, Guillaume and Ghosh, Satrajit S. and Glatard, Tristan and Halchenko, Yaroslav O. and Handwerker, Daniel A. and Hanke, Michael and Keator, David and Li, Xiangrui and Michael, Zachary and Maumet, Camille and Nichols, B. Nolan and Nichols, Thomas E. and Pellman, John and Poline, Jean-Baptiste and Rokem, Ariel and Schaefer, Gunnar and Sochat, Vanessa and Triplett, William and Turner, Jessica A. and Varoquaux, Gaël and Poldrack, Russell A.},
	month = jun,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {open science, open data},
	pages = {1--9},
}

@article{armeni_10-hour_2022,
	title = {A 10-hour within-participant magnetoencephalography narrative dataset to test models of language comprehension},
	volume = {9},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01382-7},
	doi = {10.1038/s41597-022-01382-7},
	abstract = {Abstract
            Recently, cognitive neuroscientists have increasingly studied the brain responses to narratives. At the same time, we are witnessing exciting developments in natural language processing where large-scale neural network models can be used to instantiate cognitive hypotheses in narrative processing. Yet, they learn from text alone and we lack ways of incorporating biological constraints during training. To mitigate this gap, we provide a narrative comprehension magnetoencephalography (MEG) data resource that can be used to train neural network models directly on brain data. We recorded from 3 participants, 10 separate recording hour-long sessions each, while they listened to audiobooks in English. After story listening, participants answered short questions about their experience. To minimize head movement, the participants wore MEG-compatible head casts, which immobilized their head position during recording. We report a basic evoked-response analysis showing that the responses accurately localize to primary auditory areas. The responses are robust and conserved across 10 sessions for every participant. We also provide usage notes and briefly outline possible future uses of the resource.},
	language = {en},
	number = {1},
	urldate = {2022-10-25},
	journal = {Scientific Data},
	author = {Armeni, Kristijan and Güçlü, Umut and van Gerven, Marcel and Schoffelen, Jan-Mathijs},
	month = dec,
	year = {2022},
	pages = {278},
}

@article{dupre_beyond_2022,
	title = {Beyond advertising: {New} infrastructures for publishing integrated research objects},
	volume = {18},
	issn = {1553-7358},
	shorttitle = {Beyond advertising},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009651},
	doi = {10.1371/journal.pcbi.1009651},
	language = {en},
	number = {1},
	urldate = {2023-10-24},
	journal = {PLOS Computational Biology},
	author = {DuPre, Elizabeth and Holdgraf, Chris and Karakuzu, Agah and Tetrel, Loïc and Bellec, Pierre and Stikov, Nikola and Poline, Jean-Baptiste},
	month = jan,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {open science, reproducibility, python, open data, Jupyter notebook, Rmarkdown},
	pages = {e1009651},
}

@article{peng_reproducible_2011,
	title = {Reproducible research in computational science},
	volume = {334},
	url = {https://www.science.org/doi/10.1126/science.1213847},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	number = {6060},
	urldate = {2024-09-10},
	journal = {Science},
	author = {Peng, Roger D.},
	month = dec,
	year = {2011},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1226--1227},
}

@article{lebel_natural_2023,
	title = {A natural language {fMRI} dataset for voxelwise encoding models},
	volume = {10},
	copyright = {2023 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-023-02437-z},
	doi = {10.1038/s41597-023-02437-z},
	abstract = {Speech comprehension is a complex process that draws on humans’ abilities to extract lexical information, parse syntax, and form semantic understanding. These sub-processes have traditionally been studied using separate neuroimaging experiments that attempt to isolate specific effects of interest. More recently it has become possible to study all stages of language comprehension in a single neuroimaging experiment using narrative natural language stimuli. The resulting data are richly varied at every level, enabling analyses that can probe everything from spectral representations to high-level representations of semantic meaning. We provide a dataset containing BOLD fMRI responses recorded while 8 participants each listened to 27 complete, natural, narrative stories ({\textasciitilde}6 hours). This dataset includes pre-processed and raw MRIs, as well as hand-constructed 3D cortical surfaces for each participant. To address the challenges of analyzing naturalistic data, this dataset is accompanied by a python library containing basic code for creating voxelwise encoding models. Altogether, this dataset provides a large and novel resource for understanding speech and language processing in the human brain.},
	language = {en},
	number = {1},
	urldate = {2024-09-13},
	journal = {Scientific Data},
	author = {LeBel, Amanda and Wagner, Lauren and Jain, Shailee and Adhikari-Desai, Aneesh and Gupta, Bhavin and Morgenthal, Allyson and Tang, Jerry and Xu, Lixiang and Huth, Alexander G.},
	month = aug,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, fMRI, encoding models, Cortex, Neural encoding},
	pages = {555},
}

@misc{lebel_fmri_2023,
	title = {An {fMRI} dataset during a passive natural language listening task},
	url = {https://openneuro.org/datasets/ds003020/versions/2.0.0},
	doi = {10.18112/OPENNEURO.DS003020.V2.0.0},
	urldate = {2024-09-13},
	publisher = {Openneuro},
	author = {LeBel, Amanda and Wagner, Lauren and Jain, Shailee and Adhikari-Desai, Aneesh and {Bhavin Gupta} and Morgenthal, Allyson and Tang, Jerry and {Lixiang Xu} and Huth, Alexander G.},
	year = {2023},
}

@misc{peng_real_2016,
	title = {The real reason reproducible research is important},
	shorttitle = {Simply {Statistics}},
	url = {https://simplystatistics.org/posts/2014-06-06-the-real-reason-reproducible-research-is-important/},
	urldate = {2025-02-14},
	journal = {Simply Statistics},
	author = {Peng, Roger},
	month = jun,
	year = {2016},
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxq028},
	doi = {10.1093/biostatistics/kxq028},
	number = {3},
	urldate = {2025-02-14},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	month = jul,
	year = {2010},
	pages = {385--388},
}

@article{doerig_neuroconnectionist_2023,
	title = {The neuroconnectionist research programme},
	volume = {24},
	issn = {1471-003X, 1471-0048},
	url = {https://www.nature.com/articles/s41583-023-00705-w},
	doi = {10.1038/s41583-023-00705-w},
	language = {en},
	number = {7},
	urldate = {2025-02-17},
	journal = {Nature Reviews Neuroscience},
	author = {Doerig, Adrien and Sommers, Rowan P. and Seeliger, Katja and Richards, Blake and Ismael, Jenann and Lindsay, Grace W. and Kording, Konrad P. and Konkle, Talia and Van Gerven, Marcel A. J. and Kriegeskorte, Nikolaus and Kietzmann, Tim C.},
	month = jul,
	year = {2023},
	pages = {431--450},
}

@article{silva_speech_2024,
	title = {The speech neuroprosthesis},
	volume = {25},
	copyright = {2024 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-024-00819-9},
	doi = {10.1038/s41583-024-00819-9},
	abstract = {Loss of speech after paralysis is devastating, but circumventing motor-pathway injury by directly decoding speech from intact cortical activity has the potential to restore natural communication and self-expression. Recent discoveries have defined how key features of speech production are facilitated by the coordinated activity of vocal-tract articulatory and motor-planning cortical representations. In this Review, we highlight such progress and how it has led to successful speech decoding, first in individuals implanted with intracranial electrodes for clinical epilepsy monitoring and subsequently in individuals with paralysis as part of early feasibility clinical trials to restore speech. We discuss high-spatiotemporal-resolution neural interfaces and the adaptation of state-of-the-art speech computational algorithms that have driven rapid and substantial progress in decoding neural activity into text, audible speech, and facial movements. Although restoring natural speech is a long-term goal, speech neuroprostheses already have performance levels that surpass communication rates offered by current assistive-communication technology. Given this accelerated rate of progress in the field, we propose key evaluation metrics for speed and accuracy, among others, to help standardize across studies. We finish by highlighting several directions to more fully explore the multidimensional feature space of speech and language, which will continue to accelerate progress towards a clinically viable speech neuroprosthesis.},
	language = {en},
	number = {7},
	urldate = {2025-02-17},
	journal = {Nature Reviews Neuroscience},
	author = {Silva, Alexander B. and Littlejohn, Kaylo T. and Liu, Jessie R. and Moses, David A. and Chang, Edward F.},
	month = jul,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cognitive neuroscience, Neuroscience},
	pages = {473--492},
}

@article{botvinik-nezer_variability_2020,
	title = {Variability in the analysis of a single neuroimaging dataset by many teams},
	volume = {582},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2314-9},
	doi = {10.1038/s41586-020-2314-9},
	abstract = {Data analysis workflows in many scientific domains have become increasingly complex and flexible. Here we assess the effect of this flexibility on the results of functional magnetic resonance imaging by asking 70 independent teams to analyse the same dataset, testing the same 9 ex-ante hypotheses1. The flexibility of analytical approaches is exemplified by the fact that no two teams chose identical workflows to analyse the data. This flexibility resulted in sizeable variation in the results of hypothesis tests, even for teams whose statistical maps were highly correlated at intermediate stages of the analysis pipeline. Variation in reported results was related to several aspects of analysis methodology. Notably, a meta-analytical approach that aggregated information across teams yielded a significant consensus in activated regions. Furthermore, prediction markets of researchers in the field revealed an overestimation of the likelihood of significant findings, even by researchers with direct knowledge of the dataset2–5. Our findings show that analytical flexibility can have substantial effects on scientific conclusions, and identify factors that may be related to variability in the analysis of functional magnetic resonance imaging. The results emphasize the importance of validating and sharing complex analysis workflows, and demonstrate the need for performing and reporting multiple analyses of the same data. Potential approaches that could be used to mitigate issues related to analytical variability are discussed.},
	language = {en},
	number = {7810},
	urldate = {2025-02-17},
	journal = {Nature},
	author = {Botvinik-Nezer, Rotem and Holzmeister, Felix and Camerer, Colin F. and Dreber, Anna and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Iwanir, Roni and Mumford, Jeanette A. and Adcock, R. Alison and Avesani, Paolo and Baczkowski, Blazej M. and Bajracharya, Aahana and Bakst, Leah and Ball, Sheryl and Barilari, Marco and Bault, Nadège and Beaton, Derek and Beitner, Julia and Benoit, Roland G. and Berkers, Ruud M. W. J. and Bhanji, Jamil P. and Biswal, Bharat B. and Bobadilla-Suarez, Sebastian and Bortolini, Tiago and Bottenhorn, Katherine L. and Bowring, Alexander and Braem, Senne and Brooks, Hayley R. and Brudner, Emily G. and Calderon, Cristian B. and Camilleri, Julia A. and Castrellon, Jaime J. and Cecchetti, Luca and Cieslik, Edna C. and Cole, Zachary J. and Collignon, Olivier and Cox, Robert W. and Cunningham, William A. and Czoschke, Stefan and Dadi, Kamalaker and Davis, Charles P. and Luca, Alberto De and Delgado, Mauricio R. and Demetriou, Lysia and Dennison, Jeffrey B. and Di, Xin and Dickie, Erin W. and Dobryakova, Ekaterina and Donnat, Claire L. and Dukart, Juergen and Duncan, Niall W. and Durnez, Joke and Eed, Amr and Eickhoff, Simon B. and Erhart, Andrew and Fontanesi, Laura and Fricke, G. Matthew and Fu, Shiguang and Galván, Adriana and Gau, Remi and Genon, Sarah and Glatard, Tristan and Glerean, Enrico and Goeman, Jelle J. and Golowin, Sergej A. E. and González-García, Carlos and Gorgolewski, Krzysztof J. and Grady, Cheryl L. and Green, Mikella A. and Guassi Moreira, João F. and Guest, Olivia and Hakimi, Shabnam and Hamilton, J. Paul and Hancock, Roeland and Handjaras, Giacomo and Harry, Bronson B. and Hawco, Colin and Herholz, Peer and Herman, Gabrielle and Heunis, Stephan and Hoffstaedter, Felix and Hogeveen, Jeremy and Holmes, Susan and Hu, Chuan-Peng and Huettel, Scott A. and Hughes, Matthew E. and Iacovella, Vittorio and Iordan, Alexandru D. and Isager, Peder M. and Isik, Ayse I. and Jahn, Andrew and Johnson, Matthew R. and Johnstone, Tom and Joseph, Michael J. E. and Juliano, Anthony C. and Kable, Joseph W. and Kassinopoulos, Michalis and Koba, Cemal and Kong, Xiang-Zhen and Koscik, Timothy R. and Kucukboyaci, Nuri Erkut and Kuhl, Brice A. and Kupek, Sebastian and Laird, Angela R. and Lamm, Claus and Langner, Robert and Lauharatanahirun, Nina and Lee, Hongmi and Lee, Sangil and Leemans, Alexander and Leo, Andrea and Lesage, Elise and Li, Flora and Li, Monica Y. C. and Lim, Phui Cheng and Lintz, Evan N. and Liphardt, Schuyler W. and Losecaat Vermeer, Annabel B. and Love, Bradley C. and Mack, Michael L. and Malpica, Norberto and Marins, Theo and Maumet, Camille and McDonald, Kelsey and McGuire, Joseph T. and Melero, Helena and Méndez Leal, Adriana S. and Meyer, Benjamin and Meyer, Kristin N. and Mihai, Glad and Mitsis, Georgios D. and Moll, Jorge and Nielson, Dylan M. and Nilsonne, Gustav and Notter, Michael P. and Olivetti, Emanuele and Onicas, Adrian I. and Papale, Paolo and Patil, Kaustubh R. and Peelle, Jonathan E. and Pérez, Alexandre and Pischedda, Doris and Poline, Jean-Baptiste and Prystauka, Yanina and Ray, Shruti and Reuter-Lorenz, Patricia A. and Reynolds, Richard C. and Ricciardi, Emiliano and Rieck, Jenny R. and Rodriguez-Thompson, Anais M. and Romyn, Anthony and Salo, Taylor and Samanez-Larkin, Gregory R. and Sanz-Morales, Emilio and Schlichting, Margaret L. and Schultz, Douglas H. and Shen, Qiang and Sheridan, Margaret A. and Silvers, Jennifer A. and Skagerlund, Kenny and Smith, Alec and Smith, David V. and Sokol-Hessner, Peter and Steinkamp, Simon R. and Tashjian, Sarah M. and Thirion, Bertrand and Thorp, John N. and Tinghög, Gustav and Tisdall, Loreen and Tompson, Steven H. and Toro-Serey, Claudio and Torre Tresols, Juan Jesus and Tozzi, Leonardo and Truong, Vuong and Turella, Luca and van ‘t Veer, Anna E. and Verguts, Tom and Vettel, Jean M. and Vijayarajah, Sagana and Vo, Khoi and Wall, Matthew B. and Weeda, Wouter D. and Weis, Susanne and White, David J. and Wisniewski, David and Xifra-Porxas, Alba and Yearling, Emily A. and Yoon, Sangsuk and Yuan, Rui and Yuen, Kenneth S. L. and Zhang, Lei and Zhang, Xu and Zosky, Joshua E. and Nichols, Thomas E. and Poldrack, Russell A. and Schonberg, Tom},
	month = jun,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Human behaviour, Decision, Decision making, Scientific community},
	pages = {84--88},
}

@article{ivie_reproducibility_2019,
	title = {Reproducibility in scientific computing},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3186266},
	doi = {10.1145/3186266},
	abstract = {Reproducibility is widely considered to be an essential requirement of the scientific process. However, a number of serious concerns have been raised recently, questioning whether today’s computational work is adequately reproducible. In principle, it should be possible to specify a computation to sufficient detail that anyone should be able to reproduce it exactly. But in practice, there are fundamental, technical, and social barriers to doing so. The many objectives and meanings of reproducibility are discussed within the context of scientific computing. Technical barriers to reproducibility are described, extant approaches surveyed, and open areas of research are identified.},
	language = {en},
	number = {3},
	urldate = {2025-02-18},
	journal = {ACM Computing Surveys},
	author = {Ivie, Peter and Thain, Douglas},
	month = may,
	year = {2019},
	pages = {1--36},
}

@article{peng_reproducible_2009,
	title = {Reproducible research and biostatistics},
	volume = {10},
	issn = {1468-4357, 1465-4644},
	url = {https://academic.oup.com/biostatistics/article/10/3/405/293660},
	doi = {10.1093/biostatistics/kxp014},
	language = {en},
	number = {3},
	urldate = {2025-02-18},
	journal = {Biostatistics},
	author = {Peng, Roger D.},
	month = jul,
	year = {2009},
	pages = {405--408},
}

@inproceedings{claerbout_electronic_1992,
	title = {Electronic documents give reproducible research a new meaning},
	url = {http://library.seg.org/doi/abs/10.1190/1.1822162},
	doi = {10.1190/1.1822162},
	language = {en},
	urldate = {2025-02-19},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, Jon F. and Karrenbach, Martin},
	month = jan,
	year = {1992},
	pages = {601--604},
}

@misc{barba_terminologies_2018,
	title = {Terminologies for reproducible research},
	url = {http://arxiv.org/abs/1802.03311},
	doi = {10.48550/arXiv.1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Barba, Lorena A.},
	month = feb,
	year = {2018},
	note = {arXiv:1802.03311 [cs]},
	keywords = {Computer Science - Digital Libraries},
}

@misc{us_research_software_engineer_association_research_2023,
	title = {Research software engineers: {Creating} a career path—and a career},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Research {Software} {Engineers}},
	url = {https://zenodo.org/doi/10.5281/zenodo.10073232},
	doi = {10.5281/ZENODO.10073232},
	language = {en},
	urldate = {2025-02-19},
	publisher = {Zenodo},
	author = {{US Research Software Engineer Association} and {IEEE Computer Society}},
	month = nov,
	year = {2023},
}

@misc{noauthor_four_nodate,
	title = {Four simple recommendations to encourage best practices in research software - {PMC}},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC5490478/#sec3},
	urldate = {2025-02-20},
}

@article{balaban_ten_2021,
	title = {Ten simple rules for quick and dirty scientific programming},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008549},
	doi = {10.1371/journal.pcbi.1008549},
	language = {en},
	number = {3},
	urldate = {2025-02-20},
	journal = {PLOS Computational Biology},
	author = {Balaban, Gabriel and Grytten, Ivar and Rand, Knut Dagestad and Scheffer, Lonneke and Sandve, Geir Kjetil},
	month = mar,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Computer and information sciences, Computer applications, Computer software, Optimization, Programming languages, Prototypes, Software development, Software engineering},
	pages = {e1008549},
}

@article{xiong_state_2023,
	title = {The state of play of reproducibility in statistics: {An} empirical analysis},
	volume = {77},
	issn = {0003-1305, 1537-2731},
	shorttitle = {The {State} of {Play} of {Reproducibility} in {Statistics}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2022.2131625},
	doi = {10.1080/00031305.2022.2131625},
	abstract = {Abstract Reproducibility, the ability to reproduce the results of published papers or studies using their computer code and data, is a cornerstone of reliable scientific methodology. Studies where results cannot be reproduced by the scientific community should be treated with caution. Over the past decade, the importance of reproducible research has been frequently stressed in a wide range of scientific journals such as Nature and Science and international magazines such as The Economist. However, multiple studies have demonstrated that scientific results are often not reproducible across research areas such as psychology and medicine. Statistics, the science concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data, prides itself on its openness when it comes to sharing both computer code and data. In this article, we examine reproducibility in the field of statistics by attempting to reproduce the results in 93 published papers in prominent journals using functional magnetic resonance imaging (fMRI) data during the 2010–2021 period. Overall, from both the computer code and the data perspective, among all the 93 examined papers, we could only reproduce the results in 14 (15.1\%) papers, that is, the papers provide both executable computer code (or software) with the real fMRI data, and our results matched the results in the paper. Finally, we conclude with some author-specific and journal-specific recommendations to improve the research reproducibility in statistics.},
	language = {en},
	number = {2},
	urldate = {2025-02-23},
	journal = {The American Statistician},
	author = {Xiong, Xin and Cribben, Ivor},
	month = apr,
	year = {2023},
	pages = {115--126},
}

@article{pineau_improving_2021,
	title = {Improving reproducibility in machine learning research},
	volume = {22},
	url = {http://jmlr.org/papers/v22/20-303.html},
	number = {164},
	journal = {Journal of Machine Learning Research},
	author = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Lariviere, Vincent and Beygelzimer, Alina and d'Alche-Buc, Florence and Fox, Emily and Larochelle, Hugo},
	year = {2021},
	pages = {1--20},
}

@book{martin_clean_2012,
	address = {Upper Saddle River, NJ Munich},
	edition = {Repr.},
	series = {Robert {C}. {Martin} series},
	title = {Clean code: a handbook of agile software craftsmanship},
	isbn = {978-0-13-235088-4},
	shorttitle = {Clean code},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Martin, Robert C.},
	year = {2012},
}

@book{thomas_pragmatic_2020,
	address = {Boston},
	edition = {Second edition, 20th anniversary edtion},
	title = {The pragmatic programmer: your journey to mastery},
	isbn = {978-0-13-595705-9},
	shorttitle = {The pragmatic programmer},
	abstract = {"The Pragmatic Programmer is one of those rare tech books you'll read, re-read, and read again over the years. Whether you're new to the field or an experienced practitioner, you'll come away with fresh insights each and every time. Dave Thomas and Andy Hunt wrote the first edition of this influential book in 1999 to help their clients create better software and rediscover the joy of coding. These lessons have helped a generation of programmers examine the very essence of software development, independent of any particular language, framework, or methodology, and the Pragmatic philosophy has spawned hundreds of books, screencasts, and audio books, as well as thousands of careers and success stories. Now, twenty years later, this new edition re-examines what it means to be a modern programmer. Topics range from personal responsibility and career development to architectural techniques for keeping your code flexible and easy to adapt and reuse. Read this book, and you'll learn how to: Fight software rot; Learn continuously; Avoid the trap of duplicating knowledge; Write flexible, dynamic, and adaptable code; Harness the power of basic tools; Avoid programming by coincidence; Learn real requirements; Solve the underlying problems of concurrent code; Guard against security vulnerabilities; Build teams of Pragmatic Programmers; Take responsibility for your work and career; Test ruthlessly and effectively, including property-based testing; Implement the Pragmatic Starter Kit; Delight your users. Written as a series of self-contained sections and filled with classic and fresh anecdotes, thoughtful examples, and interesting analogies, The Pragmatic Programmer illustrates the best approaches and major pitfalls of many different aspects of software development. Whether you're a new coder, an experienced programmer, or a manager responsible for software projects, use these lessons daily, and you'll quickly see improvements in personal productivity, accuracy, and job satisfaction. You'll learn skills and develop habits and attitudes that form the foundation for long-term success in your career."--Publisher's description},
	language = {eng},
	publisher = {Addison-Wesley},
	author = {Thomas, David and Hunt, Andrew},
	year = {2020},
}

@techreport{brett_research_2017,
	title = {Research {Software} {Engineers}: {State} of the nation report 2017},
	shorttitle = {Research {Software} {Engineers}},
	url = {https://zenodo.org/records/495360},
	abstract = {Most research would be impossible without software, and this reliance is forcing a rethink of the skills needed in a traditional research group. With the emergence of software as the pre-eminent research tool used across all disciplines, comes the realisation that a significant majority of results are based, ultimately, on the skill of the experts who design and build that software. 


The UK has led the world in supporting a new role in academia: the Research Software Engineer (RSE). This report describes the new expert community that has flourished in UK research, details the successes that have been achieved, and the barriers that prevent further progress.},
	urldate = {2025-02-24},
	institution = {Zenodo},
	author = {Brett, Alys and Croucher, Michael and Haines, Robert and Hettrick, Simon and Hetherington, James and Stillwell, Mark and Wyatt, Claire},
	month = apr,
	year = {2017},
	doi = {10.5281/zenodo.495360},
	keywords = {Careers, New roles in research, Research communities, Research Software Engineer, RSE, Software},
}

@article{carver_survey_2022,
	title = {A survey of the state of the practice for research software in the {United} {States}},
	volume = {8},
	issn = {2376-5992},
	url = {https://peerj.com/articles/cs-963},
	doi = {10.7717/peerj-cs.963},
	abstract = {Research software is a critical component of contemporary scholarship. Yet, most research software is developed and managed in ways that are at odds with its long-term sustainability. This paper presents findings from a survey of 1,149 researchers, primarily from the United States, about sustainability challenges they face in developing and using research software. Some of our key findings include a repeated need for more opportunities and time for developers of research software to receive training. These training needs cross the software lifecycle and various types of tools. We also identified the recurring need for better models of funding research software and for providing credit to those who develop the software so they can advance in their careers. The results of this survey will help inform future infrastructure and service support for software developers and users, as well as national research policy aimed at increasing the sustainability of research software.},
	language = {en},
	urldate = {2025-02-24},
	journal = {PeerJ Computer Science},
	author = {Carver, Jeffrey C. and Weber, Nic and Ram, Karthik and Gesing, Sandra and Katz, Daniel S.},
	month = may,
	year = {2022},
	note = {Publisher: PeerJ Inc.},
	pages = {e963},
}

@misc{community_illustrations_2021,
	title = {Illustrations from the {Turing} {Way} book dashes},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/4906004},
	abstract = {Illustrations created by Scriberia as part of the {\textless}em{\textgreater}Turing Way{\textless}/em{\textgreater} book dashes in 2019 (two events in person), 2020 (one event in-person and one online) and 2021 (one online). They depict a variety of content of the five guides in The Turing Way as well as the community activities of {\textless}em{\textgreater}The Turing Way{\textless}/em{\textgreater} in general. More information on the book dashes can be found at https://the-turing-way.netlify.app/community-handbook/bookdash.html. When using any of the images, please include the following attribution with the specific DOI as listed on the particular Zenodo page: This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence. You can cite all versions by using the DOI 10.5281/zenodo.3332807. This DOI represents all versions, and will always resolve to the latest one. Individual illustrations are provided as {\textless}strong{\textgreater}.jpg{\textless}/strong{\textgreater} files and zipped archives of the files are given in {\textless}strong{\textgreater}.pdf{\textless}/strong{\textgreater}, {\textless}strong{\textgreater}.png{\textless}/strong{\textgreater} and {\textless}strong{\textgreater}.svg{\textless}/strong{\textgreater} format when available (named starting with {\textless}strong{\textgreater}zz- {\textless}/strong{\textgreater}to keep them at the bottom of the list). zz-Latest-TheTuringWay-Scriberia-2021-JPG-English-text.zip zz-Latest-TheTuringWay-Scriberia-2021-JPG-{\textless}strong{\textgreater}without-text.zip{\textless}/strong{\textgreater} zz-Latest-TheTuringWay-Scriberia-2021-PDF-English-text.zip zz-Latest-TheTuringWay-Scriberia-2021-PDF-{\textless}strong{\textgreater}without-text.zip{\textless}/strong{\textgreater} zz-TheTuringWay-Scriberia-2019-20-AllJPG.zip zz-TheTuringWay-Scriberia-2019-20-AllPDF.zip zz-TheTuringWay-Scriberia-2019-20-SVG-where-available.zip {\textless}strong{\textgreater}Translating and editing Images: {\textless}/strong{\textgreater}Zipped archives ending with '{\textless}strong{\textgreater}-without-text.zip{\textless}/strong{\textgreater}' are provided for the latest release that can be translated into languages that you would like to use them in. We encourage the use and re-use of these images as much as possible. This includes remixing the images, for example changing the colours, translating text or merging them together with additional (openly licensed) images. If you create something that others may benefit from, we encourage you to contribute your image back to {\textless}em{\textgreater}The Turing Way. {\textless}/em{\textgreater}Please get in touch with the team members by emailing theturingway@gmail.com who can help you update this repository with the images you create. If you'd like to change the colours of the image to align with other elements of your presentation, {\textless}em{\textgreater}Turing Way{\textless}/em{\textgreater} community member Alex Chan has written a guide for changing the dominant colour in an image which we hope is helpful.},
	urldate = {2025-02-24},
	author = {Community, The Turing Way and {Scriberia}},
	month = may,
	year = {2021},
	doi = {10.5281/ZENODO.4906004},
	note = {Publisher: Zenodo},
}

@book{committee_on_reproducibility_and_replicability_in_science_reproducibility_2019,
	address = {Washington, D.C.},
	title = {Reproducibility and replicability in science},
	isbn = {978-0-309-48616-3},
	url = {https://www.nap.edu/catalog/25303},
	urldate = {2025-02-24},
	publisher = {National Academies Press},
	collaborator = {{Committee on Reproducibility and Replicability in Science} and {Board on Behavioral, Cognitive, and Sensory Sciences} and {Committee on National Statistics} and {Division of Behavioral and Social Sciences and Education} and {Nuclear and Radiation Studies Board} and {Division on Earth and Life Studies} and {Board on Mathematical Sciences and Analytics} and {Committee on Applied and Theoretical Statistics} and {Division on Engineering and Physical Sciences} and {Board on Research Data and Information} and {Committee on Science, Engineering, Medicine, and Public Policy} and {Policy and Global Affairs} and {National Academies of Sciences, Engineering, and Medicine}},
	month = sep,
	year = {2019},
	doi = {10.17226/25303},
	keywords = {Policy for Science and Technology, Policy for Science and Technology--Research and Data, Surveys and Statistics},
}

@article{open_science_collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	copyright = {http://www.sciencemag.org/about/science-licenses-journal-article-reuse},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aac4716},
	doi = {10.1126/science.aac4716},
	abstract = {Empirically analyzing empirical evidence
            
              One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts
              et al.
              describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.
            
            
              Science
              , this issue
              10.1126/science.aac4716
            
          , 
            A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.
          , 
            
              INTRODUCTION
              Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.
            
            
              RATIONALE
              There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.
            
            
              RESULTS
              
                We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and
                P
                values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (
                M
                r
                = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (
                M
                r
                = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (
                P
                {\textless} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
              
            
            
              CONCLUSION
              
                No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original
                P
                value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.
              
              Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.
              
                
                  Original study effect size versus replication effect size (correlation coefficients).
                  Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.
                
                
              
            
          , 
            Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	language = {en},
	number = {6251},
	urldate = {2025-02-26},
	journal = {Science},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pages = {aac4716},
}

@misc{beck_manifesto_2001,
	title = {Manifesto for agile software development},
	url = {http://www.agilemanifesto.org/},
	urldate = {2025-02-25},
	author = {Beck, Kent and Beedle, Mike and van Bennekum, Arie and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andrew and Jeffries, Ron and Kern, Jon and Marick, Brian and Martin, Robert C. and Mellor, Steve and Schwaber, Ken and Sutherland, Jeff and Thomas, Dave},
	year = {2001},
	keywords = {imported},
}

@misc{community_turing_2022,
	title = {The {Turing} {Way}: {A} handbook for reproducible, ethical and collaborative research},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/record/3233853},
	abstract = {The Turing Way: A handbook for reproducible, ethical and collaborative research The Turing Way December 2022 Latest The Turing Way is an open source community-driven guide to reproducible, ethical, inclusive and collaborative data science. The Turing Way book is collaboratively developed by its diverse community of researchers, learners, educators, and other stakeholders. The Turing Way project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. In 2020, the project underwent a major overhaul categorising chapters into 5 guides on reproducible research, project design, collaboration, communication and ethical research. Additionally, we added a community handbook to document all the practices designed and implemented towards the development of the project and community. This release in 2021 includes additional chapters developed by our contributors across five guides and the community handbook. In addition, all the project documents from the project are provided as they appear on The Turing Way GitHub repository including the Zenodo metadata: https://github.com/alan-turing-institute/the-turing-way. Release log v1.1.0: Zenodo metadata information and additional chapters from Book Dash Dec 2022 v1.0.3: Zenodo metadata information and additional chapters from Book Dash May 2022 v1.0.2: Zenodo metadata information and additional chapters since Book Dash November 2021 v1.0.1: Zenodo metadata information and additional chapters. v1.0.0: Five guide expansion of The Turing Way with a community handbook v0.0.4: Continuous integration chapter merged to main. v0.0.3: Reproducible environments chapter merged to main. v0.0.2: Version control chapter merged to main. v0.0.1: Reproducibility chapter merged to main. Full Changelog: https://github.com/alan-turing-institute/the-turing-way/compare/v1.0.1...v1.0.3 (Previous release: https://github.com/alan-turing-institute/the-turing-way/compare/v0.0.3...v1.0.1) v1.1.0},
	urldate = {2025-02-26},
	publisher = {Zenodo},
	author = {Community, The Turing Way},
	month = jul,
	year = {2022},
	doi = {10.5281/ZENODO.3233853},
	keywords = {collaboration, community, data science, ethics, handbook, reproducibility, research practices},
}
