
@inproceedings{brown_language_2020,
	title = {Language models are few-shot learners},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
	year = {2020},
	pages = {1877--1901},
}

@article{schoffelen_204-subject_2019,
	title = {A 204-subject multimodal neuroimaging dataset to study language processing},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0020-y},
	doi = {10.1038/s41597-019-0020-y},
	abstract = {This dataset, colloquially known as the Mother Of Unification Studies (MOUS) dataset, contains multimodal neuroimaging data that has been acquired from 204 healthy human subjects. The neuroimaging protocol consisted of magnetic resonance imaging (MRI) to derive information at high spatial resolution about brain anatomy and structural connections, and functional data during task, and at rest. In addition, magnetoencephalography (MEG) was used to obtain high temporal resolution electrophysiological measurements during task, and at rest. All subjects performed a language task, during which they processed linguistic utterances that either consisted of normal or scrambled sentences. Half of the subjects were reading the stimuli, the other half listened to the stimuli. The resting state measurements consisted of 5 minutes eyes-open for the MEG and 7 minutes eyes-closed for fMRI. The neuroimaging data, as well as the information about the experimental events are shared according to the Brain Imaging Data Structure (BIDS) format. This unprecedented neuroimaging language data collection allows for the investigation of various aspects of the neurobiological correlates of language.},
	language = {en},
	number = {1},
	urldate = {2022-01-24},
	journal = {Scientific Data},
	author = {Schoffelen, Jan-Mathijs and Oostenveld, Robert and Lam, Nietzsche H. L. and Uddén, Julia and Hultén, Annika and Hagoort, Peter},
	month = apr,
	year = {2019},
	keywords = {Language, Electrophysiology, Functional magnetic resonance imaging, Psychology},
	pages = {17},
}

@article{kriegeskorte_cognitive_2018,
	title = {Cognitive computational neuroscience},
	volume = {21},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-018-0210-5},
	doi = {10.1038/s41593-018-0210-5},
	language = {en},
	number = {9},
	urldate = {2018-09-01},
	journal = {Nature Neuroscience},
	author = {Kriegeskorte, Nikolaus and Douglas, Pamela K.},
	month = sep,
	year = {2018},
	keywords = {explanation, computation, model-based, theory},
	pages = {1148--1160},
}

@article{naselaris_encoding_2011,
	series = {Multivariate {Decoding} and {Brain} {Reading}},
	title = {Encoding and decoding in {fMRI}},
	volume = {56},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910010657},
	doi = {10.1016/j.neuroimage.2010.07.073},
	abstract = {Over the past decade fMRI researchers have developed increasingly sensitive techniques for analyzing the information represented in BOLD activity. The most popular of these techniques is linear classification, a simple technique for decoding information about experimental stimuli or tasks from patterns of activity across an array of voxels. A more recent development is the voxel-based encoding model, which describes the information about the stimulus or task that is represented in the activity of single voxels. Encoding and decoding are complementary operations: encoding uses stimuli to predict activity while decoding uses activity to predict information about the stimuli. However, in practice these two operations are often confused, and their respective strengths and weaknesses have not been made clear. Here we use the concept of a linearizing feature space to clarify the relationship between encoding and decoding. We show that encoding and decoding operations can both be used to investigate some of the most common questions about how information is represented in the brain. However, focusing on encoding models offers two important advantages over decoding. First, an encoding model can in principle provide a complete functional description of a region of interest, while a decoding model can provide only a partial description. Second, while it is straightforward to derive an optimal decoding model from an encoding model it is much more difficult to derive an encoding model from a decoding model. We propose a systematic modeling approach that begins by estimating an encoding model for every voxel in a scan and ends by using the estimated encoding models to perform decoding.},
	number = {2},
	urldate = {2018-02-16},
	journal = {NeuroImage},
	author = {Naselaris, Thomas and Kay, Kendrick N. and Nishimoto, Shinji and Gallant, Jack L.},
	month = may,
	year = {2011},
	keywords = {fMRI, project.lstmMEG, computational neuroscience, decoding, encoding},
	pages = {400--410},
}

@article{holdgraf_encoding_2017,
	title = {Encoding and decoding models in cognitive electrophysiology},
	volume = {11},
	issn = {1662-5137},
	url = {http://journal.frontiersin.org/article/10.3389/fnsys.2017.00061/full},
	doi = {10.3389/fnsys.2017.00061},
	urldate = {2018-06-25},
	journal = {Frontiers in Systems Neuroscience},
	author = {Holdgraf, Christopher R. and Rieger, Jochem W. and Micheli, Cristiano and Martin, Stephanie and Knight, Robert T. and Theunissen, Frederic E.},
	month = sep,
	year = {2017},
	keywords = {MEG, EEG, project.lstmMEG, project.vsmMEG, decoding models, ecoding models},
}

@article{van_gerven_primer_2017,
	title = {A primer on encoding models in sensory neuroscience},
	volume = {76},
	issn = {00222496},
	doi = {10.1016/j.jmp.2016.06.009},
	language = {en},
	urldate = {2018-06-25},
	journal = {Journal of Mathematical Psychology},
	author = {van Gerven, Marcel A.J.},
	month = feb,
	year = {2017},
	keywords = {project.lstmMEG, project.vsmMEG, neural networks, ANN, encoding models, model-based},
	pages = {172--183},
}

@article{huth_natural_2016,
	title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	volume = {532},
	copyright = {2016 Nature Publishing Group},
	issn = {1476-4687},
	doi = {10.1038/nature17637},
	abstract = {{\textless}p{\textgreater}It has been proposed that language meaning is represented throughout the cerebral cortex in a distributed ‘semantic system’, but little is known about the details of this network; here, voxel-wise modelling of functional MRI data collected while subjects listened to natural stories is used to create a detailed atlas that maps representations of word meaning in the human brain.{\textless}/p{\textgreater}},
	language = {En},
	number = {7600},
	urldate = {2018-01-08},
	journal = {Nature},
	author = {Huth, Alexander G. and Heer, Wendy A. de and Griffiths, Thomas L. and Theunissen, Frédéric E. and Gallant, Jack L.},
	month = apr,
	year = {2016},
	keywords = {fMRI, project.lstmMEG, project.vsmMEG, computational neuroscience, semantics},
	pages = {453},
	file = {Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:/Volumes/GoogleDrive-100121059175283315603/My Drive/zotero/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:application/pdf},
}

@incollection{clark_vector_2015,
	edition = {2},
	title = {Vector space models of lexical meaning},
	isbn = {978-0-470-67073-6},
	language = {en},
	booktitle = {Handbook of contemporary semantic theory},
	publisher = {Wiley-Blackwell},
	author = {Clark, Stephen},
	year = {2015},
	keywords = {distributional semantics, project.vsmMEG, VSM},
	pages = {493--552},
	file = {Clark - 2015 - Vector space models of lexical meaning.pdf:/Volumes/GoogleDrive-100121059175283315603/My Drive/zotero/Clark - 2015 - Vector space models of lexical meaning.pdf:application/pdf},
}

@article{naselaris_cognitive_2018,
	title = {Cognitive computational neuroscience: {A} new conference for an emerging discipline},
	issn = {13646613},
	shorttitle = {Cognitive {Computational} {Neuroscience}},
	doi = {10.1016/j.tics.2018.02.008},
	language = {en},
	urldate = {2018-03-24},
	journal = {Trends in Cognitive Sciences},
	author = {Naselaris, Thomas and Bassett, Danielle S. and Fletcher, Alyson K. and Kording, Konrad and Kriegeskorte, Nikolaus and Nienborg, Hendrikje and Poldrack, Russell A. and Shohamy, Daphna and Kay, Kendrick},
	month = feb,
	year = {2018},
}

@article{hagoort_neurobiology_2019,
	title = {The neurobiology of language beyond single-word processing},
	volume = {366},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aax0289},
	doi = {10.1126/science.aax0289},
	abstract = {In this Review, I propose a multiple-network view for the neurobiological basis of distinctly human language skills. A much more complex picture of interacting brain areas emerges than in the classical neurobiological model of language. This is because using language is more than single-word processing, and much goes on beyond the information given in the acoustic or orthographic tokens that enter primary sensory cortices. This requires the involvement of multiple networks with functionally nonoverlapping contributions.},
	language = {en},
	number = {6461},
	urldate = {2020-01-27},
	journal = {Science},
	author = {Hagoort, Peter},
	month = oct,
	year = {2019},
	keywords = {cognitive neuroscience, language},
	pages = {55--58},
}

@article{sandve_ten_2013,
	title = {Ten simple rules for reproducible computational research},
	volume = {9},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	language = {en},
	number = {10},
	urldate = {2019-12-06},
	journal = {PLoS Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	editor = {Bourne, Philip E.},
	month = oct,
	year = {2013},
	pages = {e1003285},
}

@book{forstmann_introduction_2015,
	address = {New York, NY},
	title = {An {Introduction} to model-based cognitive neuroscience},
	isbn = {978-1-4939-2235-2 978-1-4939-2236-9},
	url = {http://link.springer.com/10.1007/978-1-4939-2236-9},
	language = {en},
	urldate = {2019-07-04},
	publisher = {Springer New York},
	editor = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
	year = {2015},
	doi = {10.1007/978-1-4939-2236-9},
	keywords = {computational cognitive neuroscience, model-based},
}

@article{kriegeskorte_interpreting_2019,
	title = {Interpreting encoding and decoding models},
	volume = {55},
	issn = {09594388},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818301004},
	doi = {10.1016/j.conb.2019.04.002},
	language = {en},
	urldate = {2019-05-27},
	journal = {Current Opinion in Neurobiology},
	author = {Kriegeskorte, Nikolaus and Douglas, Pamela K},
	month = apr,
	year = {2019},
	keywords = {decoding, encoding, linear model, neural readout},
	pages = {167--179},
}

@article{hickok_cortical_2007,
	title = {The cortical organization of speech processing},
	volume = {8},
	issn = {1471-003X, 1471-0048},
	doi = {10.1038/nrn2113},
	language = {en},
	number = {5},
	urldate = {2019-05-19},
	journal = {Nature Reviews Neuroscience},
	author = {Hickok, Gregory and Poeppel, David},
	month = may,
	year = {2007},
	keywords = {readme, review},
	pages = {393--402},
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} learning in python},
	volume = {12},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	year = {2011},
	keywords = {methods, machine learning, python},
	pages = {2825--2830},
}

@article{poldrack_computational_2019,
	title = {Computational and informatic advances for reproducible data analysis in neuroimaging},
	volume = {2},
	url = {https://doi.org/10.1146/annurev-biodatasci-072018-021237},
	doi = {10.1146/annurev-biodatasci-072018-021237},
	abstract = {The reproducibility of scientific research has become a point of critical concern. We argue that openness and transparency are critical for reproducibility, and we outline an ecosystem for open and transparent science that has emerged within the human neuroimaging community. We discuss the range of open data-sharing resources that have been developed for neuroimaging data, as well as the role of data standards (particularly the brain imaging data structure) in enabling the automated sharing, processing, and reuse of large neuroimaging data sets. We outline how the open source Python language has provided the basis for a data science platform that enables reproducible data analysis and visualization. We also discuss how new advances in software engineering, such as containerization, provide the basis for greater reproducibility in data analysis. The emergence of this new ecosystem provides an example for many areas of science that are currently struggling with reproducibility.},
	number = {1},
	urldate = {2020-06-02},
	journal = {Annual Review of Biomedical Data Science},
	author = {Poldrack, Russell A. and Gorgolewski, Krzysztof J. and Varoquaux, Gaël},
	year = {2019},
	keywords = {open science, reproducibility, data sharing},
	pages = {119--138},
}

@article{poldrack_making_2014,
	title = {Making big data open: data sharing in neuroimaging},
	volume = {17},
	issn = {1097-6256, 1546-1726},
	shorttitle = {Making big data open},
	url = {http://www.nature.com/articles/nn.3818},
	doi = {10.1038/nn.3818},
	language = {en},
	number = {11},
	urldate = {2020-05-23},
	journal = {Nature Neuroscience},
	author = {Poldrack, Russell A and Gorgolewski, Krzysztof J},
	month = nov,
	year = {2014},
	keywords = {open science, data sharing},
	pages = {1510--1517},
}

@article{gorgolewski_brain_2016,
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201644},
	doi = {10.1038/sdata.2016.44},
	abstract = {The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.},
	language = {en},
	number = {1},
	urldate = {2020-05-01},
	journal = {Scientific Data},
	author = {Gorgolewski, Krzysztof J. and Auer, Tibor and Calhoun, Vince D. and Craddock, R. Cameron and Das, Samir and Duff, Eugene P. and Flandin, Guillaume and Ghosh, Satrajit S. and Glatard, Tristan and Halchenko, Yaroslav O. and Handwerker, Daniel A. and Hanke, Michael and Keator, David and Li, Xiangrui and Michael, Zachary and Maumet, Camille and Nichols, B. Nolan and Nichols, Thomas E. and Pellman, John and Poline, Jean-Baptiste and Rokem, Ariel and Schaefer, Gunnar and Sochat, Vanessa and Triplett, William and Turner, Jessica A. and Varoquaux, Gaël and Poldrack, Russell A.},
	month = jun,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {open science, open data},
	pages = {1--9},
}

@article{armeni_10-hour_2022,
	title = {A 10-hour within-participant magnetoencephalography narrative dataset to test models of language comprehension},
	volume = {9},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01382-7},
	doi = {10.1038/s41597-022-01382-7},
	abstract = {Abstract
            Recently, cognitive neuroscientists have increasingly studied the brain responses to narratives. At the same time, we are witnessing exciting developments in natural language processing where large-scale neural network models can be used to instantiate cognitive hypotheses in narrative processing. Yet, they learn from text alone and we lack ways of incorporating biological constraints during training. To mitigate this gap, we provide a narrative comprehension magnetoencephalography (MEG) data resource that can be used to train neural network models directly on brain data. We recorded from 3 participants, 10 separate recording hour-long sessions each, while they listened to audiobooks in English. After story listening, participants answered short questions about their experience. To minimize head movement, the participants wore MEG-compatible head casts, which immobilized their head position during recording. We report a basic evoked-response analysis showing that the responses accurately localize to primary auditory areas. The responses are robust and conserved across 10 sessions for every participant. We also provide usage notes and briefly outline possible future uses of the resource.},
	language = {en},
	number = {1},
	urldate = {2022-10-25},
	journal = {Scientific Data},
	author = {Armeni, Kristijan and Güçlü, Umut and van Gerven, Marcel and Schoffelen, Jan-Mathijs},
	month = dec,
	year = {2022},
	pages = {278},
}

@article{dupre_beyond_2022,
	title = {Beyond advertising: {New} infrastructures for publishing integrated research objects},
	volume = {18},
	issn = {1553-7358},
	shorttitle = {Beyond advertising},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009651},
	doi = {10.1371/journal.pcbi.1009651},
	language = {en},
	number = {1},
	urldate = {2023-10-24},
	journal = {PLOS Computational Biology},
	author = {DuPre, Elizabeth and Holdgraf, Chris and Karakuzu, Agah and Tetrel, Loïc and Bellec, Pierre and Stikov, Nikola and Poline, Jean-Baptiste},
	month = jan,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {open science, reproducibility, python, open data, Jupyter notebook, Rmarkdown},
	pages = {e1009651},
}

@article{manning_human_2022,
	title = {Human language understanding \& reasoning},
	volume = {151},
	issn = {0011-5266},
	url = {https://doi.org/10.1162/daed_a_01905},
	doi = {10.1162/daed_a_01905},
	abstract = {The last decade has yielded dramatic and quite surprising breakthroughs in natural
language processing through the use of simple artificial neural network computations,
replicated on a very large scale and trained over exceedingly large amounts of data. The
resulting pretrained language models, such as BERT and GPT-3, have provided a powerful
universal language understanding and generation base, which can easily be adapted to many
understanding, writing, and reasoning tasks. These models show the first inklings of a
more general form of artificial intelligence, which may lead to powerful foundation models
in domains of sensory experience beyond just language.},
	number = {2},
	urldate = {2024-03-18},
	journal = {Daedalus},
	author = {Manning, Christopher D.},
	month = may,
	year = {2022},
	pages = {127--138},
}

@article{fedorenko_language_2024,
	title = {The language network as a natural kind within the broader landscape of the human brain},
	volume = {25},
	copyright = {2024 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-024-00802-4},
	doi = {10.1038/s41583-024-00802-4},
	abstract = {Language behaviour is complex, but neuroscientific evidence disentangles it into distinct components supported by dedicated brain areas or networks. In this Review, we describe the ‘core’ language network, which includes left-hemisphere frontal and temporal areas, and show that it is strongly interconnected, independent of input and output modalities, causally important for language and language-selective. We discuss evidence that this language network plausibly stores language knowledge and supports core linguistic computations related to accessing words and constructions from memory and combining them to interpret (decode) or generate (encode) linguistic messages. We emphasize that the language network works closely with, but is distinct from, both lower-level — perceptual and motor — mechanisms and higher-level systems of knowledge and reasoning. The perceptual and motor mechanisms process linguistic signals, but, in contrast to the language network, are sensitive only to these signals’ surface properties, not their meanings; the systems of knowledge and reasoning (such as the system that supports social reasoning) are sometimes engaged during language use but are not language-selective. This Review lays a foundation both for in-depth investigations of these different components of the language processing pipeline and for probing inter-component interactions.},
	language = {en},
	number = {5},
	urldate = {2024-08-15},
	journal = {Nature Reviews Neuroscience},
	author = {Fedorenko, Evelina and Ivanova, Anna A. and Regev, Tamar I.},
	month = may,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Human behaviour},
	pages = {289--312},
}

@article{peng_reproducible_2011,
	title = {Reproducible research in computational science},
	volume = {334},
	url = {https://www.science.org/doi/10.1126/science.1213847},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	number = {6060},
	urldate = {2024-09-10},
	journal = {Science},
	author = {Peng, Roger D.},
	month = dec,
	year = {2011},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1226--1227},
}

@article{lebel_natural_2023,
	title = {A natural language {fMRI} dataset for voxelwise encoding models},
	volume = {10},
	copyright = {2023 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-023-02437-z},
	doi = {10.1038/s41597-023-02437-z},
	abstract = {Speech comprehension is a complex process that draws on humans’ abilities to extract lexical information, parse syntax, and form semantic understanding. These sub-processes have traditionally been studied using separate neuroimaging experiments that attempt to isolate specific effects of interest. More recently it has become possible to study all stages of language comprehension in a single neuroimaging experiment using narrative natural language stimuli. The resulting data are richly varied at every level, enabling analyses that can probe everything from spectral representations to high-level representations of semantic meaning. We provide a dataset containing BOLD fMRI responses recorded while 8 participants each listened to 27 complete, natural, narrative stories ({\textasciitilde}6 hours). This dataset includes pre-processed and raw MRIs, as well as hand-constructed 3D cortical surfaces for each participant. To address the challenges of analyzing naturalistic data, this dataset is accompanied by a python library containing basic code for creating voxelwise encoding models. Altogether, this dataset provides a large and novel resource for understanding speech and language processing in the human brain.},
	language = {en},
	number = {1},
	urldate = {2024-09-13},
	journal = {Scientific Data},
	author = {LeBel, Amanda and Wagner, Lauren and Jain, Shailee and Adhikari-Desai, Aneesh and Gupta, Bhavin and Morgenthal, Allyson and Tang, Jerry and Xu, Lixiang and Huth, Alexander G.},
	month = aug,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, fMRI, encoding models, Cortex, Neural encoding},
	pages = {555},
}

@misc{lebel_fmri_2023,
	title = {An {fMRI} dataset during a passive natural language listening task},
	url = {https://openneuro.org/datasets/ds003020/versions/2.0.0},
	doi = {10.18112/OPENNEURO.DS003020.V2.0.0},
	urldate = {2024-09-13},
	publisher = {Openneuro},
	author = {LeBel, Amanda and Wagner, Lauren and Jain, Shailee and Adhikari-Desai, Aneesh and {Bhavin Gupta} and Morgenthal, Allyson and Tang, Jerry and {Lixiang Xu} and Huth, Alexander G.},
	year = {2023},
}

@misc{peng_real_2016,
	title = {The real reason reproducible research is important},
	shorttitle = {Simply {Statistics}},
	url = {https://simplystatistics.org/posts/2014-06-06-the-real-reason-reproducible-research-is-important/},
	urldate = {2025-02-14},
	journal = {Simply Statistics},
	author = {Peng, Roger},
	month = jun,
	year = {2016},
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxq028},
	doi = {10.1093/biostatistics/kxq028},
	number = {3},
	urldate = {2025-02-14},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	month = jul,
	year = {2010},
	pages = {385--388},
}

@article{doerig_neuroconnectionist_2023,
	title = {The neuroconnectionist research programme},
	volume = {24},
	issn = {1471-003X, 1471-0048},
	url = {https://www.nature.com/articles/s41583-023-00705-w},
	doi = {10.1038/s41583-023-00705-w},
	language = {en},
	number = {7},
	urldate = {2025-02-17},
	journal = {Nature Reviews Neuroscience},
	author = {Doerig, Adrien and Sommers, Rowan P. and Seeliger, Katja and Richards, Blake and Ismael, Jenann and Lindsay, Grace W. and Kording, Konrad P. and Konkle, Talia and Van Gerven, Marcel A. J. and Kriegeskorte, Nikolaus and Kietzmann, Tim C.},
	month = jul,
	year = {2023},
	pages = {431--450},
}

@article{silva_speech_2024,
	title = {The speech neuroprosthesis},
	volume = {25},
	copyright = {2024 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-024-00819-9},
	doi = {10.1038/s41583-024-00819-9},
	abstract = {Loss of speech after paralysis is devastating, but circumventing motor-pathway injury by directly decoding speech from intact cortical activity has the potential to restore natural communication and self-expression. Recent discoveries have defined how key features of speech production are facilitated by the coordinated activity of vocal-tract articulatory and motor-planning cortical representations. In this Review, we highlight such progress and how it has led to successful speech decoding, first in individuals implanted with intracranial electrodes for clinical epilepsy monitoring and subsequently in individuals with paralysis as part of early feasibility clinical trials to restore speech. We discuss high-spatiotemporal-resolution neural interfaces and the adaptation of state-of-the-art speech computational algorithms that have driven rapid and substantial progress in decoding neural activity into text, audible speech, and facial movements. Although restoring natural speech is a long-term goal, speech neuroprostheses already have performance levels that surpass communication rates offered by current assistive-communication technology. Given this accelerated rate of progress in the field, we propose key evaluation metrics for speed and accuracy, among others, to help standardize across studies. We finish by highlighting several directions to more fully explore the multidimensional feature space of speech and language, which will continue to accelerate progress towards a clinically viable speech neuroprosthesis.},
	language = {en},
	number = {7},
	urldate = {2025-02-17},
	journal = {Nature Reviews Neuroscience},
	author = {Silva, Alexander B. and Littlejohn, Kaylo T. and Liu, Jessie R. and Moses, David A. and Chang, Edward F.},
	month = jul,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	pages = {473--492},
}

@article{botvinik-nezer_variability_2020,
	title = {Variability in the analysis of a single neuroimaging dataset by many teams},
	volume = {582},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2314-9},
	doi = {10.1038/s41586-020-2314-9},
	abstract = {Data analysis workflows in many scientific domains have become increasingly complex and flexible. Here we assess the effect of this flexibility on the results of functional magnetic resonance imaging by asking 70 independent teams to analyse the same dataset, testing the same 9 ex-ante hypotheses1. The flexibility of analytical approaches is exemplified by the fact that no two teams chose identical workflows to analyse the data. This flexibility resulted in sizeable variation in the results of hypothesis tests, even for teams whose statistical maps were highly correlated at intermediate stages of the analysis pipeline. Variation in reported results was related to several aspects of analysis methodology. Notably, a meta-analytical approach that aggregated information across teams yielded a significant consensus in activated regions. Furthermore, prediction markets of researchers in the field revealed an overestimation of the likelihood of significant findings, even by researchers with direct knowledge of the dataset2–5. Our findings show that analytical flexibility can have substantial effects on scientific conclusions, and identify factors that may be related to variability in the analysis of functional magnetic resonance imaging. The results emphasize the importance of validating and sharing complex analysis workflows, and demonstrate the need for performing and reporting multiple analyses of the same data. Potential approaches that could be used to mitigate issues related to analytical variability are discussed.},
	language = {en},
	number = {7810},
	urldate = {2025-02-17},
	journal = {Nature},
	author = {Botvinik-Nezer, Rotem and Holzmeister, Felix and Camerer, Colin F. and Dreber, Anna and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Iwanir, Roni and Mumford, Jeanette A. and Adcock, R. Alison and Avesani, Paolo and Baczkowski, Blazej M. and Bajracharya, Aahana and Bakst, Leah and Ball, Sheryl and Barilari, Marco and Bault, Nadège and Beaton, Derek and Beitner, Julia and Benoit, Roland G. and Berkers, Ruud M. W. J. and Bhanji, Jamil P. and Biswal, Bharat B. and Bobadilla-Suarez, Sebastian and Bortolini, Tiago and Bottenhorn, Katherine L. and Bowring, Alexander and Braem, Senne and Brooks, Hayley R. and Brudner, Emily G. and Calderon, Cristian B. and Camilleri, Julia A. and Castrellon, Jaime J. and Cecchetti, Luca and Cieslik, Edna C. and Cole, Zachary J. and Collignon, Olivier and Cox, Robert W. and Cunningham, William A. and Czoschke, Stefan and Dadi, Kamalaker and Davis, Charles P. and Luca, Alberto De and Delgado, Mauricio R. and Demetriou, Lysia and Dennison, Jeffrey B. and Di, Xin and Dickie, Erin W. and Dobryakova, Ekaterina and Donnat, Claire L. and Dukart, Juergen and Duncan, Niall W. and Durnez, Joke and Eed, Amr and Eickhoff, Simon B. and Erhart, Andrew and Fontanesi, Laura and Fricke, G. Matthew and Fu, Shiguang and Galván, Adriana and Gau, Remi and Genon, Sarah and Glatard, Tristan and Glerean, Enrico and Goeman, Jelle J. and Golowin, Sergej A. E. and González-García, Carlos and Gorgolewski, Krzysztof J. and Grady, Cheryl L. and Green, Mikella A. and Guassi Moreira, João F. and Guest, Olivia and Hakimi, Shabnam and Hamilton, J. Paul and Hancock, Roeland and Handjaras, Giacomo and Harry, Bronson B. and Hawco, Colin and Herholz, Peer and Herman, Gabrielle and Heunis, Stephan and Hoffstaedter, Felix and Hogeveen, Jeremy and Holmes, Susan and Hu, Chuan-Peng and Huettel, Scott A. and Hughes, Matthew E. and Iacovella, Vittorio and Iordan, Alexandru D. and Isager, Peder M. and Isik, Ayse I. and Jahn, Andrew and Johnson, Matthew R. and Johnstone, Tom and Joseph, Michael J. E. and Juliano, Anthony C. and Kable, Joseph W. and Kassinopoulos, Michalis and Koba, Cemal and Kong, Xiang-Zhen and Koscik, Timothy R. and Kucukboyaci, Nuri Erkut and Kuhl, Brice A. and Kupek, Sebastian and Laird, Angela R. and Lamm, Claus and Langner, Robert and Lauharatanahirun, Nina and Lee, Hongmi and Lee, Sangil and Leemans, Alexander and Leo, Andrea and Lesage, Elise and Li, Flora and Li, Monica Y. C. and Lim, Phui Cheng and Lintz, Evan N. and Liphardt, Schuyler W. and Losecaat Vermeer, Annabel B. and Love, Bradley C. and Mack, Michael L. and Malpica, Norberto and Marins, Theo and Maumet, Camille and McDonald, Kelsey and McGuire, Joseph T. and Melero, Helena and Méndez Leal, Adriana S. and Meyer, Benjamin and Meyer, Kristin N. and Mihai, Glad and Mitsis, Georgios D. and Moll, Jorge and Nielson, Dylan M. and Nilsonne, Gustav and Notter, Michael P. and Olivetti, Emanuele and Onicas, Adrian I. and Papale, Paolo and Patil, Kaustubh R. and Peelle, Jonathan E. and Pérez, Alexandre and Pischedda, Doris and Poline, Jean-Baptiste and Prystauka, Yanina and Ray, Shruti and Reuter-Lorenz, Patricia A. and Reynolds, Richard C. and Ricciardi, Emiliano and Rieck, Jenny R. and Rodriguez-Thompson, Anais M. and Romyn, Anthony and Salo, Taylor and Samanez-Larkin, Gregory R. and Sanz-Morales, Emilio and Schlichting, Margaret L. and Schultz, Douglas H. and Shen, Qiang and Sheridan, Margaret A. and Silvers, Jennifer A. and Skagerlund, Kenny and Smith, Alec and Smith, David V. and Sokol-Hessner, Peter and Steinkamp, Simon R. and Tashjian, Sarah M. and Thirion, Bertrand and Thorp, John N. and Tinghög, Gustav and Tisdall, Loreen and Tompson, Steven H. and Toro-Serey, Claudio and Torre Tresols, Juan Jesus and Tozzi, Leonardo and Truong, Vuong and Turella, Luca and van ‘t Veer, Anna E. and Verguts, Tom and Vettel, Jean M. and Vijayarajah, Sagana and Vo, Khoi and Wall, Matthew B. and Weeda, Wouter D. and Weis, Susanne and White, David J. and Wisniewski, David and Xifra-Porxas, Alba and Yearling, Emily A. and Yoon, Sangsuk and Yuan, Rui and Yuen, Kenneth S. L. and Zhang, Lei and Zhang, Xu and Zosky, Joshua E. and Nichols, Thomas E. and Poldrack, Russell A. and Schonberg, Tom},
	month = jun,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Human behaviour, Decision, Decision making, Scientific community},
	pages = {84--88},
}

@article{ivie_reproducibility_2019,
	title = {Reproducibility in scientific computing},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3186266},
	doi = {10.1145/3186266},
	abstract = {Reproducibility is widely considered to be an essential requirement of the scientific process. However, a number of serious concerns have been raised recently, questioning whether today’s computational work is adequately reproducible. In principle, it should be possible to specify a computation to sufficient detail that anyone should be able to reproduce it exactly. But in practice, there are fundamental, technical, and social barriers to doing so. The many objectives and meanings of reproducibility are discussed within the context of scientific computing. Technical barriers to reproducibility are described, extant approaches surveyed, and open areas of research are identified.},
	language = {en},
	number = {3},
	urldate = {2025-02-18},
	journal = {ACM Computing Surveys},
	author = {Ivie, Peter and Thain, Douglas},
	month = may,
	year = {2019},
	pages = {1--36},
}

@article{peng_reproducible_2009,
	title = {Reproducible research and biostatistics},
	volume = {10},
	issn = {1468-4357, 1465-4644},
	url = {https://academic.oup.com/biostatistics/article/10/3/405/293660},
	doi = {10.1093/biostatistics/kxp014},
	language = {en},
	number = {3},
	urldate = {2025-02-18},
	journal = {Biostatistics},
	author = {Peng, Roger D.},
	month = jul,
	year = {2009},
	pages = {405--408},
}

@inproceedings{claerbout_electronic_1992,
	title = {Electronic documents give reproducible research a new meaning},
	url = {http://library.seg.org/doi/abs/10.1190/1.1822162},
	doi = {10.1190/1.1822162},
	language = {en},
	urldate = {2025-02-19},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, Jon F. and Karrenbach, Martin},
	month = jan,
	year = {1992},
	pages = {601--604},
}

@misc{barba_terminologies_2018,
	title = {Terminologies for reproducible research},
	url = {http://arxiv.org/abs/1802.03311},
	doi = {10.48550/arXiv.1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Barba, Lorena A.},
	month = feb,
	year = {2018},
	note = {arXiv:1802.03311 [cs]},
	keywords = {Computer Science - Digital Libraries},
}

@misc{us_research_software_engineer_association_research_2023,
	title = {Research software engineers: {Creating} a career path—and a career},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Research {Software} {Engineers}},
	url = {https://zenodo.org/doi/10.5281/zenodo.10073232},
	doi = {10.5281/ZENODO.10073232},
	language = {en},
	urldate = {2025-02-19},
	publisher = {Zenodo},
	author = {{US Research Software Engineer Association} and {IEEE Computer Society}},
	month = nov,
	year = {2023},
}

@misc{noauthor_four_nodate,
	title = {Four simple recommendations to encourage best practices in research software - {PMC}},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC5490478/#sec3},
	urldate = {2025-02-20},
}

@article{balaban_ten_2021,
	title = {Ten simple rules for quick and dirty scientific programming},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008549},
	doi = {10.1371/journal.pcbi.1008549},
	language = {en},
	number = {3},
	urldate = {2025-02-20},
	journal = {PLOS Computational Biology},
	author = {Balaban, Gabriel and Grytten, Ivar and Rand, Knut Dagestad and Scheffer, Lonneke and Sandve, Geir Kjetil},
	month = mar,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Computer and information sciences, Computer applications, Computer software, Optimization, Programming languages, Prototypes, Software development, Software engineering},
	pages = {e1008549},
}

@article{xiong_state_2023,
	title = {The state of play of reproducibility in statistics: {An} empirical analysis},
	volume = {77},
	issn = {0003-1305, 1537-2731},
	shorttitle = {The {State} of {Play} of {Reproducibility} in {Statistics}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2022.2131625},
	doi = {10.1080/00031305.2022.2131625},
	abstract = {Abstract Reproducibility, the ability to reproduce the results of published papers or studies using their computer code and data, is a cornerstone of reliable scientific methodology. Studies where results cannot be reproduced by the scientific community should be treated with caution. Over the past decade, the importance of reproducible research has been frequently stressed in a wide range of scientific journals such as Nature and Science and international magazines such as The Economist. However, multiple studies have demonstrated that scientific results are often not reproducible across research areas such as psychology and medicine. Statistics, the science concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data, prides itself on its openness when it comes to sharing both computer code and data. In this article, we examine reproducibility in the field of statistics by attempting to reproduce the results in 93 published papers in prominent journals using functional magnetic resonance imaging (fMRI) data during the 2010–2021 period. Overall, from both the computer code and the data perspective, among all the 93 examined papers, we could only reproduce the results in 14 (15.1\%) papers, that is, the papers provide both executable computer code (or software) with the real fMRI data, and our results matched the results in the paper. Finally, we conclude with some author-specific and journal-specific recommendations to improve the research reproducibility in statistics.},
	language = {en},
	number = {2},
	urldate = {2025-02-23},
	journal = {The American Statistician},
	author = {Xiong, Xin and Cribben, Ivor},
	month = apr,
	year = {2023},
	pages = {115--126},
}

@article{pineau_improving_2021,
	title = {Improving reproducibility in machine learning research},
	volume = {22},
	url = {http://jmlr.org/papers/v22/20-303.html},
	number = {164},
	journal = {Journal of Machine Learning Research},
	author = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Lariviere, Vincent and Beygelzimer, Alina and d'Alche-Buc, Florence and Fox, Emily and Larochelle, Hugo},
	year = {2021},
	pages = {1--20},
}

@book{martin_clean_2012,
	address = {Upper Saddle River, NJ Munich},
	edition = {Repr.},
	series = {Robert {C}. {Martin} series},
	title = {Clean code: a handbook of agile software craftsmanship},
	isbn = {978-0-13-235088-4},
	shorttitle = {Clean code},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Martin, Robert C.},
	year = {2012},
}

@book{thomas_pragmatic_2020,
	address = {Boston},
	edition = {Second edition, 20th anniversary edtion},
	title = {The pragmatic programmer: your journey to mastery},
	isbn = {978-0-13-595705-9},
	shorttitle = {The pragmatic programmer},
	abstract = {"The Pragmatic Programmer is one of those rare tech books you'll read, re-read, and read again over the years. Whether you're new to the field or an experienced practitioner, you'll come away with fresh insights each and every time. Dave Thomas and Andy Hunt wrote the first edition of this influential book in 1999 to help their clients create better software and rediscover the joy of coding. These lessons have helped a generation of programmers examine the very essence of software development, independent of any particular language, framework, or methodology, and the Pragmatic philosophy has spawned hundreds of books, screencasts, and audio books, as well as thousands of careers and success stories. Now, twenty years later, this new edition re-examines what it means to be a modern programmer. Topics range from personal responsibility and career development to architectural techniques for keeping your code flexible and easy to adapt and reuse. Read this book, and you'll learn how to: Fight software rot; Learn continuously; Avoid the trap of duplicating knowledge; Write flexible, dynamic, and adaptable code; Harness the power of basic tools; Avoid programming by coincidence; Learn real requirements; Solve the underlying problems of concurrent code; Guard against security vulnerabilities; Build teams of Pragmatic Programmers; Take responsibility for your work and career; Test ruthlessly and effectively, including property-based testing; Implement the Pragmatic Starter Kit; Delight your users. Written as a series of self-contained sections and filled with classic and fresh anecdotes, thoughtful examples, and interesting analogies, The Pragmatic Programmer illustrates the best approaches and major pitfalls of many different aspects of software development. Whether you're a new coder, an experienced programmer, or a manager responsible for software projects, use these lessons daily, and you'll quickly see improvements in personal productivity, accuracy, and job satisfaction. You'll learn skills and develop habits and attitudes that form the foundation for long-term success in your career."--Publisher's description},
	language = {eng},
	publisher = {Addison-Wesley},
	author = {Thomas, David and Hunt, Andrew},
	year = {2020},
}

@techreport{brett_research_2017,
	title = {Research {Software} {Engineers}: {State} of the nation report 2017},
	shorttitle = {Research {Software} {Engineers}},
	url = {https://zenodo.org/records/495360},
	abstract = {Most research would be impossible without software, and this reliance is forcing a rethink of the skills needed in a traditional research group. With the emergence of software as the pre-eminent research tool used across all disciplines, comes the realisation that a significant majority of results are based, ultimately, on the skill of the experts who design and build that software. 


The UK has led the world in supporting a new role in academia: the Research Software Engineer (RSE). This report describes the new expert community that has flourished in UK research, details the successes that have been achieved, and the barriers that prevent further progress.},
	urldate = {2025-02-24},
	institution = {Zenodo},
	author = {Brett, Alys and Croucher, Michael and Haines, Robert and Hettrick, Simon and Hetherington, James and Stillwell, Mark and Wyatt, Claire},
	month = apr,
	year = {2017},
	doi = {10.5281/zenodo.495360},
	keywords = {RSE, Careers, New roles in research, Research communities, Research Software Engineer, Software},
}

@article{carver_survey_2022,
	title = {A survey of the state of the practice for research software in the {United} {States}},
	volume = {8},
	issn = {2376-5992},
	url = {https://peerj.com/articles/cs-963},
	doi = {10.7717/peerj-cs.963},
	abstract = {Research software is a critical component of contemporary scholarship. Yet, most research software is developed and managed in ways that are at odds with its long-term sustainability. This paper presents findings from a survey of 1,149 researchers, primarily from the United States, about sustainability challenges they face in developing and using research software. Some of our key findings include a repeated need for more opportunities and time for developers of research software to receive training. These training needs cross the software lifecycle and various types of tools. We also identified the recurring need for better models of funding research software and for providing credit to those who develop the software so they can advance in their careers. The results of this survey will help inform future infrastructure and service support for software developers and users, as well as national research policy aimed at increasing the sustainability of research software.},
	language = {en},
	urldate = {2025-02-24},
	journal = {PeerJ Computer Science},
	author = {Carver, Jeffrey C. and Weber, Nic and Ram, Karthik and Gesing, Sandra and Katz, Daniel S.},
	month = may,
	year = {2022},
	note = {Publisher: PeerJ Inc.},
	pages = {e963},
}

@misc{community_illustrations_2021,
	title = {Illustrations from the {Turing} {Way} book dashes},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/4906004},
	abstract = {Illustrations created by Scriberia as part of the {\textless}em{\textgreater}Turing Way{\textless}/em{\textgreater} book dashes in 2019 (two events in person), 2020 (one event in-person and one online) and 2021 (one online). They depict a variety of content of the five guides in The Turing Way as well as the community activities of {\textless}em{\textgreater}The Turing Way{\textless}/em{\textgreater} in general. More information on the book dashes can be found at https://the-turing-way.netlify.app/community-handbook/bookdash.html. When using any of the images, please include the following attribution with the specific DOI as listed on the particular Zenodo page: This image was created by Scriberia for The Turing Way community and is used under a CC-BY licence. You can cite all versions by using the DOI 10.5281/zenodo.3332807. This DOI represents all versions, and will always resolve to the latest one. Individual illustrations are provided as {\textless}strong{\textgreater}.jpg{\textless}/strong{\textgreater} files and zipped archives of the files are given in {\textless}strong{\textgreater}.pdf{\textless}/strong{\textgreater}, {\textless}strong{\textgreater}.png{\textless}/strong{\textgreater} and {\textless}strong{\textgreater}.svg{\textless}/strong{\textgreater} format when available (named starting with {\textless}strong{\textgreater}zz- {\textless}/strong{\textgreater}to keep them at the bottom of the list). zz-Latest-TheTuringWay-Scriberia-2021-JPG-English-text.zip zz-Latest-TheTuringWay-Scriberia-2021-JPG-{\textless}strong{\textgreater}without-text.zip{\textless}/strong{\textgreater} zz-Latest-TheTuringWay-Scriberia-2021-PDF-English-text.zip zz-Latest-TheTuringWay-Scriberia-2021-PDF-{\textless}strong{\textgreater}without-text.zip{\textless}/strong{\textgreater} zz-TheTuringWay-Scriberia-2019-20-AllJPG.zip zz-TheTuringWay-Scriberia-2019-20-AllPDF.zip zz-TheTuringWay-Scriberia-2019-20-SVG-where-available.zip {\textless}strong{\textgreater}Translating and editing Images: {\textless}/strong{\textgreater}Zipped archives ending with '{\textless}strong{\textgreater}-without-text.zip{\textless}/strong{\textgreater}' are provided for the latest release that can be translated into languages that you would like to use them in. We encourage the use and re-use of these images as much as possible. This includes remixing the images, for example changing the colours, translating text or merging them together with additional (openly licensed) images. If you create something that others may benefit from, we encourage you to contribute your image back to {\textless}em{\textgreater}The Turing Way. {\textless}/em{\textgreater}Please get in touch with the team members by emailing theturingway@gmail.com who can help you update this repository with the images you create. If you'd like to change the colours of the image to align with other elements of your presentation, {\textless}em{\textgreater}Turing Way{\textless}/em{\textgreater} community member Alex Chan has written a guide for changing the dominant colour in an image which we hope is helpful.},
	urldate = {2025-02-24},
	author = {Community, The Turing Way and {Scriberia}},
	month = may,
	year = {2021},
	doi = {10.5281/ZENODO.4906004},
	note = {Publisher: Zenodo},
}

@book{committee_on_reproducibility_and_replicability_in_science_reproducibility_2019,
	address = {Washington, D.C.},
	title = {Reproducibility and replicability in science},
	isbn = {978-0-309-48616-3},
	url = {https://www.nap.edu/catalog/25303},
	urldate = {2025-02-24},
	publisher = {National Academies Press},
	collaborator = {{Committee on Reproducibility and Replicability in Science} and {Board on Behavioral, Cognitive, and Sensory Sciences} and {Committee on National Statistics} and {Division of Behavioral and Social Sciences and Education} and {Nuclear and Radiation Studies Board} and {Division on Earth and Life Studies} and {Board on Mathematical Sciences and Analytics} and {Committee on Applied and Theoretical Statistics} and {Division on Engineering and Physical Sciences} and {Board on Research Data and Information} and {Committee on Science, Engineering, Medicine, and Public Policy} and {Policy and Global Affairs} and {National Academies of Sciences, Engineering, and Medicine}},
	month = sep,
	year = {2019},
	doi = {10.17226/25303},
	keywords = {Policy for Science and Technology, Policy for Science and Technology--Research and Data, Surveys and Statistics},
}

@article{open_science_collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	copyright = {http://www.sciencemag.org/about/science-licenses-journal-article-reuse},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aac4716},
	doi = {10.1126/science.aac4716},
	abstract = {Empirically analyzing empirical evidence
            
              One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts
              et al.
              describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.
            
            
              Science
              , this issue
              10.1126/science.aac4716
            
          , 
            A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.
          , 
            
              INTRODUCTION
              Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.
            
            
              RATIONALE
              There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.
            
            
              RESULTS
              
                We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and
                P
                values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (
                M
                r
                = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (
                M
                r
                = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (
                P
                {\textless} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
              
            
            
              CONCLUSION
              
                No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original
                P
                value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.
              
              Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.
              
                
                  Original study effect size versus replication effect size (correlation coefficients).
                  Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.
                
                
              
            
          , 
            Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	language = {en},
	number = {6251},
	urldate = {2025-02-26},
	journal = {Science},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pages = {aac4716},
}

@misc{beck_manifesto_2001,
	title = {Manifesto for agile software development},
	url = {http://www.agilemanifesto.org/},
	urldate = {2025-02-25},
	author = {Beck, Kent and Beedle, Mike and van Bennekum, Arie and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andrew and Jeffries, Ron and Kern, Jon and Marick, Brian and Martin, Robert C. and Mellor, Steve and Schwaber, Ken and Sutherland, Jeff and Thomas, Dave},
	year = {2001},
	keywords = {imported},
}

@misc{community_turing_2022,
	title = {The {Turing} {Way}: {A} handbook for reproducible, ethical and collaborative research},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/record/3233853},
	abstract = {The Turing Way: A handbook for reproducible, ethical and collaborative research The Turing Way December 2022 Latest The Turing Way is an open source community-driven guide to reproducible, ethical, inclusive and collaborative data science. The Turing Way book is collaboratively developed by its diverse community of researchers, learners, educators, and other stakeholders. The Turing Way project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. In 2020, the project underwent a major overhaul categorising chapters into 5 guides on reproducible research, project design, collaboration, communication and ethical research. Additionally, we added a community handbook to document all the practices designed and implemented towards the development of the project and community. This release in 2021 includes additional chapters developed by our contributors across five guides and the community handbook. In addition, all the project documents from the project are provided as they appear on The Turing Way GitHub repository including the Zenodo metadata: https://github.com/alan-turing-institute/the-turing-way. Release log v1.1.0: Zenodo metadata information and additional chapters from Book Dash Dec 2022 v1.0.3: Zenodo metadata information and additional chapters from Book Dash May 2022 v1.0.2: Zenodo metadata information and additional chapters since Book Dash November 2021 v1.0.1: Zenodo metadata information and additional chapters. v1.0.0: Five guide expansion of The Turing Way with a community handbook v0.0.4: Continuous integration chapter merged to main. v0.0.3: Reproducible environments chapter merged to main. v0.0.2: Version control chapter merged to main. v0.0.1: Reproducibility chapter merged to main. Full Changelog: https://github.com/alan-turing-institute/the-turing-way/compare/v1.0.1...v1.0.3 (Previous release: https://github.com/alan-turing-institute/the-turing-way/compare/v0.0.3...v1.0.1) v1.1.0},
	urldate = {2025-02-26},
	publisher = {Zenodo},
	author = {Community, The Turing Way},
	month = jul,
	year = {2022},
	doi = {10.5281/ZENODO.3233853},
	keywords = {reproducibility, ethics, data science, research practices, collaboration, community, handbook},
}

@article{zwaan_making_2018,
	title = {Making replication mainstream},
	volume = {41},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/making-replication-mainstream/2E3D8805BF34927A76B963C7BBE36AC7},
	doi = {10.1017/S0140525X17001972},
	abstract = {Many philosophers of science and methodologists have argued that the ability to repeat studies and obtain similar results is an essential component of science. A finding is elevated from single observation to scientific evidence when the procedures that were used to obtain it can be reproduced and the finding itself can be replicated. Recent replication attempts show that some high profile results – most notably in psychology, but in many other disciplines as well – cannot be replicated consistently. These replication attempts have generated a considerable amount of controversy, and the issue of whether direct replications have value has, in particular, proven to be contentious. However, much of this discussion has occurred in published commentaries and social media outlets, resulting in a fragmented discourse. To address the need for an integrative summary, we review various types of replication studies and then discuss the most commonly voiced concerns about direct replication. We provide detailed responses to these concerns and consider different statistical ways to evaluate replications. We conclude there are no theoretical or statistical obstacles to making direct replication a routine aspect of psychological science.},
	language = {en},
	urldate = {2025-02-26},
	journal = {Behavioral and Brain Sciences},
	author = {Zwaan, Rolf A. and Etz, Alexander and Lucas, Richard E. and Donnellan, M. Brent},
	month = jan,
	year = {2018},
	keywords = {reproducibility, replication, psychological research, research programs},
	pages = {e120},
}

@article{grahe_replication_2014,
	title = {Replication education},
	volume = {27},
	url = {https://www.psychologicalscience.org/observer/replication-education},
	abstract = {Replications are not only one key component of the scientific method, they are also an effective pedagogical tool.With this in mind, we recently launched the Collaboration Replications and Education Project (CREP; rhymes with grape) to …},
	language = {en},
	urldate = {2025-02-26},
	journal = {APS Observer},
	author = {Grahe, Jon and Brandt, Mark and IJzerman, Hans and Cohoon, {and} Johanna},
	month = feb,
	year = {2014},
	file = {Snapshot:/Users/kriarm/Zotero/storage/FTWIUC6X/replication-education.html:text/html},
}

@article{gernsbacher_three_2018,
	title = {Three ways to make replication mainstream},
	volume = {41},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X1800064X/type/journal_article},
	doi = {10.1017/S0140525X1800064X},
	abstract = {Abstract
            Zwaan et al. argue convincingly that replication needs to be more mainstream. Here, I suggest three practices for achieving that goal: Incremental Replications, which are built into each experiment in a series of experiments; Reciprocal Replications, which are reciprocal arrangements of co-replications across labs; and Didactic Replications, which are replications used for training.},
	language = {en},
	urldate = {2025-02-26},
	journal = {Behavioral and Brain Sciences},
	author = {Gernsbacher, Morton Ann},
	year = {2018},
	pages = {e129},
	file = {Accepted Version:/Users/kriarm/Zotero/storage/XC9Y6SG7/Gernsbacher - 2018 - Three ways to make replication mainstream.pdf:application/pdf},
}

@article{kochari_introducing_2018,
	title = {Introducing a replication-first rule for {Ph}.{D}. projects},
	volume = {41},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X18000730/type/journal_article},
	doi = {10.1017/S0140525X18000730},
	abstract = {Abstract
            Zwaan et al. mention that young researchers should conduct replications as a small part of their portfolio. We extend this proposal and suggest that conducting and reporting replications should become an integral part of Ph.D. projects and be taken into account in their assessment. We discuss how this would help not only scientific advancement, but also Ph.D. candidates' careers.},
	language = {en},
	urldate = {2025-02-26},
	journal = {Behavioral and Brain Sciences},
	author = {Kochari, Arnold R. and Ostarek, Markus},
	year = {2018},
	pages = {e138},
	file = {Submitted Version:/Users/kriarm/Zotero/storage/SLDMS3SL/Kochari and Ostarek - 2018 - Introducing a replication-first rule for Ph.D. projects.pdf:application/pdf},
}

@article{rokem_hands-neuroinformatics_2024,
	title = {Hands-{On} neuroinformatics education at the crossroads of online and in-person: {Lessons} learned from {NeuroHackademy}},
	volume = {22},
	issn = {1559-0089},
	shorttitle = {Hands-{On} {Neuroinformatics} {Education} at the {Crossroads} of {Online} and {In}-{Person}},
	url = {https://link.springer.com/10.1007/s12021-024-09666-6},
	doi = {10.1007/s12021-024-09666-6},
	language = {en},
	number = {4},
	urldate = {2025-03-05},
	journal = {Neuroinformatics},
	author = {Rokem, Ariel and Benson, Noah C.},
	month = may,
	year = {2024},
	pages = {647--655},
}

@article{gau_brainhack_2021,
	title = {Brainhack: {Developing} a culture of open, inclusive, community-driven neuroscience},
	volume = {109},
	issn = {08966273},
	shorttitle = {Brainhack},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627321002312},
	doi = {10.1016/j.neuron.2021.04.001},
	language = {en},
	number = {11},
	urldate = {2025-03-05},
	journal = {Neuron},
	author = {Gau, Rémi and Noble, Stephanie and Heuer, Katja and Bottenhorn, Katherine L. and Bilgin, Isil P. and Yang, Yu-Fang and Huntenburg, Julia M. and Bayer, Johanna M.M. and Bethlehem, Richard A.I. and Rhoads, Shawn A. and Vogelbacher, Christoph and Borghesani, Valentina and Levitis, Elizabeth and Wang, Hao-Ting and Van Den Bossche, Sofie and Kobeleva, Xenia and Legarreta, Jon Haitz and Guay, Samuel and Atay, Selim Melvin and Varoquaux, Gael P. and Huijser, Dorien C. and Sandström, Malin S. and Herholz, Peer and Nastase, Samuel A. and Badhwar, AmanPreet and Dumas, Guillaume and Schwab, Simon and Moia, Stefano and Dayan, Michael and Bassil, Yasmine and Brooks, Paula P. and Mancini, Matteo and Shine, James M. and O’Connor, David and Xie, Xihe and Poggiali, Davide and Friedrich, Patrick and Heinsfeld, Anibal S. and Riedl, Lydia and Toro, Roberto and Caballero-Gaudes, César and Eklund, Anders and Garner, Kelly G. and Nolan, Christopher R. and Demeter, Damion V. and Barrios, Fernando A. and Merchant, Junaid S. and McDevitt, Elizabeth A. and Oostenveld, Robert and Craddock, R. Cameron and Rokem, Ariel and Doyle, Andrew and Ghosh, Satrajit S. and Nikolaidis, Aki and Stanley, Olivia W. and Uruñuela, Eneko and Anousheh, Nasim and Arnatkeviciute, Aurina and Auzias, Guillaume and Bachar, Dipankar and Bannier, Elise and Basanisi, Ruggero and Basavaraj, Arshitha and Bedini, Marco and Bellec, Pierre and Benn, R. Austin and Berluti, Kathryn and Bollmann, Steffen and Bollmann, Saskia and Bradley, Claire and Brown, Jesse and Buchweitz, Augusto and Callahan, Patrick and Chan, Micaela Y. and Chandio, Bramsh Q. and Cheng, Theresa and Chopra, Sidhant and Chung, Ai Wern and Close, Thomas G. and Combrisson, Etienne and Cona, Giorgia and Constable, R. Todd and Cury, Claire and Dadi, Kamalaker and Damasceno, Pablo F. and Das, Samir and De Vico Fallani, Fabrizio and DeStasio, Krista and Dickie, Erin W. and Dorfschmidt, Lena and Duff, Eugene P. and DuPre, Elizabeth and Dziura, Sarah and Esper, Nathalia B. and Esteban, Oscar and Fadnavis, Shreyas and Flandin, Guillaume and Flannery, Jessica E. and Flournoy, John and Forkel, Stephanie J. and Franco, Alexandre R. and Ganesan, Saampras and Gao, Siyuan and García Alanis, José C. and Garyfallidis, Eleftherios and Glatard, Tristan and Glerean, Enrico and Gonzalez-Castillo, Javier and Gould Van Praag, Cassandra D. and Greene, Abigail S. and Gupta, Geetika and Hahn, Catherine Alice and Halchenko, Yaroslav O. and Handwerker, Daniel and Hartmann, Thomas S. and Hayot-Sasson, Valérie and Heunis, Stephan and Hoffstaedter, Felix and Hohmann, Daniela M. and Horien, Corey and Ioanas, Horea-Ioan and Iordan, Alexandru and Jiang, Chao and Joseph, Michael and Kai, Jason and Karakuzu, Agah and Kennedy, David N. and Keshavan, Anisha and Khan, Ali R. and Kiar, Gregory and Klink, P. Christiaan and Koppelmans, Vincent and Koudoro, Serge and Laird, Angela R. and Langs, Georg and Laws, Marissa and Licandro, Roxane and Liew, Sook-Lei and Lipic, Tomislav and Litinas, Krisanne and Lurie, Daniel J. and Lussier, Désirée and Madan, Christopher R. and Mais, Lea-Theresa and Mansour L, Sina and Manzano-Patron, J.P. and Maoutsa, Dimitra and Marcon, Matheus and Margulies, Daniel S. and Marinato, Giorgio and Marinazzo, Daniele and Markiewicz, Christopher J. and Maumet, Camille and Meneguzzi, Felipe and Meunier, David and Milham, Michael P. and Mills, Kathryn L. and Momi, Davide and Moreau, Clara A. and Motala, Aysha and Moxon-Emre, Iska and Nichols, Thomas E. and Nielson, Dylan M. and Nilsonne, Gustav and Novello, Lisa and O’Brien, Caroline and Olafson, Emily and Oliver, Lindsay D. and Onofrey, John A. and Orchard, Edwina R. and Oudyk, Kendra and Park, Patrick J. and Parsapoor, Mahboobeh and Pasquini, Lorenzo and Peltier, Scott and Pernet, Cyril R. and Pienaar, Rudolph and Pinheiro-Chagas, Pedro and Poline, Jean-Baptiste and Qiu, Anqi and Quendera, Tiago and Rice, Laura C. and Rocha-Hidalgo, Joscelin and Rutherford, Saige and Scharinger, Mathias and Scheinost, Dustin and Shariq, Deena and Shaw, Thomas B. and Siless, Viviana and Simmonite, Molly and Sirmpilatze, Nikoloz and Spence, Hayli and Sprenger, Julia and Stajduhar, Andrija and Szinte, Martin and Takerkart, Sylvain and Tam, Angela and Tejavibulya, Link and Thiebaut De Schotten, Michel and Thome, Ina and Tomaz Da Silva, Laura and Traut, Nicolas and Uddin, Lucina Q. and Vallesi, Antonino and VanMeter, John W. and Vijayakumar, Nandita and Di Oleggio Castello, Matteo Visconti and Vohryzek, Jakub and Vukojević, Jakša and Whitaker, Kirstie Jane and Whitmore, Lucy and Wideman, Steve and Witt, Suzanne T. and Xie, Hua and Xu, Ting and Yan, Chao-Gan and Yeh, Fang-Cheng and Yeo, B.T. Thomas and Zuo, Xi-Nian},
	month = jun,
	year = {2021},
	pages = {1769--1775},
}

@article{craddock_brainhack_2016,
	title = {Brainhack: a collaborative workshop for the open neuroscience community},
	volume = {5},
	issn = {2047-217X},
	shorttitle = {Brainhack},
	url = {https://doi.org/10.1186/s13742-016-0121-x},
	doi = {10.1186/s13742-016-0121-x},
	abstract = {Brainhack events offer a novel workshop format with participant-generated content that caters to the rapidly growing open neuroscience community. Including components from hackathons and unconferences, as well as parallel educational sessions, Brainhack fosters novel collaborations around the interests of its attendees. Here we provide an overview of its structure, past events, and example projects. Additionally, we outline current innovations such as regional events and post-conference publications. Through introducing Brainhack to the wider neuroscience community, we hope to provide a unique conference format that promotes the features of collaborative, open science.},
	number = {1},
	urldate = {2025-03-05},
	journal = {GigaScience},
	author = {Craddock, R. Cameron and Margulies, Daniel S. and Bellec, Pierre and Nichols, B. Nolan and Alcauter, Sarael and Barrios, Fernando A. and Burnod, Yves and Cannistraci, Christopher J. and Cohen-Adad, Julien and De Leener, Benjamin and Dery, Sebastien and Downar, Jonathan and Dunlop, Katharine and Franco, Alexandre R. and Froehlich, Caroline Seligman and Gerber, Andrew J. and Ghosh, Satrajit S. and Grabowski, Thomas J. and Hill, Sean and Heinsfeld, Anibal Sólon and Hutchison, R. Matthew and Kundu, Prantik and Laird, Angela R. and Liew, Sook-Lei and Lurie, Daniel J. and McLaren, Donald G. and Meneguzzi, Felipe and Mennes, Maarten and Mesmoudi, Salma and O’Connor, David and Pasaye, Erick H. and Peltier, Scott and Poline, Jean-Baptiste and Prasad, Gautam and Pereira, Ramon Fraga and Quirion, Pierre-Olivier and Rokem, Ariel and Saad, Ziad S. and Shi, Yonggang and Strother, Stephen C. and Toro, Roberto and Uddin, Lucina Q. and Van Horn, John D. and Van Meter, John W. and Welsh, Robert C. and Xu, Ting},
	month = mar,
	year = {2016},
	keywords = {open science, data sharing, hackathon},
	pages = {16},
}

@article{australian_climate_simulator_harnessing_2025,
	title = {Harnessing marine open data science for ocean sustainability in {Africa}, {South} {Asia}, and {Latin} {America}},
	volume = {38},
	issn = {10428275},
	url = {https://tos.org/oceanography/article/harnessing-marine-open-data-science-for-ocean-sustainability-in-africa-south-asia-and-latin-america},
	doi = {10.5670/oceanog.2025.121},
	abstract = {One of the biggest barriers to conducting ocean science around the globe is limited access to computational tools and resources, including software, computing infrastructure, and data. Open tools, such as open-source software, open data, and online computing resources, offer promising solutions toward more equitable access to scientific resources. Here, we discuss the enabling power of these tools in under-resourced and non-English speaking regions, based on experience gained in the organization of three independent programs in West African, Latin American, and Indian Ocean nations. These programs have embraced the “hackweek” learning model that bridges the gap between data science and domain applications. Hackweeks function as knowledge exchange forums and foster meaningful international and regional connections among scientists. Lessons learned across the three case studies include the importance of using open computational and data resources, tailoring programs to regional and cultural differences, and the benefits and challenges of using cloud-based infrastructure. Sharing capacity in marine open data science through the regional hackweek approach can expand the participation of more diverse scientific communities and help incorporate different perspectives and broader solutions to threats to marine ecosystems and communities.},
	number = {1},
	urldate = {2025-03-05},
	journal = {Oceanography},
	author = {{Australian Climate Simulator} and Martin, Paige and Holmes, Elizabeth and Mayorga, Emilio and Ansong, Joseph and Bhaskar, Uday and Cornejo-Donoso, Jorge and Correa-Chilón, David and Damoah, Richard and Fierro-Arcos, Denisse and Gómez-Navarro, Laura and Kumar, Nimit and Lawal-Are, Aderonke and Maity, Sourav and Majumder, Swarnali and Menemenlis, Dimitris and Modi, Aditi and Nyadjro, Ebenezer and Oghenechovwen, Oghenekevwe and Oikonomou, Anthi and Oladipo, Mumin and Peña, Marian and Quaye, Daniel and Santana-Falcón, Yeray and Smitha, Br and Troupin, Charles and Vagenas, Georgios and Villalobos, Héctor and Wagner, Gregory},
	year = {2025},
	keywords = {hackathon},
}

@misc{nosek_strategy_2019,
	title = {Strategy for culture change},
	url = {https://www.cos.io/blog/strategy-for-culture-change},
	abstract = {Strategy for Culture Change},
	language = {en},
	urldate = {2025-03-05},
	author = {Nosek, Brian},
	month = jun,
	year = {2019},
}

@article{armeni_towards_2021,
	title = {Towards wide-scale adoption of open science practices: {The} role of open science communities},
	volume = {48},
	issn = {0302-3427},
	shorttitle = {Towards wide-scale adoption of open science practices},
	url = {https://doi.org/10.1093/scipol/scab039},
	doi = {10.1093/scipol/scab039},
	abstract = {Despite the increasing availability of Open Science (OS) infrastructure and the rise in policies to change behaviour, OS practices are not yet the norm. While pioneering researchers are developing OS practices, the majority sticks to status quo. To transition to common practice, we must engage a critical proportion of the academic community. In this transition, OS Communities (OSCs) play a key role. OSCs are bottom-up learning groups of scholars that discuss OS within and across disciplines. They make OS knowledge more accessible and facilitate communication among scholars and policymakers. Over the past two years, eleven OSCs were founded at several Dutch university cities. In other countries, similar OSCs are starting up. In this article, we discuss the pivotal role OSCs play in the large-scale transition to OS. We emphasize that, despite the grassroot character of OSCs, support from universities is critical for OSCs to be viable, effective, and sustainable.},
	number = {5},
	urldate = {2025-03-05},
	journal = {Science and Public Policy},
	author = {Armeni, Kristijan and Brinkman, Loek and Carlsson, Rickard and Eerland, Anita and Fijten, Rianne and Fondberg, Robin and Heininga, Vera E and Heunis, Stephan and Koh, Wei Qi and Masselink, Maurits and Moran, Niall and Baoill, Andrew Ó and Sarafoglou, Alexandra and Schettino, Antonio and Schwamm, Hardy and Sjoerds, Zsuzsika and Teperek, Marta and van den Akker, Olmo R and van't Veer, Anna and Zurita-Milla, Raul},
	month = oct,
	year = {2021},
	pages = {605--611},
}

@article{rokem_ten_2024,
	title = {Ten simple rules for scientific code review},
	volume = {20},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012375},
	doi = {10.1371/journal.pcbi.1012375},
	abstract = {As large, high-dimensional data have become more common, software development is playing an increasingly important role in research across many different fields. This creates a need to adopt software engineering practices in research settings. Code review is the engineering practice of giving and receiving detailed feedback on a computer program. Consistent and continuous examination of the evolution of computer programs by others has been shown to be beneficial, especially when reviewers are familiar with the technical aspects of the software and also when they possess relevant domain expertise. The rules described in the present article provide information about the why, when, and how of code review. They provide the motivation for continual code reviews as a natural part of a rigorous research program. They provide practical guidelines for conducting review of code both in person, as a “lab meeting for code,” as well as asynchronously, using industry-standard online tools. A set of guidelines is provided for the nitty-gritty details of code review, as well as for the etiquette of such a review. Both the technical and the social aspects of code review are covered to provide the reader with a comprehensive approach that facilitates an effective, enjoyable, and educational approach to code review.},
	language = {en},
	number = {9},
	urldate = {2025-03-13},
	journal = {PLOS Computational Biology},
	author = {Rokem, Ariel},
	month = sep,
	year = {2024},
	note = {Publisher: Public Library of Science},
	keywords = {Open source software, Computer applications, Computer software, Programming languages, Software development, Software engineering, Scientists, Software tools},
	pages = {e1012375},
}

@article{barba_path_2024,
	title = {The path to frictionless reproducibility is still under construction},
	volume = {6},
	issn = {2644-2353, 2688-8513},
	url = {https://hdsr.mitpress.mit.edu/pub/7ncz09ji/release/1},
	doi = {10.1162/99608f92.d73c0559},
	language = {en},
	number = {1},
	urldate = {2025-03-13},
	journal = {Harvard Data Science Review},
	author = {Barba, Lorena},
	month = jan,
	year = {2024},
	note = {Publisher: The MIT Press},
}

@article{sejnowski_putting_2014,
	title = {Putting big data to good use in neuroscience},
	volume = {17},
	copyright = {2014 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3839},
	doi = {10.1038/nn.3839},
	abstract = {Neuroscience is poised to collect Big Data sets. In this Commentary, the authors argue that, to exploit its full potential, there need to be ways to standardize, integrate and synthesize diverse types of data and that this will require a cultural shift to a central role for theorists in neuroscience research.},
	language = {en},
	number = {11},
	urldate = {2025-03-18},
	journal = {Nature Neuroscience},
	author = {Sejnowski, Terrence J. and Churchland, Patricia S. and Movshon, J. Anthony},
	month = nov,
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Scientific community, Databases, Emergence},
	pages = {1440--1441},
}

@article{connolly_software_2023,
	title = {Software engineering practices in academia: {Promoting} the {3Rs}—{Readability}, {Resilience}, and {Reuse}},
	volume = {5},
	issn = {2644-2353, 2688-8513},
	shorttitle = {Software {Engineering} {Practices} in {Academia}},
	url = {https://hdsr.mitpress.mit.edu/pub/f0f7h5cu/release/2},
	doi = {10.1162/99608f92.018bf012},
	abstract = {Over the past decade as data science has become integral to the research workflow, we, like many others, have learned that good data science requires high-quality software engineering. Unfortunately, our experience is that many data science projects can be limited by the absence of software engineering processes. We advocate that data science projects should incorporate what we call the 3Rs of software engineering: readability (human understandable codes), resilience (fails rarely/gracefully), and reuse (can easily be used by others and can be embedded in other software). This article discusses engineering practices that promote 3R software in academia. We emphasize that best practices in academia may differ from those in industry because of substantial differences in project scope (most academic projects have a single developer who is the sole user) and the reward systems in place in academia. We provide a framework for selecting a level of software engineering rigor that aligns well with the project scope, something that may change over time. We further discuss how to improve training in software engineering skills in an academic environment and how to build communities of practice that span across disciplines.},
	language = {en},
	number = {2},
	urldate = {2025-03-18},
	journal = {Harvard Data Science Review},
	author = {Connolly, Andrew and Hellerstein, Joseph and Alterman, Naomi and Beck, David and Fatland, Rob and Lazowska, Ed and Mandava, Vani and Stone, Sarah},
	month = apr,
	year = {2023},
	note = {Publisher: The MIT Press},
}

@article{boehm_software_1976,
	title = {Software engineering},
	volume = {25},
	issn = {0018-9340},
	url = {https://doi.org/10.1109/TC.1976.1674590},
	doi = {10.1109/TC.1976.1674590},
	abstract = {This paper provides a definition of the term "software engineering" and a survey of the current state of the art and likely future trends in the field. The survey covers the technology available in the various phases of the software life cycle requirements engineering, design, coding, test, and maintenance and in the overall area of software management and integrated technology-management approaches. It is oriented primarily toward discussing the domain of applicability of techniques (where and when they work), rather than how they work in detail. To cover the latter, an extensive set of 104 references is provided.},
	number = {12},
	urldate = {2025-03-18},
	journal = {IEEE Trans. Comput.},
	author = {Boehm, B. W.},
	month = dec,
	year = {1976},
	pages = {1226--1241},
}

@article{ivanova_beyond_2022,
	title = {Beyond linear regression: mapping models in cognitive neuroscience should align with research goals},
	volume = {1},
	issn = {2690-2664},
	shorttitle = {Beyond linear regression},
	url = {https://nbdt.scholasticahq.com/article/37507-beyond-linear-regression-mapping-models-in-cognitive-neuroscience-should-align-with-research-goals},
	doi = {10.51628/001c.37507},
	abstract = {Many cognitive neuroscience studies use large feature sets to predict and interpret brain activity patterns. Feature sets take many forms, from human stimulus annotations to representations in deep neural networks. Of crucial importance in all these studies is the mapping model, which defines the space of possible relationships between features and neural data. Until recently, most encoding and decoding studies have used linear mapping models. Increasing availability of large datasets and computing resources has recently allowed some researchers to employ more flexible nonlinear mapping models; however, the question of whether nonlinear mapping models can yield meaningful scientific insights remains debated. Here, we discuss the choice of a mapping model in the context of three overarching desiderata: predictive accuracy, interpretability, and biological plausibility. We show that these desiderata do not map cleanly onto the linear/nonlinear divide; instead, each desideratum can refer to multiple research goals, each of which imposes its own constraints on the mapping model. Moreover, we argue that, instead of categorically treating the mapping models as linear or nonlinear, researchers should report the complexity of these models. We show that, in many cases, complexity provides a more accurate reflection of restrictions imposed by various research goals and outline several complexity metrics that can be used to effectively evaluate mapping models.},
	language = {en},
	urldate = {2025-03-19},
	journal = {Neurons, Behavior, Data analysis, and Theory},
	author = {Ivanova, Anna A and Schrimpf, Martin and Anzellotti, Stefano and Zaslavsky, Noga and Fedorenko, Evelina and Isik, Leyla},
	month = aug,
	year = {2022},
}

@article{halchenko_datalad_2021,
	title = {{DataLad}: distributed system for joint management of code, data, and their relationship},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2475-9066},
	shorttitle = {{DataLad}},
	url = {https://joss.theoj.org/papers/10.21105/joss.03262},
	doi = {10.21105/joss.03262},
	number = {63},
	urldate = {2025-03-19},
	journal = {Journal of Open Source Software},
	author = {Halchenko, Yaroslav and Meyer, Kyle and Poldrack, Benjamin and Solanky, Debanjum and Wagner, Adina and Gors, Jason and MacFarlane, Dave and Pustina, Dorian and Sochat, Vanessa and Ghosh, Satrajit and Mönch, Christian and Markiewicz, Christopher and Waite, Laura and Shlyakhter, Ilya and De La Vega, Alejandro and Hayashi, Soichi and Häusler, Christian and Poline, Jean-Baptiste and Kadelka, Tobias and Skytén, Kusti and Jarecka, Dorota and Kennedy, David and Strauss, Ted and Cieslak, Matt and Vavra, Peter and Ioanas, Horea-Ioan and Schneider, Robin and Pflüger, Mika and Haxby, James and Eickhoff, Simon and Hanke, Michael},
	month = jul,
	year = {2021},
	pages = {3262},
}

@misc{niso_taxonomy_definitions_and_recognition_badging_scheme_working_group_reproducibility_nodate,
	title = {Reproducibility badging and definitions},
	url = {https://www.niso.org/publications/rp-31-2021-badging},
	doi = {10.3789/niso-rp-31-2021},
	language = {en},
	urldate = {2025-03-26},
	publisher = {NISO},
	author = {{NISO Taxonomy, Definitions, and Recognition Badging Scheme Working Group}},
}

@article{friederici_language_2013,
	title = {The language network},
	volume = {23},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09594388},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438812001614},
	doi = {10.1016/j.conb.2012.10.002},
	language = {en},
	number = {2},
	urldate = {2025-03-27},
	journal = {Current Opinion in Neurobiology},
	author = {Friederici, Angela D and Gierhan, Sarah Me},
	month = apr,
	year = {2013},
	pages = {250--254},
}

@article{logothetis_underpinnings_2003,
	title = {The underpinnings of the {BOLD} functional magnetic resonance imaging signal},
	volume = {23},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-10-03963.2003},
	doi = {10.1523/JNEUROSCI.23-10-03963.2003},
	language = {en},
	number = {10},
	urldate = {2025-03-27},
	journal = {The Journal of Neuroscience},
	author = {Logothetis, Nikos K.},
	month = may,
	year = {2003},
	pages = {3963--3971},
}

@misc{rowan_cockett_jupyter-bookmystmd_2025,
	title = {jupyter-book/mystmd: v1.3.24},
	copyright = {MIT License},
	shorttitle = {jupyter-book/mystmd},
	url = {https://zenodo.org/doi/10.5281/zenodo.14805610},
	abstract = {What's Changed



🐛 Improve error message for missing javascript and python plugins by @JimMadge in https://github.com/jupyter-book/mystmd/pull/1835

🔗 Add citation for the project by @rowanc1 in https://github.com/jupyter-book/mystmd/pull/1837

✍️ Fix typo in Jupyter Book TOC upgrade routine by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1839

🪟 Fix plugin loading on Windows by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1841

📖 Update to installing instructions to include conda by @mmcky in https://github.com/jupyter-book/mystmd/pull/1840

🚫 Add page frontmatter option to disable execution by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1842

⬆️ Add simple upgrade/downgrade package for MyST AST by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1802

📖 Improve Executable Markdown Documentation by @rowanc1 in https://github.com/jupyter-book/mystmd/pull/1852

📖 Remove warnings by @rowanc1 in https://github.com/jupyter-book/mystmd/pull/1853

🔧 Fix errors about missing images on non-first builds by @fwkoch in https://github.com/jupyter-book/mystmd/pull/1856

📂 Set site.options.folders: true for JB upgrades by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1867

Handle unsupported options for include directive by @JimMadge in https://github.com/jupyter-book/mystmd/pull/1872

💇 Add documentation on site.options.style by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1873

✏️ Use myst directive with proof option definitions by @agoose77 in https://github.com/jupyter-book/mystmd/pull/1881

✨ New table of contents directive by @fwkoch in https://github.com/jupyter-book/mystmd/pull/1826

🚀 Release by @github-actions in https://github.com/jupyter-book/mystmd/pull/1836


New Contributors



@JimMadge made their first contribution in https://github.com/jupyter-book/mystmd/pull/1835

@mmcky made their first contribution in https://github.com/jupyter-book/mystmd/pull/1840


Full Changelog: https://github.com/jupyter-book/mystmd/compare/mystmd@1.3.23...mystmd@1.3.24},
	urldate = {2025-03-31},
	publisher = {Zenodo},
	author = {Rowan Cockett and Franklin Koch and Steve Purves and Angus Hollands and Yuxi Wang and Dylan Grandmont and Chris Holdgraf and Andrea and Jan-Hendrik Müller and Spencer Lyon and Cristian Le and Jim Madge and wwx and Sugan Reden and Yuanhao Geng and Ryan Lovett and Mikkel Roald-Arbøl and Matt McKay and Matthew Brett and M Bussonnier and Mridul Seth and Nicolas M. Thiéry and Raniere Silva and Sarah Brown and Sinan Bekar and Tavin Cole and Thad Guidry and Toby Driscoll},
	month = feb,
	year = {2025},
	doi = {10.5281/ZENODO.14805610},
}

@article{vable_code_2021,
	title = {Code review as a simple trick to enhance reproducibility, accelerate learning, and improve the quality of your team’s research},
	volume = {190},
	issn = {0002-9262},
	url = {https://doi.org/10.1093/aje/kwab092},
	doi = {10.1093/aje/kwab092},
	abstract = {Programming for data wrangling and statistical analysis is an essential technical tool of modern epidemiology, yet many epidemiologists receive limited formal training in strategies to optimize the quality of our code. In complex projects, coding mistakes are easy to make, even for skilled practitioners. Such mistakes can lead to invalid research claims that reduce the credibility of the field. Code review is a straightforward technique used by the software industry to reduce the likelihood of coding bugs. The systematic implementation of code review in epidemiologic research projects could not only improve science but also decrease stress, accelerate learning, contribute to team building, and codify best practices. In the present article, we argue for the importance of code review and provide some recommendations for successful implementation for 1) the research laboratory, 2) the code author (the initial programmer), and 3) the code reviewer. We outline a feasible strategy for implementation of code review, though other successful implementation processes are possible to accommodate the resources and workflows of different research groups, including other practices to improve code quality. Code review isn’t always glamorous, but it is critically important for science and reproducibility. Humans are fallible; that’s why we need code review.},
	number = {10},
	urldate = {2025-04-02},
	journal = {American Journal of Epidemiology},
	author = {Vable, Anusha M and Diehl, Scott F and Glymour, M Maria},
	month = oct,
	year = {2021},
	pages = {2172--2177},
}

@article{ackerman_software_1989,
	title = {Software inspections: an effective verification process},
	volume = {6},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0740-7459},
	shorttitle = {Software inspections},
	url = {http://ieeexplore.ieee.org/document/28121/},
	doi = {10.1109/52.28121},
	number = {3},
	urldate = {2025-04-02},
	journal = {IEEE Software},
	author = {Ackerman, A.F. and Buchwald, L.S. and Lewski, F.H.},
	month = may,
	year = {1989},
	pages = {31--36},
}

@inproceedings{bacchelli_expectations_2013,
	address = {San Francisco, CA, USA},
	series = {{ICSE} '13},
	title = {Expectations, outcomes, and challenges of modern code review},
	isbn = {978-1-4673-3076-3},
	abstract = {Code review is a common software engineering practice employed both in open source and industrial contexts. Review today is less formal and more lightweight than the code inspections performed and studied in the 70s and 80s. We empirically explore the motivations, challenges, and outcomes of tool-based code reviews. We observed, interviewed, and surveyed developers and managers and manually classified hundreds of review comments across diverse teams at Microsoft. Our study reveals that while finding defects remains the main motivation for review, reviews are less about defects than expected and instead provide additional benefits such as knowledge transfer, increased team awareness, and creation of alternative solutions to problems. Moreover, we find that code and change understanding is the key aspect of code reviewing and that developers employ a wide range of mechanisms to meet their understanding needs, most of which are not met by current tools. We provide recommendations for practitioners and researchers.},
	urldate = {2025-04-02},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Bacchelli, Alberto and Bird, Christian},
	month = may,
	year = {2013},
	pages = {712--721},
}

@article{chue_hong_fair_2022,
	title = {{FAIR} {Principles} for {Research} {Software} ({FAIR4RS} {Principles})},
	url = {https://zenodo.org/records/6623556},
	doi = {10.15497/RDA00068},
	abstract = {To improve the sharing and reuse of research software, the FAIR for Research Software (FAIR4RS) Working Group has applied the FAIR Guiding Principles for scientific data management and stewardship to research software, bringing together existing and new community efforts. Many of the FAIR Guiding Principles can be directly applied to research software by treating software and data as similar digital research objects. However, specific characteristics of software — such as its executability, composite nature, and continuous evolution and versioning — make it necessary to revise and extend the principles.


This document presents the first version of the FAIR Principles for Research Software (FAIR4RS Principles), and includes explanatory text to aid adoption. It is an outcome of the FAIR for Research Software Working Group (FAIR4RS WG) based on community consultations that started in 2019.


The FAIR for Research Software Working Group was jointly convened as a Research Data Alliance (RDA) Working Group, FORCE11 Working Group, and Research Software Alliance (ReSA) Task Force.


The RDA Software Source Code Interest Group is the maintenance home for the principles. Concerns or queries about the principles can be raised at RDA plenary events organized by the SSC IG, where there may be opportunities for adopters to report back on progress. The full maintenance and retirement plan for the principles can be found on the RDA website.},
	language = {eng},
	urldate = {2025-04-02},
	author = {Chue Hong, Neil P. and Katz, Daniel S. and Barker, Michelle and Lamprecht, Anna-Lena and Martinez, Carlos and Psomopoulos, Fotis E. and Harrow, Jen and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom and Struck, Alexander and Lee, Allen and Loewe, Axel and van Werkhoven, Ben and Jones, Catherine and Garijo, Daniel and Plomp, Esther and Genova, Francoise and Shanahan, Hugh and Leng, Joanna and Hellström, Maggie and Sandström, Malin and Sinha, Manodeep and Kuzak, Mateusz and Herterich, Patricia and Zhang, Qian and Islam, Sharif and Sansone, Susanna-Assunta and Pollard, Tom and Atmojo, Udayanto Dwi and Williams, Alan and Czerniak, Andreas and Niehues, Anna and Fouilloux, Anne Claire and Desinghu, Bala and Goble, Carole and Richard, Céline and Gray, Charles and Erdmann, Chris and Nüst, Daniel and Tartarini, Daniele and Ranguelova, Elena and Anzt, Hartwig and Todorov, Ilian and McNally, James and Moldon, Javier and Burnett, Jessica and Garrido-Sánchez, Julián and Belhajjame, Khalid and Sesink, Laurents and Hwang, Lorraine and Tovani-Palone, Marcos Roberto and Wilkinson, Mark D. and Servillat, Mathieu and Liffers, Matthias and Fox, Merc and Miljković, Nadica and Lynch, Nick and Martinez Lavanchy, Paula and Gesing, Sandra and Stevens, Sarah and Martinez Cuesta, Sergio and Peroni, Silvio and Soiland-Reyes, Stian and Bakker, Tom and Rabemanantsoa, Tovo and Sochat, Vanessa and Yehudi, Yo and WG, RDA FAIR4RS},
	month = may,
	year = {2022},
	note = {Publisher: Zenodo},
}

@book{wasser_pyopenscipython-package-guide_2024,
	title = {{pyOpenSci}/python-package-guide: {pyOpenSci} packaging guide v0.4},
	shorttitle = {{pyOpenSci}/python-package-guide},
	url = {https://zenodo.org/records/13154979},
	abstract = {What's Changed



Fix: reorganize index structure for users by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/188

Fix: minor edits by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/206

Fix broken stuff 2 (and keep stuff unbroken) by @sneakers-the-rat in https://github.com/pyOpenSci/python-package-guide/pull/205

Use pyproject.toml, remove requirements.txt by @sneakers-the-rat in https://github.com/pyOpenSci/python-package-guide/pull/204

docs: add ctb as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/208

all my requirements gone by @sneakers-the-rat in https://github.com/pyOpenSci/python-package-guide/pull/207

docs: add calekochenour as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/214

Version specification in main text of tutorials/pyproject-toml.md by @sneakers-the-rat in https://github.com/pyOpenSci/python-package-guide/pull/191

Fix: update link to coc by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/216

docs: add miguelalizo as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/219

Fix: Issue 201 - conda-forge tutorial learning objectives by @miguelalizo in https://github.com/pyOpenSci/python-package-guide/pull/218

docs: add nyeshlur as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/231

docs: add Tyler-Bonnell as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/233

docs: add ptressel as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/235

update: hatch tutorial by @ucodery in https://github.com/pyOpenSci/python-package-guide/pull/217

Update installable-code.md by @nyeshlur in https://github.com/pyOpenSci/python-package-guide/pull/230

Update installable-code.md by @nyeshlur in https://github.com/pyOpenSci/python-package-guide/pull/220

Update publish-conda-forge.md to fix tiny typo by @ptressel in https://github.com/pyOpenSci/python-package-guide/pull/225

Update publish-pypi.md to remove near-duplicate line. by @ptressel in https://github.com/pyOpenSci/python-package-guide/pull/223

Update intro.md: Remove Duplicate Link/Sentence by @Tyler-Bonnell in https://github.com/pyOpenSci/python-package-guide/pull/221

Update text to reflect modern Hatch by @ofek in https://github.com/pyOpenSci/python-package-guide/pull/241

Add: text on Hatch backend compatibility by @ucodery in https://github.com/pyOpenSci/python-package-guide/pull/228

More consistent LICENSE and CODE\_OF\_CONDUCT usage by @ptressel in https://github.com/pyOpenSci/python-package-guide/pull/234

Add: changelog-file.md to the Docs-for-Contributors-and-Maintainers section. by @miguelalizo in https://github.com/pyOpenSci/python-package-guide/pull/222

Update publish-pypi.md with consistent usage for "test PyPI". by @ptressel in https://github.com/pyOpenSci/python-package-guide/pull/224

Add: Tutorial for migrating from setup.py to pyproject.toml using Hatch by @miguelalizo in https://github.com/pyOpenSci/python-package-guide/pull/229

Update get-to-know-hatch.md for consistent style of "Hatch" etc. by @ptressel in https://github.com/pyOpenSci/python-package-guide/pull/227

API Documentation Tutorial: Fix a few typos and clean up punctuation by @Tyler-Bonnell in https://github.com/pyOpenSci/python-package-guide/pull/242

Include missed update step pyproject.toml by @Tyler-Bonnell in https://github.com/pyOpenSci/python-package-guide/pull/243

Fix: sphinx warnings by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/246

[pre-commit.ci] pre-commit autoupdate by @pre-commit-ci in https://github.com/pyOpenSci/python-package-guide/pull/245

docs: add ucodery as a contributor for code, review, and 2 more by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/251

literalinclude directives by @ucodery in https://github.com/pyOpenSci/python-package-guide/pull/239

update version from 0.1.0 to 0.1 by @pb-413 in https://github.com/pyOpenSci/python-package-guide/pull/262

docs: add kenseehart as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/283

docs: add ryanskeith as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/284

Update version references in tutorial: 0.1.0 -{\textgreater} 0.1 by @pb-413 in https://github.com/pyOpenSci/python-package-guide/pull/279

docs: add pb-413 as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/285

docs: add sosey as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/286

docs: add BSuperbad as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/288

Add command line example for finding hatch config file location by @sosey in https://github.com/pyOpenSci/python-package-guide/pull/256

Fixing Table of Contents/ Nav by @BSuperbad in https://github.com/pyOpenSci/python-package-guide/pull/266

docs: add chenghlee as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/289

docs: add Vaunty as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/290

Replace usage of "Anaconda Cloud" in various contexts by @chenghlee in https://github.com/pyOpenSci/python-package-guide/pull/269

Update github actions versions to current by @sosey in https://github.com/pyOpenSci/python-package-guide/pull/277

Unique package name - Corrective action steps by @pb-413 in https://github.com/pyOpenSci/python-package-guide/pull/280

use literalinclude in code-style-linting-format by @ucodery in https://github.com/pyOpenSci/python-package-guide/pull/259

Add: hatch plus meson-python python package example to guidebook by @ucodery in https://github.com/pyOpenSci/python-package-guide/pull/274

docs: add flpm as a contributor for review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/291

docs: add zackw as a contributor for review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/292

docs: add sn3hay as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/295

Setup Vale (prose linter) with a minimal unobtrusive configuration by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/281

[pre-commit.ci] pre-commit autoupdate by @pre-commit-ci in https://github.com/pyOpenSci/python-package-guide/pull/294

Change formatting to satisfy codespell check by @willingc in https://github.com/pyOpenSci/python-package-guide/pull/296

Add: help wanted automated workflow to guidebook repo by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/297

Always use python -m with pip by @jhkennedy in https://github.com/pyOpenSci/python-package-guide/pull/300

Update diagram -hatch backends by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/302

docs: add stefanor as a contributor for review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/303

docs: add stefmolin as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/306

Mention that the code of conduct has placeholder values by @stefmolin in https://github.com/pyOpenSci/python-package-guide/pull/305

docs: add WeepingClown13 as a contributor for review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/307

Add support for internationalization to the guide by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/298

Add a translation guide for contributors by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/304

Start spanish translation by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/309

[pre-commit.ci] pre-commit autoupdate by @pre-commit-ci in https://github.com/pyOpenSci/python-package-guide/pull/312

[Tuesday july 2 merge] Fix: update hatch install instructions by @lwasser in https://github.com/pyOpenSci/python-package-guide/pull/308

Structure the CONTRIBUTING guide to define sprint tasks by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/311

Prepare translation files for SciPy sprint by @flpm in https://github.com/pyOpenSci/python-package-guide/pull/314

docs: add choldgraf as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/315

docs: add npch as a contributor for review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/316

update badges url by @sneakers-the-rat in https://github.com/pyOpenSci/python-package-guide/pull/318

docs: add RobPasMue as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/344

docs: add yardasol as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/345

docs: add ayhanxian as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/346

docs: add hpodzorski-USGS as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/347

docs: add ncclementi as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/348

docs: add John-Drake as a contributor for code, and review by @allcontributors in https://github.com/pyOpenSci/python-package-guide/pull/349

Update conf.py to include Code of Conduct link to footer by @ayhanxian in https://github.com/pyOpenSci/python-package-guide/pull/324


New Contributors



@miguelalizo made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/218

@nyeshlur made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/230

@ptressel made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/225

@Tyler-Bonnell made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/221

@ofek made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/241

@pb-413 made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/262

@sosey made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/256

@BSuperbad made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/266

@chenghlee made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/269

@flpm made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/281

@willingc made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/296

@jhkennedy made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/300

@stefmolin made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/305

@ayhanxian made their first contribution in https://github.com/pyOpenSci/python-package-guide/pull/324


Full Changelog: https://github.com/pyOpenSci/python-package-guide/compare/v0.3...v0.4},
	urldate = {2025-04-02},
	publisher = {Zenodo},
	author = {Wasser, Leah and Nicholson, David and Sasso, Ariane and Batisse, Alexandre and Molinsky, Simon and Marmo, Chiara and Fernandes, Filipe and Saunders, Jonny and Willing, Carol and Smith, Trevor James and Mostipak, Jesse and Paige, Jeremy and Murphy, Nick and Broderick, Billy and Zimmerman, Isabel and Beber, Moritz E. and Welch, Erik},
	month = aug,
	year = {2024},
	doi = {10.5281/zenodo.13154979},
	note = {Version Number: v0.4},
	keywords = {data science, science, open peer review, open reproducible science, open source software, Python},
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2025-04-02},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Reproducibility, Computer software, Programming languages, Software tools, Control systems, Data management, Metadata, Source code},
	pages = {e1005510},
}

@article{ma_human_2024,
	title = {The human dimension to clean, distributable, and documented data science code},
	url = {https://ericmjl.github.io/blog/2024/10/25/the-human-dimension-to-clean-distributable-and-documented-data-science-code},
	journal = {Eric J. Ma's Blog},
	author = {Ma, Eric J.},
	month = oct,
	year = {2024},
}

@article{wilson_wheres_2006,
	title = {Where’s the real bottleneck in scientific computing?},
	volume = {94},
	issn = {0003-0996, 1545-2786},
	url = {http://www.americanscientist.org/issues/pub/2006/1/wheres-the-real-bottleneck-in-scientific-computing},
	doi = {10.1511/2006.57.3473},
	abstract = {WHEN I FIRST started doing computational science in 1986, a new generation of fast, cheap chips had just ushered in the airrent era of low-cost supercomputers, in which multiple processors work in parallel on a single problem. Suddenly, it seemed as thougli e{\textbackslash}'eryone who ttx)k number cmnching seriously was rewriting his or her software to take advantage of these new machines. Sure, it hurt—the compilers that translated programs to iTin on parallel computers were flaky, debugging tools were nonexistent, and thinking},
	language = {en},
	number = {1},
	urldate = {2025-04-03},
	journal = {American Scientist},
	author = {Wilson, Gregory},
	year = {2006},
	pages = {5},
}

@article{wilson_best_2014,
	title = {Best practices for scientific computing},
	volume = {12},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745},
	doi = {10.1371/journal.pbio.1001745},
	abstract = {We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.},
	language = {en},
	number = {1},
	urldate = {2025-04-03},
	journal = {PLOS Biology},
	author = {Wilson, Greg and Aruliah, D. A. and Brown, C. Titus and Hong, Neil P. Chue and Davis, Matt and Guy, Richard T. and Haddock, Steven H. D. and Huff, Kathryn D. and Mitchell, Ian M. and Plumbley, Mark D. and Waugh, Ben and White, Ethan P. and Wilson, Paul},
	month = jan,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Open source software, Reproducibility, Computer software, Programming languages, Software development, Scientists, Control systems, Computers},
	pages = {e1001745},
}

@misc{johnson_sciops_2024,
	title = {{SciOps}: {Achieving} productivity and reliability in data-intensive research},
	shorttitle = {{SciOps}},
	url = {http://arxiv.org/abs/2401.00077},
	doi = {10.48550/arXiv.2401.00077},
	abstract = {Scientists are increasingly leveraging advances in instruments, automation, and collaborative tools to scale up their experiments and research goals, leading to new bursts of discovery. Various scientific disciplines, including neuroscience, have adopted key technologies to enhance collaboration, reproducibility, and automation. Drawing inspiration from advancements in the software industry, we present a roadmap to enhance the reliability and scalability of scientific operations for diverse research teams tackling large and complex projects. We introduce a five-level Capability Maturity Model describing the principles of rigorous scientific operations in projects ranging from small-scale exploratory studies to large-scale, multi-disciplinary research endeavors. Achieving higher levels of operational maturity necessitates the adoption of new, technology-enabled methodologies, which we refer to as SciOps. This concept is derived from the DevOps methodologies that have revolutionized the software industry. SciOps involves digital research environments that seamlessly integrate computational, automation, and AI-driven efforts throughout the research cycle-from experimental design and data collection to analysis and dissemination, ultimately leading to closed-loop discovery. This maturity model offers a framework for assessing and improving operational practices in multidisciplinary research teams, guiding them towards greater efficiency and effectiveness in scientific inquiry.},
	urldate = {2025-04-03},
	publisher = {arXiv},
	author = {Johnson, Erik C. and Nguyen, Thinh T. and Dichter, Benjamin K. and Zappulla, Frank and Kosma, Montgomery and Gunalan, Kabilar and Halchenko, Yaroslav O. and Neufeld, Shay Q. and Ratan, Kristen and Edwards, Nicholas J. and Ressl, Susanne and Heilbronner, Sarah R. and Schirner, Michael and Ritter, Petra and Wester, Brock and Ghosh, Satrajit and Martone, Maryann E. and Pestilli, Franco and Yatsenko, Dimitri},
	month = nov,
	year = {2024},
	note = {arXiv:2401.00077 [q-bio]},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Computers and Society},
}

@book{kaner_lessons_2002,
	address = {New York},
	edition = {Online-Ausg},
	title = {Lessons learned in software testing: a context-driven approach},
	isbn = {978-0-471-08112-8 978-1-118-17274-2},
	shorttitle = {Lessons learned in software testing},
	language = {eng},
	publisher = {Wiley},
	author = {Kaner, Cem and Bach, James and Pettichord, Bret},
	year = {2002},
}

@article{storer_bridging_2017,
	title = {Bridging the chasm: {A} survey of software engineering practice in scientific programming},
	volume = {50},
	issn = {0360-0300},
	shorttitle = {Bridging the {Chasm}},
	url = {https://doi.org/10.1145/3084225},
	doi = {10.1145/3084225},
	abstract = {The use of software is pervasive in all fields of science. Associated software development efforts may be very large, long lived, and complex, requiring the commitment of significant resources. However, several authors have argued that the “gap” or “chasm” between software engineering and scientific programming is a serious risk to the production of reliable scientific results, as demonstrated in a number of case studies. This article reviews the research that addresses the gap, exploring how both software engineering and research practice may need to evolve to accommodate the use of software in science.},
	number = {4},
	urldate = {2025-04-03},
	journal = {ACM Comput. Surv.},
	author = {Storer, Tim},
	month = aug,
	year = {2017},
	pages = {47:1--47:32},
}

@misc{eisty_testing_2025,
	title = {Testing research software: {An} in-depth survey of practices, methods, and tools},
	shorttitle = {Testing {Research} {Software}},
	url = {http://arxiv.org/abs/2501.17739},
	doi = {10.48550/arXiv.2501.17739},
	abstract = {Context: Research software is essential for developing advanced tools and models to solve complex research problems and drive innovation across domains. Therefore, it is essential to ensure its correctness. Software testing plays a vital role in this task. However, testing research software is challenging due to the software's complexity and to the unique culture of the research software community. Aims: Building on previous research, this study provides an in-depth investigation of testing practices in research software, focusing on test case design, challenges with expected outputs, use of quality metrics, execution methods, tools, and desired tool features. Additionally, we explore whether demographic factors influence testing processes. Method: We survey research software developers to understand how they design test cases, handle output challenges, use metrics, execute tests, and select tools. Results: Research software testing varies widely. The primary challenges are test case design, evaluating test quality, and evaluating the correctness of test outputs. Overall, research software developers are not familiar with existing testing tools and have a need for new tools to support their specific needs. Conclusion: Allocating human resources to testing and providing developers with knowledge about effective testing techniques are important steps toward improving the testing process of research software. While many industrial testing tools exist, they are inadequate for testing research software due to its complexity, specialized algorithms, continuous updates, and need for flexible, custom testing approaches. Access to a standard set of testing tools that address these special characteristics will increase level of testing in research software development and reduce the overhead of distributing knowledge about software testing.},
	urldate = {2025-04-03},
	publisher = {arXiv},
	author = {Eisty, Nasir U. and Kanewala, Upulee and Carver, Jeffrey C.},
	month = jan,
	year = {2025},
	note = {arXiv:2501.17739 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@article{vliet_seven_2020,
	title = {Seven quick tips for analysis scripts in neuroimaging},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007358},
	doi = {10.1371/journal.pcbi.1007358},
	language = {en},
	number = {3},
	urldate = {2025-04-03},
	journal = {PLOS Computational Biology},
	author = {Vliet, Marijn van},
	month = mar,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Neuroimaging, Computer software, Creativity, Data processing, Data visualization, Habits, Magnetoencephalography, Vision},
	pages = {e1007358},
}

@article{wilkinson_applying_2025,
	title = {Applying the {FAIR} {Principles} to computational workflows},
	volume = {12},
	copyright = {2025 UT-Battelle, LLC and the Authors 2025},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-025-04451-9},
	doi = {10.1038/s41597-025-04451-9},
	abstract = {Recent trends within computational and data sciences show an increasing recognition and adoption of computational workflows as tools for productivity and reproducibility that also democratize access to platforms and processing know-how. As digital objects to be shared, discovered, and reused, computational workflows benefit from the FAIR principles, which stand for Findable, Accessible, Interoperable, and Reusable. The Workflows Community Initiative’s FAIR Workflows Working Group (WCI-FW), a global and open community of researchers and developers working with computational workflows across disciplines and domains, has systematically addressed the application of both FAIR data and software principles to computational workflows. We present recommendations with commentary that reflects our discussions and justifies our choices and adaptations. These are offered to workflow users and authors, workflow management system developers, and providers of workflow services as guidelines for adoption and fodder for discussion. The FAIR recommendations for workflows that we propose in this paper will maximize their value as research assets and facilitate their adoption by the wider community.},
	language = {en},
	number = {1},
	urldate = {2025-04-03},
	journal = {Scientific Data},
	author = {Wilkinson, Sean R. and Aloqalaa, Meznah and Belhajjame, Khalid and Crusoe, Michael R. and de Paula Kinoshita, Bruno and Gadelha, Luiz and Garijo, Daniel and Gustafsson, Ove Johan Ragnar and Juty, Nick and Kanwal, Sehrish and Khan, Farah Zaib and Köster, Johannes and Peters-von Gehlen, Karsten and Pouchard, Line and Rannow, Randy K. and Soiland-Reyes, Stian and Soranzo, Nicola and Sufi, Shoaib and Sun, Ziheng and Vilne, Baiba and Wouters, Merridee A. and Yuen, Denis and Goble, Carole},
	month = feb,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Scientific community, Computational biology and bioinformatics, Mathematics and computing},
	pages = {328},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/T8UERAMS/Wilkinson et al. - 2025 - Applying the FAIR Principles to computational workflows.pdf:application/pdf},
}

@article{morin_quick_2012,
	title = {A quick guide to software licensing for the scientist-programmer},
	volume = {8},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002598},
	doi = {10.1371/journal.pcbi.1002598},
	language = {en},
	number = {7},
	urldate = {2025-04-03},
	journal = {PLOS Computational Biology},
	author = {Morin, Andrew and Urban, Jennifer and Sliz, Piotr},
	month = jul,
	year = {2012},
	note = {Publisher: Public Library of Science},
	keywords = {Open source software, Computer applications, Computer software, Scientists, Software tools, Source code, Peer review, Wildebeest},
	pages = {e1002598},
}

@article{cockett_continuous_2024,
	title = {Continuous tools for scientific publishing},
	issn = {2575-9752},
	url = {https://proceedings.scipy.org/articles/NKVC9349},
	doi = {10.25080/NKVC9349},
	abstract = {Science requires new mediums to compose ideas and ways to share research findings iteratively, as early as possible and connected directly to software and data. In this paper we discuss two tools for scientific authoring and publishing, MyST Markdown and Curvenote, and illustrate examples of improving metadata, reimagining the reading experience, including computational content, and transforming publishing practices for individuals and societies through automation and continuous practices.},
	language = {en},
	urldate = {2025-04-03},
	journal = {scipy},
	author = {Cockett, Rowan and Purves, Steve and Koch, Franklin and Morrison, Mike},
	month = jun,
	year = {2024},
	pages = {121--136},
}

@article{stall_notebooks_2022,
	title = {Notebooks {Now}! {Elevating} notebooks into scholarly publishing.},
	url = {https://zenodo.org/records/6981363},
	doi = {10.5281/zenodo.6981363},
	abstract = {Proposal by the American Geophysical Union (AGU) and the Notebooks Community


The American Geophysical Union (AGU) received Alfred P. Sloan Foundation funding to work with the computational notebooks community to design and implement a publishing workflow for computational notebooks. This effort includes developing pilot solutions that will elevate notebooks as a format in scholarly publishing.


Project website: https://data.agu.org/notebooks-now/},
	language = {eng},
	urldate = {2025-04-03},
	author = {Stall, Shelley and Erdmann, Christopher and Hanson, Brooks and Lyon, Laura and Ricci, Mia and Giampoala, Matthew and Sedora, Brian},
	month = aug,
	year = {2022},
	note = {Publisher: Zenodo},
	keywords = {Computational Notebooks},
}

@misc{richard_mcelreath_science_2020,
	title = {Science as amateur software development},
	url = {https://www.youtube.com/watch?v=zwRdO9_GGhY},
	abstract = {Licenca za priznanje avtorstva Creative Commons (vnovična raba dovoljena)},
	language = {English (US)},
	urldate = {2025-04-04},
	author = {{Richard McElreath}},
	month = sep,
	year = {2020},
}

@misc{barba_reproducibility_2012,
	title = {Reproducibility {PI} {Manifesto}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://figshare.com/articles/presentation/Reproducibility_PI_Manifesto/104539/1},
	doi = {10.6084/M9.FIGSHARE.104539.V1},
	abstract = {Slides for lightning talk at the ICERM workshop on "Reproducibility in Computational and Experimental Mathematics", December 2012. Shared under CC-BY.},
	urldate = {2025-04-04},
	publisher = {figshare},
	author = {Barba, Lorena A.},
	year = {2012},
	note = {Artwork Size: 0 Bytes
Pages: 0 Bytes},
	keywords = {FOS: Computer and information sciences, 80309 Software Engineering, Computational Physics, FOS: Mechanical engineering, Mechanical Engineering},
}

@article{alser_packaging_2024,
	title = {Packaging and containerization of computational methods},
	volume = {19},
	issn = {1754-2189, 1750-2799},
	url = {https://www.nature.com/articles/s41596-024-00986-0},
	doi = {10.1038/s41596-024-00986-0},
	language = {en},
	number = {9},
	urldate = {2025-04-06},
	journal = {Nature Protocols},
	author = {Alser, Mohammed and Lawlor, Brendan and Abdill, Richard J. and Waymost, Sharon and Ayyala, Ram and Rajkumar, Neha and LaPierre, Nathan and Brito, Jaqueline and Ribeiro-dos-Santos, André M. and Almadhoun, Nour and Sarwal, Varuni and Firtina, Can and Osinski, Tomasz and Eskin, Eleazar and Hu, Qiyang and Strong, Derek and Kim, Byoung-Do and Abedalthagafi, Malak S. and Mutlu, Onur and Mangul, Serghei},
	month = sep,
	year = {2024},
	pages = {2529--2539},
}

@book{bain_neuroscience_2020,
	address = {Washington, D.C.},
	title = {Neuroscience {Data} in the {Cloud}: {Opportunities} and {Challenges}: {Proceedings} of a {Workshop}},
	isbn = {978-0-309-67055-5},
	shorttitle = {Neuroscience {Data} in the {Cloud}},
	url = {https://www.nap.edu/catalog/25653},
	urldate = {2025-04-06},
	publisher = {National Academies Press},
	editor = {Bain, Lisa and Gee, Amanda Wagner and Stroud, Clare},
	collaborator = {{Forum on Neuroscience and Nervous System Disorders} and {Board on Health Sciences Policy} and {Health and Medicine Division} and {National Academies of Sciences, Engineering, and Medicine}},
	month = may,
	year = {2020},
	doi = {10.17226/25653},
	keywords = {Health and Medicine--Health Sciences, Health and Medicine--Policy, Reviews and Evaluations},
}

@article{hayashi_brainlifeio_2024,
	title = {brainlife.io: a decentralized and open-source cloud platform to support neuroscience research},
	volume = {21},
	copyright = {2024 The Author(s)},
	issn = {1548-7105},
	shorttitle = {brainlife.io},
	url = {https://www.nature.com/articles/s41592-024-02237-2},
	doi = {10.1038/s41592-024-02237-2},
	abstract = {Neuroscience is advancing standardization and tool development to support rigor and transparency. Consequently, data pipeline complexity has increased, hindering FAIR (findable, accessible, interoperable and reusable) access. brainlife.io was developed to democratize neuroimaging research. The platform provides data standardization, management, visualization and processing and automatically tracks the provenance history of thousands of data objects. Here, brainlife.io is described and evaluated for validity, reliability, reproducibility, replicability and scientific utility using four data modalities and 3,200 participants.},
	language = {en},
	number = {5},
	urldate = {2025-04-06},
	journal = {Nature Methods},
	author = {Hayashi, Soichi and Caron, Bradley A. and Heinsfeld, Anibal Sólon and Vinci-Booher, Sophia and McPherson, Brent and Bullock, Daniel N. and Bertò, Giulia and Niso, Guiomar and Hanekamp, Sandra and Levitas, Daniel and Ray, Kimberly and MacKenzie, Anne and Avesani, Paolo and Kitchell, Lindsey and Leong, Josiah K. and Nascimento-Silva, Filipi and Koudoro, Serge and Willis, Hanna and Jolly, Jasleen K. and Pisner, Derek and Zuidema, Taylor R. and Kurzawski, Jan W. and Mikellidou, Kyriaki and Bussalb, Aurore and Chaumon, Maximilien and George, Nathalie and Rorden, Christopher and Victory, Conner and Bhatia, Dheeraj and Aydogan, Dogu Baran and Yeh, Fang-Cheng F. and Delogu, Franco and Guaje, Javier and Veraart, Jelle and Fischer, Jeremy and Faskowitz, Joshua and Fabrega, Ricardo and Hunt, David and McKee, Shawn and Brown, Shawn T. and Heyman, Stephanie and Iacovella, Vittorio and Mejia, Amanda F. and Marinazzo, Daniele and Craddock, R. Cameron and Olivetti, Emanuale and Hanson, Jamie L. and Garyfallidis, Eleftherios and Stanzione, Dan and Carson, James and Henschel, Robert and Hancock, David Y. and Stewart, Craig A. and Schnyer, David and Eke, Damian O. and Poldrack, Russell A. and Bollmann, Steffen and Stewart, Ashley and Bridge, Holly and Sani, Ilaria and Freiwald, Winrich A. and Puce, Aina and Port, Nicholas L. and Pestilli, Franco},
	month = may,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	pages = {809--813},
}

@article{renton_neurodesk_2024,
	title = {Neurodesk: an accessible, flexible and portable data analysis environment for reproducible neuroimaging},
	volume = {21},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {Neurodesk},
	url = {https://www.nature.com/articles/s41592-023-02145-x},
	doi = {10.1038/s41592-023-02145-x},
	abstract = {Neuroimaging research requires purpose-built analysis software, which is challenging to install and may produce different results across computing environments. The community-oriented, open-source Neurodesk platform (https://www.neurodesk.org/) harnesses a comprehensive and growing suite of neuroimaging software containers. Neurodesk includes a browser-accessible virtual desktop, command-line interface and computational notebook compatibility, allowing for accessible, flexible, portable and fully reproducible neuroimaging analysis on personal workstations, high-performance computers and the cloud.},
	language = {en},
	number = {5},
	urldate = {2025-04-06},
	journal = {Nature Methods},
	author = {Renton, Angela I. and Dao, Thuy T. and Johnstone, Tom and Civier, Oren and Sullivan, Ryan P. and White, David J. and Lyons, Paris and Slade, Benjamin M. and Abbott, David F. and Amos, Toluwani J. and Bollmann, Saskia and Botting, Andy and Campbell, Megan E. J. and Chang, Jeryn and Close, Thomas G. and Dörig, Monika and Eckstein, Korbinian and Egan, Gary F. and Evas, Stefanie and Flandin, Guillaume and Garner, Kelly G. and Garrido, Marta I. and Ghosh, Satrajit S. and Grignard, Martin and Halchenko, Yaroslav O. and Hannan, Anthony J. and Heinsfeld, Anibal S. and Huber, Laurentius and Hughes, Matthew E. and Kaczmarzyk, Jakub R. and Kasper, Lars and Kuhlmann, Levin and Lou, Kexin and Mantilla-Ramos, Yorguin-Jose and Mattingley, Jason B. and Meier, Michael L. and Morris, Jo and Narayanan, Akshaiy and Pestilli, Franco and Puce, Aina and Ribeiro, Fernanda L. and Rogasch, Nigel C. and Rorden, Chris and Schira, Mark M. and Shaw, Thomas B. and Sowman, Paul F. and Spitz, Gershon and Stewart, Ashley W. and Ye, Xincheng and Zhu, Judy D. and Narayanan, Aswin and Bollmann, Steffen},
	month = may,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Technology, Neuroscience, Research management},
	pages = {804--808},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/B3J7IWLZ/Renton et al. - 2024 - Neurodesk an accessible, flexible and portable data analysis environment for reproducible neuroimag.pdf:application/pdf},
}

@article{tenopir_data_2020,
	title = {Data sharing, management, use, and reuse: {Practices} and perceptions of scientists worldwide},
	volume = {15},
	issn = {1932-6203},
	shorttitle = {Data sharing, management, use, and reuse},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229003},
	doi = {10.1371/journal.pone.0229003},
	abstract = {Background With data becoming a centerpiece of modern scientific discovery, data sharing by scientists is now a crucial element of scientific progress. This article aims to provide an in-depth examination of the practices and perceptions of data management, including data storage, data sharing, and data use and reuse by scientists around the world. Methods The Usability and Assessment Working Group of DataONE, an NSF-funded environmental cyberinfrastructure project, distributed a survey to a multinational and multidisciplinary sample of scientific researchers in a two-waves approach in 2017–2018. We focused our analysis on examining the differences across age groups, sub-disciplines of science, and sectors of employment. Findings Most respondents displayed what we describe as high and mediocre risk data practices by storing their data on their personal computer, departmental servers or USB drives. Respondents appeared to be satisfied with short-term storage solutions; however, only half of them are satisfied with available mechanisms for storing data beyond the life of the process. Data sharing and data reuse were viewed positively: over 85\% of respondents admitted they would be willing to share their data with others and said they would use data collected by others if it could be easily accessed. A vast majority of respondents felt that the lack of access to data generated by other researchers or institutions was a major impediment to progress in science at large, yet only about a half thought that it restricted their own ability to answer scientific questions. Although attitudes towards data sharing and data use and reuse are mostly positive, practice does not always support data storage, sharing, and future reuse. Assistance through data managers or data librarians, readily available data repositories for both long-term and short-term storage, and educational programs for both awareness and to help engender good data practices are clearly needed.},
	language = {en},
	number = {3},
	urldate = {2025-04-06},
	journal = {PLOS ONE},
	author = {Tenopir, Carol and Rice, Natalie M. and Allard, Suzie and Baird, Lynn and Borycz, Josh and Christian, Lisa and Grant, Bruce and Olendorf, Robert and Sandusky, Robert J.},
	month = mar,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Scientists, Data management, Metadata, Employment, Librarians, Open data, Psychological attitudes, Surveys},
	pages = {e0229003},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/6KCSV6QK/Tenopir et al. - 2020 - Data sharing, management, use, and reuse Practices and perceptions of scientists worldwide.pdf:application/pdf},
}

@article{berriman_application_2013,
	title = {The application of cloud computing to scientific workflows: a study of cost and performance},
	volume = {371},
	shorttitle = {The application of cloud computing to scientific workflows},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2012.0066},
	doi = {10.1098/rsta.2012.0066},
	abstract = {The current model of transferring data from data centres to desktops for analysis will soon be rendered impractical by the accelerating growth in the volume of science datasets. Processing will instead often take place on high-performance servers co-located with data. Evaluations of how new technologies such as cloud computing would support such a new distributed computing model are urgently needed. Cloud computing is a new way of purchasing computing and storage resources on demand through virtualization technologies. We report here the results of investigations of the applicability of commercial cloud computing to scientific computing, with an emphasis on astronomy, including investigations of what types of applications can be run cheaply and efficiently on the cloud, and an example of an application well suited to the cloud: processing a large dataset to create a new science product.},
	number = {1983},
	urldate = {2025-04-06},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Berriman, G. Bruce and Deelman, Ewa and Juve, Gideon and Rynge, Mats and Vöckler, Jens-S.},
	month = jan,
	year = {2013},
	note = {Publisher: Royal Society},
	keywords = {cloud computing, astronomy, computer architecture, data management, grids},
	pages = {20120066},
}

@article{moreau_containers_2023,
	title = {Containers for computational reproducibility},
	volume = {3},
	copyright = {2023 Springer Nature Limited},
	issn = {2662-8449},
	url = {https://www.nature.com/articles/s43586-023-00236-9},
	doi = {10.1038/s43586-023-00236-9},
	abstract = {The fast-paced development of computational tools has enabled tremendous scientific progress in recent years. However, this rapid surge of technological capability also comes at a cost, as it leads to an increase in the complexity of software environments and potential compatibility issues across systems. Advanced workflows in processing or analysis often require specific software versions and operating systems to run smoothly, and discrepancies across machines and researchers can impede reproducibility and efficient collaboration. As a result, scientific teams are increasingly relying on containers to implement robust, dependable research ecosystems. Originally popularized in software engineering, containers have become common in scientific projects, particularly in large collaborative efforts. In this Primer, we describe what containers are, how they work and the rationale for their use in scientific projects. We review state-of-the-art implementations in diverse contexts and fields, with examples in various scientific fields. Finally, we discuss the possibilities enabled by the widespread adoption of containerization, especially in the context of open and reproducible research, and propose recommendations to facilitate seamless implementation across platforms and domains, including within high-performance computing clusters such as those typically available at universities and research institutes.},
	language = {en},
	number = {1},
	urldate = {2025-04-06},
	journal = {Nature Reviews Methods Primers},
	author = {Moreau, David and Wiebels, Kristina and Boettiger, Carl},
	month = jul,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Software, Research management},
	pages = {1--16},
}

@misc{jansen_codescientist_2025,
	title = {{CodeScientist}: {End}-to-end semi-automated scientific discovery with code-based experimentation},
	shorttitle = {{CodeScientist}},
	url = {http://arxiv.org/abs/2503.22708},
	doi = {10.48550/arXiv.2503.22708},
	abstract = {Despite the surge of interest in autonomous scientific discovery (ASD) of software artifacts (e.g., improved ML algorithms), current ASD systems face two key limitations: (1) they largely explore variants of existing codebases or similarly constrained design spaces, and (2) they produce large volumes of research artifacts (such as automatically generated papers and code) that are typically evaluated using conference-style paper review with limited evaluation of code. In this work we introduce CodeScientist, a novel ASD system that frames ideation and experiment construction as a form of genetic search jointly over combinations of research articles and codeblocks defining common actions in a domain (like prompting a language model). We use this paradigm to conduct hundreds of automated experiments on machine-generated ideas broadly in the domain of agents and virtual environments, with the system returning 19 discoveries, 6 of which were judged as being both at least minimally sound and incrementally novel after a multi-faceted evaluation beyond that typically conducted in prior work, including external (conference-style) review, code review, and replication attempts. Moreover, the discoveries span new tasks, agents, metrics, and data, suggesting a qualitative shift from benchmark optimization to broader discoveries.},
	urldate = {2025-04-06},
	publisher = {arXiv},
	author = {Jansen, Peter and Tafjord, Oyvind and Radensky, Marissa and Siangliulue, Pao and Hope, Tom and Mishra, Bhavana Dalvi and Majumder, Bodhisattwa Prasad and Weld, Daniel S. and Clark, Peter},
	month = mar,
	year = {2025},
	note = {arXiv:2503.22708 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/Users/kriarm/Zotero/storage/KHD6T8D3/Jansen et al. - 2025 - CodeScientist End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/7CMIWHAE/2503.html:text/html},
}

@article{charness_next_2025,
	title = {The next generation of experimental research with {LLMs}},
	copyright = {2025 Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-025-02137-1},
	doi = {10.1038/s41562-025-02137-1},
	abstract = {Large language models (LLMs) can enhance experimental research via the design and implementation of studies, and data analysis. When available, we suggest using LLM-based tools that require no coding skills and only a simple human–AI interaction. We discuss the social risks associated with this integration.},
	language = {en},
	urldate = {2025-04-06},
	journal = {Nature Human Behaviour},
	author = {Charness, Gary and Jabarian, Brian and List, John A.},
	month = mar,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Social sciences, Economics},
	pages = {1--3},
}

@article{lin_why_2023,
	title = {Why and how to embrace {AI} such as {ChatGPT} in your academic life},
	volume = {10},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.230658},
	doi = {10.1098/rsos.230658},
	abstract = {Generative artificial intelligence (AI), including large language models (LLMs), is poised to transform scientific research, enabling researchers to elevate their research productivity. This article presents a how-to guide for employing LLMs in academic settings, focusing on their unique strengths, constraints and implications through the lens of philosophy of science and epistemology. Using ChatGPT as a case study, I identify and elaborate on three attributes contributing to its effectiveness—intelligence, versatility and collaboration—accompanied by tips on crafting effective prompts, practical use cases and a living resource online (https://osf.io/8vpwu/). Next, I evaluate the limitations of generative AI and its implications for ethical use, equality and education. Regarding ethical and responsible use, I argue from technical and epistemic standpoints that there is no need to restrict the scope or nature of AI assistance, provided that its use is transparently disclosed. A pressing challenge, however, lies in detecting fake research, which can be mitigated by embracing open science practices, such as transparent peer review and sharing data, code and materials. Addressing equality, I contend that while generative AI may promote equality for some, it may simultaneously exacerbate disparities for others—an issue with potentially significant yet unclear ramifications as it unfolds. Lastly, I consider the implications for education, advocating for active engagement with LLMs and cultivating students' critical thinking and analytical skills. The how-to guide seeks to empower researchers with the knowledge and resources necessary to effectively harness generative AI while navigating the complex ethical dilemmas intrinsic to its application.},
	number = {8},
	urldate = {2025-04-06},
	journal = {Royal Society Open Science},
	author = {Lin, Zhicheng},
	month = aug,
	year = {2023},
	note = {Publisher: Royal Society},
	keywords = {open science, ethics, artificial intelligence, productivity, large language models, ChatGPT/bard},
	pages = {230658},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/PL35YSVD/Lin - 2023 - Why and how to embrace AI such as ChatGPT in your academic life.pdf:application/pdf},
}

@article{birhane_science_2023,
	title = {Science in the age of large language models},
	volume = {5},
	copyright = {2023 Springer Nature Limited},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-023-00581-4},
	doi = {10.1038/s42254-023-00581-4},
	abstract = {Rapid advances in the capabilities of large language models and the broad accessibility of tools powered by this technology have led to both excitement and concern regarding their use in science. Four experts in artificial intelligence ethics and policy discuss potential risks and call for careful consideration and responsible usage to ensure that good scientific practices and trust in science are not compromised.},
	language = {en},
	number = {5},
	urldate = {2025-04-06},
	journal = {Nature Reviews Physics},
	author = {Birhane, Abeba and Kasirzadeh, Atoosa and Leslie, David and Wachter, Sandra},
	month = may,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Physics},
	pages = {277--280},
}

@article{markiewicz_openneuro_2021,
	title = {The {OpenNeuro} resource for sharing of neuroscience data},
	volume = {10},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/71774},
	doi = {10.7554/eLife.71774},
	abstract = {The sharing of research data is essential to ensure reproducibility and maximize the impact of public investments in scientific research. Here, we describe OpenNeuro, a BRAIN Initiative data archive that provides the ability to openly share data from a broad range of brain imaging data types following the FAIR principles for data sharing. We highlight the importance of the Brain Imaging Data Structure standard for enabling effective curation, sharing, and reuse of data. The archive presently shares more than 600 datasets including data from more than 20,000 participants, comprising multiple species and measurement modalities and a broad range of phenotypes. The impact of the shared data is evident in a growing number of published reuses, currently totalling more than 150 publications. We conclude by describing plans for future development and integration with other ongoing open science efforts.},
	language = {en},
	urldate = {2025-04-06},
	journal = {eLife},
	author = {Markiewicz, Christopher J and Gorgolewski, Krzysztof J and Feingold, Franklin and Blair, Ross and Halchenko, Yaroslav O and Miller, Eric and Hardcastle, Nell and Wexler, Joe and Esteban, Oscar and Goncavles, Mathias and Jwa, Anita and Poldrack, Russell},
	month = oct,
	year = {2021},
	pages = {e71774},
}

@article{jwa_spectrum_2022,
	title = {The spectrum of data sharing policies in neuroimaging data repositories},
	volume = {43},
	copyright = {© 2022 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25803},
	doi = {10.1002/hbm.25803},
	abstract = {Sharing data is a scientific imperative that accelerates scientific discoveries, reinforces open science inquiry, and allows for efficient use of public investment and research resources. Considering these benefits, data sharing has been widely promoted in diverse fields and neuroscience has been no exception to this movement. For all its promise, however, the sharing of human neuroimaging data raises critical ethical and legal issues, such as data privacy. Recently, the heightened risks to data privacy posed by the rapid advances in artificial intelligence and machine learning techniques have made data sharing more challenging; the regulatory landscape around data sharing has also been evolving rapidly. Here we present an in-depth ethical and regulatory analysis that examines how neuroimaging data are currently shared against the backdrop of the relevant regulations and policies in the United States and how advanced software tools and algorithms might undermine subjects' privacy in neuroimaging data sharing. The implications of these novel technological threats to privacy in neuroimaging data sharing practices and policies will also be discussed. We then conclude with a proposal for a legal prohibition against malicious use of neuroscience data as a regulatory mechanism to address privacy risks associated with the data while maximizing the benefits of data sharing and open science practice in the field of neuroscience.},
	language = {en},
	number = {8},
	urldate = {2025-04-07},
	journal = {Human Brain Mapping},
	author = {Jwa, Anita S. and Poldrack, Russell A.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25803},
	keywords = {neuroimaging, data sharing, data privacy, data re-identification, data use agreement, neuroethics},
	pages = {2707--2721},
}

@misc{karakuzu_neurolibre_2022,
	title = {{NeuroLibre} : {A} preprint server for full-fledged reproducible neuroscience},
	shorttitle = {{NeuroLibre}},
	url = {https://osf.io/h89js_v1},
	doi = {10.31219/osf.io/h89js},
	abstract = {NeuroLibre is a preprint server for neuroscience Jupyter Books, blending code, visualization and narrative text into one document. NeuroLibre archives the environment, code and data and also implements a technical review to ensure readers can reproduce the work. NeuroLibre offers an online platform where readers can reproduce or modify each preprint from a web browser, without any installation required. We hope that NeuroLibre will contribute to usher the research community in a new area of open and reproducible neuroscience. The preprint server is built with open source components, and can be freely adapted to meet the needs of other communities in the future as well.},
	language = {en-us},
	urldate = {2025-04-07},
	publisher = {OSF},
	author = {Karakuzu, Agah and DuPre, Elizabeth and Tetrel, Loic and Bermudez, Patrick and Boudreau, Mathieu and Chin, Mary and Poline, Jean-Baptiste and Das, Samir and Bellec, Lune and Stikov, Nikola},
	month = apr,
	year = {2022},
	keywords = {Reproducibility, Publishing, Open Science, Communication},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: {Fundamental} {Algorithms} for {Scientific} {Computing} in {Python}},
	volume = {17},
	doi = {10.1038/s41592-019-0686-2},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul and {SciPy 1.0 Contributors}},
	year = {2020},
	pages = {261--272},
}

@misc{the_pandas_development_team_pandas-devpandas_2024,
	title = {pandas-dev/pandas: {Pandas}},
	shorttitle = {pandas-dev/pandas},
	url = {https://zenodo.org/records/10957263},
	abstract = {Pandas is a powerful data structures for data analysis, time series, and statistics.},
	urldate = {2025-04-07},
	publisher = {Zenodo},
	author = {The Pandas Development Team,},
	month = apr,
	year = {2024},
	doi = {10.5281/zenodo.10957263},
	keywords = {data science, python},
	file = {Snapshot:/Users/kriarm/Zotero/storage/35Z7CMRL/10957263.html:text/html},
}

@inproceedings{mckinney_data_2010,
	title = {Data structures for statistical computing in {Python}},
	doi = {10.25080/Majora-92bf1922-00a},
	booktitle = {Proceedings of the 9th {Python} in {Science} {Conference}},
	author = {McKinney, Wes},
	editor = {Walt, Stéfan van der and Millman, Jarrod},
	year = {2010},
	pages = {56 -- 61},
}

@article{hunter_matplotlib_2007,
	title = {Matplotlib: {A} {2D} graphics environment},
	volume = {9},
	doi = {10.1109/MCSE.2007.55},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
	number = {3},
	journal = {Computing in Science \& Engineering},
	author = {Hunter, J. D.},
	year = {2007},
	note = {Publisher: IEEE COMPUTER SOC},
	pages = {90--95},
}

@misc{the_matplotlib_development_team_matplotlib_2024,
	title = {Matplotlib: {Visualization} with {Python}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Matplotlib},
	url = {https://zenodo.org/doi/10.5281/zenodo.13308876},
	abstract = {This is the second bugfix release of the 3.9.x series.

This release contains several bug-fixes and adjustments:



Be more resilient to I/O failures when writing font cache

Fix nondeterministic behavior with subplot spacing and constrained layout

Fix sticky edge tolerance relative to data range

Improve formatting of image values in cases of singular norms


Windows wheels now bundle the MSVC runtime DLL statically to avoid inconsistencies with other wheels and random crashes depending on import order.},
	urldate = {2025-04-07},
	publisher = {Zenodo},
	author = {The Matplotlib Development Team,},
	month = aug,
	year = {2024},
	doi = {10.5281/ZENODO.13308876},
}

@article{gao_pycortex_2015,
	title = {Pycortex: an interactive surface visualizer for {fMRI}},
	volume = {9},
	issn = {1662-5196},
	shorttitle = {Pycortex},
	url = {http://journal.frontiersin.org/Article/10.3389/fninf.2015.00023/abstract},
	doi = {10.3389/fninf.2015.00023},
	urldate = {2025-04-07},
	journal = {Frontiers in Neuroinformatics},
	author = {Gao, James S. and Huth, Alexander G. and Lescroart, Mark D. and Gallant, Jack L.},
	month = sep,
	year = {2015},
	file = {Full Text:/Users/kriarm/Zotero/storage/AH4X8TWH/Gao et al. - 2015 - Pycortex an interactive surface visualizer for fMRI.pdf:application/pdf},
}

@article{waskom_seaborn_2021,
	title = {seaborn: statistical data visualization},
	volume = {6},
	url = {https://doi.org/10.21105/joss.03021},
	doi = {10.21105/joss.03021},
	number = {60},
	journal = {Journal of Open Source Software},
	author = {Waskom, Michael L.},
	year = {2021},
	note = {Publisher: The Open Journal},
	pages = {3021},
}

@article{harris_array_2020,
	title = {Array programming with {NumPy}},
	volume = {585},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2649-2},
	doi = {10.1038/s41586-020-2649-2},
	abstract = {Abstract
            
              Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves
              1
              and in the first imaging of a black hole
              2
              . Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
	language = {en},
	number = {7825},
	urldate = {2025-04-07},
	journal = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and Van Der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and Van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and Del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	month = sep,
	year = {2020},
	pages = {357--362},
	file = {Full Text:/Users/kriarm/Zotero/storage/79YVHD3U/Harris et al. - 2020 - Array programming with NumPy.pdf:application/pdf},
}

@article{botvinik-nezer_reproducibility_2023,
	series = {Reliability of {Neurocognitive} {Measures} for {Mental} {Health}},
	title = {Reproducibility in neuroimaging analysis: {Challenges} and solutions},
	volume = {8},
	issn = {2451-9022},
	shorttitle = {Reproducibility in {Neuroimaging} {Analysis}},
	url = {https://www.sciencedirect.com/science/article/pii/S245190222200341X},
	doi = {10.1016/j.bpsc.2022.12.006},
	abstract = {Recent years have marked a renaissance in efforts to increase research reproducibility in psychology, neuroscience, and related fields. Reproducibility is the cornerstone of a solid foundation of fundamental research—one that will support new theories built on valid findings and technological innovation that works. The increased focus on reproducibility has made the barriers to it increasingly apparent, along with the development of new tools and practices to overcome these barriers. Here, we review challenges, solutions, and emerging best practices with a particular emphasis on neuroimaging studies. We distinguish 3 main types of reproducibility, discussing each in turn. Analytical reproducibility is the ability to reproduce findings using the same data and methods. Replicability is the ability to find an effect in new datasets, using the same or similar methods. Finally, robustness to analytical variability refers to the ability to identify a finding consistently across variation in methods. The incorporation of these tools and practices will result in more reproducible, replicable, and robust psychological and brain research and a stronger scientific foundation across fields of inquiry.},
	number = {8},
	urldate = {2025-04-07},
	journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	author = {Botvinik-Nezer, Rotem and Wager, Tor D.},
	month = aug,
	year = {2023},
	keywords = {Reproducibility, Neuroimaging, Mental health, Open science, Replicability, Robustness},
	pages = {780--788},
}

@article{poldrack_scanning_2017,
	title = {Scanning the horizon: towards transparent and reproducible neuroimaging research},
	volume = {18},
	copyright = {2017 Springer Nature Limited},
	issn = {1471-0048},
	shorttitle = {Scanning the horizon},
	url = {https://www.nature.com/articles/nrn.2016.167},
	doi = {10.1038/nrn.2016.167},
	abstract = {There is growing concern about the reproducibility of scientific research, and neuroimaging research suffers from many features that are thought to lead to high levels of false results.Statistical power of neuroimaging studies has increased over time but remains relatively low, especially for group comparison studies. An analysis of effect sizes in the Human Connectome Project demonstrates that most functional MRI studies are not sufficiently powered to find reasonable effect sizes.Neuroimaging analysis has a high degree of flexibility in analysis methods, which can lead to inflated false-positive rates unless controlled for. Pre-registration of analysis plans and clear delineation of hypothesis-driven and exploratory research are potential solutions to this problem.The use of appropriate corrections for multiple tests has increased, but some common methods can have highly inflated false-positive rates. The use of non-parametric methods is encouraged to provide accurate correction for multiple tests.Software errors have the potential to lead to incorrect or irreproducible results. The adoption of improved software engineering methods and software testing strategies can help to reduce such problems.Reproducibility will be improved through greater transparency in methods reporting and through increased sharing of data and code.},
	language = {en},
	number = {2},
	urldate = {2025-04-07},
	journal = {Nature Reviews Neuroscience},
	author = {Poldrack, Russell A. and Baker, Chris I. and Durnez, Joke and Gorgolewski, Krzysztof J. and Matthews, Paul M. and Munafò, Marcus R. and Nichols, Thomas E. and Poline, Jean-Baptiste and Vul, Edward and Yarkoni, Tal},
	month = feb,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Functional magnetic resonance imaging, Neuroscience, Data processing, Magnetic resonance imaging, Research data},
	pages = {115--126},
}

@article{de_vries_sharing_2023,
	title = {Sharing neurophysiology data from the {Allen} {Brain} {Observatory}},
	volume = {12},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.85550},
	doi = {10.7554/eLife.85550},
	abstract = {Nullius in verba (‘trust no one’), chosen as the motto of the Royal Society in 1660, implies that independently verifiable observations—rather than authoritative claims—are a defining feature of empirical science. As the complexity of modern scientific instrumentation has made exact replications prohibitive, sharing data is now essential for ensuring the trustworthiness of one’s findings. While embraced in spirit by many, in practice open data sharing remains the exception in contemporary systems neuroscience. Here, we take stock of the Allen Brain Observatory, an effort to share data and metadata associated with surveys of neuronal activity in the visual system of laboratory mice. Data from these surveys have been used to produce new discoveries, to validate computational algorithms, and as a benchmark for comparison with other data, resulting in over 100 publications and preprints to date. We distill some of the lessons learned about open surveys and data reuse, including remaining barriers to data sharing and what might be done to address these.},
	urldate = {2025-04-07},
	journal = {eLife},
	author = {de Vries, Saskia EJ and Siegle, Joshua H and Koch, Christof},
	editor = {Meister, Markus and Gold, Joshua I and Meister, Markus and Chen, Jerry L},
	month = jul,
	year = {2023},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {open science, electrophysiology, data sharing, neurophysiology, two photon calcium imaging},
	pages = {e85550},
}

@misc{poldrack_ai-assisted_2023,
	title = {{AI}-assisted coding: {Experiments} with {GPT}-4},
	shorttitle = {{AI}-assisted coding},
	url = {http://arxiv.org/abs/2304.13187},
	doi = {10.48550/arXiv.2304.13187},
	abstract = {Artificial intelligence (AI) tools based on large language models have acheived human-level performance on some computer programming tasks. We report several experiments using GPT-4 to generate computer code. These experiments demonstrate that AI code generation using the current generation of tools, while powerful, requires substantial human validation to ensure accurate performance. We also demonstrate that GPT-4 refactoring of existing code can significantly improve that code along several established metrics for code quality, and we show that GPT-4 can generate tests with substantial coverage, but that many of the tests fail when applied to the associated code. These findings suggest that while AI coding tools are very powerful, they still require humans in the loop to ensure validity and accuracy of the results.},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Poldrack, Russell A. and Lu, Thomas and Beguš, Gašper},
	month = apr,
	year = {2023},
	note = {arXiv:2304.13187 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/kriarm/Zotero/storage/3CSWMQZX/Poldrack et al. - 2023 - AI-assisted coding Experiments with GPT-4.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/JF7HFUDP/2304.html:text/html},
}

@misc{duque_leveraging_2023,
	title = {Leveraging {Large} {Language} {Models} to {Build} and {Execute} {Computational} {Workflows}},
	url = {http://arxiv.org/abs/2312.07711},
	doi = {10.48550/arXiv.2312.07711},
	abstract = {The recent development of large language models (LLMs) with multi-billion parameters, coupled with the creation of user-friendly application programming interfaces (APIs), has paved the way for automatically generating and executing code in response to straightforward human queries. This paper explores how these emerging capabilities can be harnessed to facilitate complex scientific workflows, eliminating the need for traditional coding methods. We present initial findings from our attempt to integrate Phyloflow with OpenAI's function-calling API, and outline a strategy for developing a comprehensive workflow management system based on these concepts.},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Duque, Alejandro and Syed, Abdullah and Day, Kastan V. and Berry, Matthew J. and Katz, Daniel S. and Kindratenko, Volodymyr V.},
	month = dec,
	year = {2023},
	note = {arXiv:2312.07711 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/Users/kriarm/Zotero/storage/SX73XXN6/Duque et al. - 2023 - Leveraging Large Language Models to Build and Execute Computational Workflows.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/EAIQMEAK/2312.html:text/html},
}

@article{binz_how_2025,
	title = {How should the advancement of large language models affect the practice of science?},
	volume = {122},
	url = {https://www.pnas.org/doi/10.1073/pnas.2401227121},
	doi = {10.1073/pnas.2401227121},
	abstract = {Large language models (LLMs) are being increasingly incorporated into scientific workflows. However, we have yet to fully grasp the implications of this integration. How should the advancement of large language models affect the practice of science? For this opinion piece, we have invited four diverse groups of scientists to reflect on this query, sharing their perspectives and engaging in debate. Schulz et al. make the argument that working with LLMs is not fundamentally different from working with human collaborators, while Bender et al. argue that LLMs are often misused and overhyped, and that their limitations warrant a focus on more specialized, easily interpretable tools. Marelli et al. emphasize the importance of transparent attribution and responsible use of LLMs. Finally, Botvinick and Gershman advocate that humans should retain responsibility for determining the scientific roadmap. To facilitate the discussion, the four perspectives are complemented with a response from each group. By putting these different perspectives in conversation, we aim to bring attention to important considerations within the academic community regarding the adoption of LLMs and their impact on both current and future scientific practices.},
	number = {5},
	urldate = {2025-04-07},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Binz, Marcel and Alaniz, Stephan and Roskies, Adina and Aczel, Balazs and Bergstrom, Carl T. and Allen, Colin and Schad, Daniel and Wulff, Dirk and West, Jevin D. and Zhang, Qiong and Shiffrin, Richard M. and Gershman, Samuel J. and Popov, Vencislav and Bender, Emily M. and Marelli, Marco and Botvinick, Matthew M. and Akata, Zeynep and Schulz, Eric},
	month = feb,
	year = {2025},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2401227121},
}

@misc{krishna_importing_2025,
	title = {Importing {Phantoms}: {Measuring} {LLM} {Package} {Hallucination} {Vulnerabilities}},
	shorttitle = {Importing {Phantoms}},
	url = {http://arxiv.org/abs/2501.19012},
	doi = {10.48550/arXiv.2501.19012},
	abstract = {Large Language Models (LLMs) have become an essential tool in the programmer's toolkit, but their tendency to hallucinate code can be used by malicious actors to introduce vulnerabilities to broad swathes of the software supply chain. In this work, we analyze package hallucination behaviour in LLMs across popular programming languages examining both existing package references and fictional dependencies. By analyzing this package hallucination behaviour we find potential attacks and suggest defensive strategies to defend against these attacks. We discover that package hallucination rate is predicated not only on model choice, but also programming language, model size, and specificity of the coding task request. The Pareto optimality boundary between code generation performance and package hallucination is sparsely populated, suggesting that coding models are not being optimized for secure code. Additionally, we find an inverse correlation between package hallucination rate and the HumanEval coding benchmark, offering a heuristic for evaluating the propensity of a model to hallucinate packages. Our metrics, findings and analyses provide a base for future models, securing AI-assisted software development workflows against package supply chain attacks.},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Krishna, Arjun and Galinkin, Erick and Derczynski, Leon and Martin, Jeffrey},
	month = jan,
	year = {2025},
	note = {arXiv:2501.19012 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{choudhury_promise_2025,
	title = {The promise and pitfalls of generative {AI}},
	volume = {4},
	issn = {2731-0574},
	url = {https://www.nature.com/articles/s44159-024-00402-0},
	doi = {10.1038/s44159-024-00402-0},
	language = {en},
	number = {2},
	urldate = {2025-04-07},
	journal = {Nature Reviews Psychology},
	author = {Choudhury, Monojit and Elyoseph, Zohar and Fast, Nathanael J. and Ong, Desmond C. and Nsoesie, Elaine O. and Pavlick, Ellie},
	month = jan,
	year = {2025},
	pages = {75--80},
}

@article{shumailov_ai_2024,
	title = {{AI} models collapse when trained on recursively generated data},
	volume = {631},
	copyright = {2024 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-024-07566-y},
	doi = {10.1038/s41586-024-07566-y},
	abstract = {Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-\{n\} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.},
	language = {en},
	number = {8022},
	urldate = {2025-04-07},
	journal = {Nature},
	author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
	month = jul,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science},
	pages = {755--759},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/928AQNRE/Shumailov et al. - 2024 - AI models collapse when trained on recursively generated data.pdf:application/pdf},
}

@article{li_language_2022,
	title = {Language models: past, present, and future},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	shorttitle = {Language models},
	url = {https://dl.acm.org/doi/10.1145/3490443},
	doi = {10.1145/3490443},
	abstract = {A language modeling overview, highlighting basic concepts, intuitive explanations, technical achievements, and fundamental challenges.},
	language = {en},
	number = {7},
	urldate = {2025-04-07},
	journal = {Communications of the ACM},
	author = {Li, Hang},
	month = jul,
	year = {2022},
	pages = {56--63},
}

@misc{bommasani_opportunities_2022,
	title = {On the opportunities and risks of foundation models},
	url = {http://arxiv.org/abs/2108.07258},
	doi = {10.48550/arXiv.2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and Arx, Sydney von and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/kriarm/Zotero/storage/4U9YMFAX/Bommasani et al. - 2022 - On the Opportunities and Risks of Foundation Models.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/KKBNE75Z/2108.html:text/html},
}

@article{dupre_future_2024,
	title = {The future of data analysis is now: {Integrating} generative {AI} in neuroimaging methods development},
	volume = {2},
	issn = {2837-6056},
	shorttitle = {The future of data analysis is now},
	url = {https://doi.org/10.1162/imag_a_00241},
	doi = {10.1162/imag_a_00241},
	abstract = {In this perspective, we highlight how emerging artificial intelligence tools are likely to impact the experiences of researchers conducting computational fMRI analyses. While calls for the automatization of statistical procedures date back at least to the inception of “data science” as a field, generative artificial intelligence offers new opportunities to advance field practice. We highlight how these tools are poised to impact both new neuroimaging methods development in areas such as image quality control and in day-to-day practice when generating analysis code. We argue that considering generative artificial intelligence as a catalyst for computational neuroscience—rather than as unique tools in their own right—can substantially improve its positioning in the research ecosystem. In particular, we argue that generative artificial intelligence will reinforce the importance of existing open science initiatives, rather than supplanting them. Overall, we call for clearer metrics by which neuroimaging results—whether generated by individual research teams or by generative artificial intelligence technologies—can be meaningfully compared.},
	urldate = {2025-04-07},
	journal = {Imaging Neuroscience},
	author = {DuPre, Elizabeth and Poldrack, Russell Alan},
	month = jul,
	year = {2024},
	pages = {1--8},
	file = {Full Text PDF:/Users/kriarm/Zotero/storage/GCF38DSW/DuPre and Poldrack - 2024 - The future of data analysis is now Integrating generative AI in neuroimaging methods development.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/896LD5D8/The-future-of-data-analysis-is-now-Integrating.html:text/html},
}

@article{boynton_linear_1996,
	title = {Linear systems analysis of functional magnetic resonance imaging in human {V1}},
	volume = {16},
	copyright = {https://creativecommons.org/licenses/by-nc-sa/4.0/},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.16-13-04207.1996},
	doi = {10.1523/JNEUROSCI.16-13-04207.1996},
	abstract = {The linear transform model of functional magnetic resonance imaging (fMRI) hypothesizes that fMRI responses are proportional to local average neural activity averaged over a period of time. This work reports results from three empirical tests that support this hypothesis. First, fMRI responses in human primary visual cortex (V1) depend separably on stimulus timing and stimulus contrast. Second, responses to long-duration stimuli can be predicted from responses to shorter duration stimuli. Third, the noise in the fMRI data is independent of stimulus contrast and temporal period. Although these tests can not prove the correctness of the linear transform model, they might have been used to reject the model. Because the linear transform model is consistent with our data, we proceeded to estimate the temporal fMRI impulse–response function and the underlying (presumably neural) contrast–response function of human V1.},
	language = {en},
	number = {13},
	urldate = {2025-04-07},
	journal = {The Journal of Neuroscience},
	author = {Boynton, Geoffrey M. and Engel, Stephen A. and Glover, Gary H. and Heeger, David J.},
	month = jul,
	year = {1996},
	pages = {4207--4221},
}

@misc{nguyen_are_2025,
	title = {Are the majority of public computational notebooks pathologically non-executable?},
	url = {http://arxiv.org/abs/2502.04184},
	doi = {10.48550/arXiv.2502.04184},
	abstract = {Computational notebooks are the de facto platforms for exploratory data science, offering an interactive programming environment where users can create, modify, and execute code cells in any sequence. However, this flexibility often introduces code quality issues, with prior studies showing that approximately 76\% of public notebooks are non-executable, raising significant concerns about reusability. We argue that the traditional notion of executability - requiring a notebook to run fully and without error - is overly rigid, misclassifying many notebooks and overestimating their non-executability. This paper investigates pathological executability issues in public notebooks under varying notions and degrees of executability. Even partially improving executability can improve code comprehension and offer a pathway for dynamic analyses. With this insight, we first categorize notebooks into potentially restorable and pathological non-executable notebooks and then measure how removing misconfiguration and superficial execution issues in notebooks can improve their executability (i.e., additional cells executed without error). In a dataset of 42,546 popular public notebooks containing 34,659 non-executable notebooks, only 21.3\% are truly pathologically non-executable. For restorable notebooks, LLM-based methods fully restore 5.4\% of previously non-executable notebooks. Among the partially restored, the executability of notebooks improves by 42.7\% and 28\% by installing the correct modules and generating synthetic data. These findings challenge prior assumptions, suggesting that notebooks have higher executability than previously reported, many of which offer valuable partial execution, and that their executability should be evaluated within the interactive notebook paradigm rather than through traditional software executability standards.},
	urldate = {2025-04-08},
	publisher = {arXiv},
	author = {Nguyen, Tien and Gill, Waris and Gulzar, Muhammad Ali},
	month = feb,
	year = {2025},
	note = {arXiv:2502.04184 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/kriarm/Zotero/storage/7V8ENKPY/Nguyen et al. - 2025 - Are the Majority of Public Computational Notebooks Pathologically Non-Executable.pdf:application/pdf;Snapshot:/Users/kriarm/Zotero/storage/C3QPIJQQ/2502.html:text/html},
}

@inproceedings{pimentel_large-scale_2019,
	title = {A large-scale study about quality and reproducibility of jupyter notebooks},
	url = {https://ieeexplore.ieee.org/document/8816763},
	doi = {10.1109/MSR.2019.00077},
	abstract = {Jupyter Notebooks have been widely adopted by many different communities, both in science and industry. They support the creation of literate programming documents that combine code, text, and execution results with visualizations and all sorts of rich media. The self-documenting aspects and the ability to reproduce results have been touted as significant benefits of notebooks. At the same time, there has been growing criticism that the way notebooks are being used leads to unexpected behavior, encourage poor coding practices, and that their results can be hard to reproduce. To understand good and bad practices used in the development of real notebooks, we studied 1.4 million notebooks from GitHub. We present a detailed analysis of their characteristics that impact reproducibility. We also propose a set of best practices that can improve the rate of reproducibility and discuss open challenges that require further research and development.},
	urldate = {2025-04-08},
	booktitle = {2019 {IEEE}/{ACM} 16th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Pimentel, João Felipe and Murta, Leonardo and Braganholo, Vanessa and Freire, Juliana},
	month = may,
	year = {2019},
	note = {ISSN: 2574-3864},
	keywords = {reproducibility, github, Python, Best practices, jupyter notebook, Media, Programming, Testing, Tools},
	pages = {507--517},
	file = {IEEE Xplore Abstract Record:/Users/kriarm/Zotero/storage/DJHIFSW5/8816763.html:text/html},
}

@misc{community_turing_2025,
	title = {The {Turing} {Way}: {A} handbook for reproducible, ethical and collaborative research},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/records/15213042},
	abstract = {The Turing Way: A handbook for reproducible, ethical and collaborative research

The Turing Way April 2024 Latest

The Turing Way is an open source community-driven guide to reproducible, ethical, inclusive and collaborative data science. The Turing Way book is collaboratively developed by its diverse community of researchers, learners, educators, and other stakeholders.

The Turing Way project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. In 2020, the project underwent a major overhaul categorising chapters into 5 guides on reproducible research, project design, collaboration, communication and ethical research. Additionally, we added a community handbook to document all the practices designed and implemented towards the development of the project and community.

This release in 2021 includes additional chapters developed by our contributors across five guides and the community handbook. In addition, all the project documents from the project are provided as they appear on The Turing Way GitHub repository including the Zenodo metadata: https://github.com/alan-turing-institute/the-turing-way.

Release log

v1.2: Zenodo release from 2023-2024v1.1.0: Zenodo metadata information and additional chapters from Book Dash May and November 2022;v1.0.2: Zenodo metadata information and additional chapters since Book Dash November 2021;v1.0.1: Zenodo metadata information and additional chapters;v1.0.0: Five guide expansion of The Turing Way with a community handbook;v0.0.4: Continuous integration chapter merged to main;v0.0.3: Reproducible environments chapter merged to main;v0.0.2: Version control chapter merged to main;v0.0.1: Reproducibility chapter merged to main;

Full Changelog: https://github.com/alan-turing-institute/the-turing-way/compare/v1.0.1...v1.0.2 (Previous release: https://github.com/alan-turing-institute/the-turing-way/compare/v0.0.3...v1.0.1)

v1.2.0

\#\# What's Changed* Challenges with \& Pillars of OSS Sustainability* Update the unions page with more recommendations* Useful Resources subchapter for remote collab* edit instructions on Google Scholar citations* Add checklist and responsibility document for Fireside chat * Local-build-instructions in a subchapter* Move welcome to index.md* edit alt-text to be more informative* Fixing the landing page deployment and updating redirects* Update the website footer to remove copyright assertion, and replace it with a link to the project licenses * Fixed dead link to eScience Center language guides* Add Mastodon badge in News README.md* Updated files for new release and update release-workflow.md to add a missing step* add fireside speakers for eventOrganizing* adds Plausible Analytics* MAINT: remove mentions of travis* Create team-manual.md* Adding new set of images and compressing file larger than 700 kb* Add template for the translation* Update newsletters-process with Zenodo link and missing sections* Add mentions of the The Software Freedom Law Center \& Software Freedom Conservancy to the section in Machine Learning Model Licenses on license enforcement.* Add Book Dash reports from 2021 and 2022* Repositories chapter* Adding instructions for making your software on gitlab citable  with Zenodo* Update pd-overview-planning.md* Update citable-steps.md (including hardware* Creating Academic-Industry Collaboration chapter and subchapters* Facilitating Stakeholder Engagement* Chapter on Hybrid Collaboration* Leadership chapter with 3 new subchapters and landing page* Data Governance for the ML Pipeline* Update ram.md (research application management)* Restructure link checking* rewrite version control for datasets * Add a tag in presenting about The Turing Way chapter * Update glossary.md -open hardware * Add Landing Page for Infrastructure Documentation * Update translation-getting-started.md * Update reg registered reports chapter with case study* Registration forms sub-chapter* creating governance folder + adding coworking \& core team notes * Remove sensitive links* Create Newsletter\_41\_Mar2023.md* Create Newsletter\_42\_Apr2023.md* Create Newsletter\_43\_May2023.md* Add link to Chinese readme* Update Localisation Guidelines* workflows: add accessibility alt-text bot.* Add a chapter about error management* Update coc documents to make the committee information up to date* Create licenses-hardware.md* Upload illustrations from the May Book Dash* Update citation information* Add GSoC files and include reports* The Environmental Impact of Digital Research* Update 2023-GSoC-Final-Report-arya* 2023 Digital Infrastructure Insights Fund RFP* Create newsletter\_40\_Feb2023.md* Create newsletter\_44\_Jun2023.md* Rename Newsletter\_41\_Mar2023.md* Rename Newsletter\_42\_April2023.md* Adding Slack policy to community handbook* Adding Open peer review image* Adding research infrastructure roles image* Adding valuing people-process image* Updating "Data Stewards" page with figure* Adding illustrations to academic-industry chapters* Updating references to Programming Historian* adding ethics-committee-with-text image* Added FAIR Wizard to DMP tools * Use executable notebooks image in open notebooks section* Add image to cultural change* Add new resources to Open Education* Adding figure and alt-text to "The Environmental Impact of Digital Research" page* Create Newsletter\_40\_Feb2023.md * Update the Research Data Management chapter* Data Feminism Landing Page* [Ready for review] Update Twitter references to use X* Add contents: write permission for crowdin workflow* Separate collaborators from contributors' files in the community handbook* Installing Python Package developed to provide user pathways to access a curated set of chapters* Update contributors to pathways work* adding new alt text for collaboration iceberg image * Ethics-informed licensing - an extension of and partial re-write of the licencing section in reproducible research* Update citable-cite.md * Update research data management data curation* Data hazards chapter release* Electronic Lab Notebooks Chapter * Introducing Blobless Clones to Address Slow Internet Connections* Add reports and templates from Book Dash 2021 * Update social media chapter * Update Crowdin Contributors table * Adding access considerations and support to community handbook for events and moving alt text* Update communication-channels.md to add channel information* Update README.md - remove gitter link * Domain migration banner * Add sketch for DNS page * Update slack-welcome-guide.md * Reduce animation filesize* Add previous project reports* Create coworking and pm-core-20240321.md meeting notes* Share script for book stats for reporting* Create Newsletter\_39\_Jan2023.md* Updating 2022 Annual Report Archive* Upload Book Dash WG meeting notes from September 2023* Changing buttondown links to tinyletter* Add illustrations from November* WIP Inclusive Events* Update Organizing Conference file * Adding Chapter on Hosting Events with Public Contributors* Update ways\_of\_working.md with role shifts* Collab Cafe page maintenance* Adding book-dash-collaboration* Update coworking-collabcafe.md * Update netlify urls* Add a resource to Open Education* Add a resource to team manuals* licence vs license 

\#\# New Contributors

\#\# New Contributors* @AlexandraAAJ made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/2964* @gedankenstuecke made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/2968* @LizHareDogs made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/2971* @chrisdburr made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3010* @tpronk made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/2995* @RealRichi3 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/2961* @shreyadimri made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3028* @RichardJActon made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3049* @emmac123 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3069* @GabinWK made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3079* @luisaforozco made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3112* @spier made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3175* @srtee made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3199* @alexwlchan made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/883* @mosoriob made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3278* @AaliyaK1391 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3284* @arya1302 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3296* @alee made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3300* @tobyhodges made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3274* @hanneoberman made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3336* @kallewesterling made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3374* @llewelld made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3347* @CeilidhWelsh made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3377* @krystofkomanec made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3244* @f-rower made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3414* @gigikenneth made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3417* @zimolzak made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3468* @Cghlewis made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3476* @nikitoshina made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3477* @richarddushime made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3519* @Adityagarg8384 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3529* @Susana465 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3539* @IshanG97 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3646* @likeajumprope made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3659* @unshur made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3665* @SaraVilla made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3666* @NoorhanAbbas made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3668* @denisebianco made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3670* @nghuixin made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3667* @CDonesCU made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3671* @Zeena-Shawa made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3672* @njbaum83 made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3673* @nickyjgarland made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3674* @pre-commit-ci made their first contribution in https://github.com/the-turing-way/the-turing-way/pull/3695

**Full Changelog**: https://github.com/the-turing-way/the-turing-way/compare/v1.2.1...v1.2.2},
	urldate = {2025-04-14},
	publisher = {Zenodo},
	author = {Community, The Turing Way},
	month = apr,
	year = {2025},
	doi = {10.5281/zenodo.15213042},
	keywords = {reproducibility, ethics, data science, research practices, collaboration, community, handbook},
	file = {Snapshot:/Users/kriarm/Zotero/storage/YPMZ3E5X/15213042.html:text/html},
}

@article{narayanan_why_2025,
	title = {Why an overreliance on {AI}-driven modelling is bad for science},
	volume = {640},
	copyright = {2025 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/d41586-025-01067-2},
	doi = {10.1038/d41586-025-01067-2},
	abstract = {Without clear protocols to catch errors, artificial intelligence’s growing role in science could do more harm than good.},
	language = {en},
	number = {8058},
	urldate = {2025-04-16},
	journal = {Nature},
	author = {Narayanan, Arvind and Kapoor, Sayash},
	month = apr,
	year = {2025},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Publisher: Nature Publishing Group
Subject\_term: Computer science, Machine learning, Mathematics and computing, Scientific community},
	keywords = {reproducibility, AI, LLM},
	pages = {312--314},
}

@misc{nelson_ensuring_2022,
	title = {Ensuring free, immediate, and equitable access to federally funded research},
	url = {https://bidenwhitehouse.archives.gov/wp-content/uploads/2022/08/08-2022-OSTP-Public-Access-Memo.pdf},
	language = {English (US)},
	publisher = {Office of Science and Technology Policy, Executive Office of the President of United States},
	author = {Nelson, Alondra},
	month = aug,
	year = {2022},
}

@book{washizaki_guide_2024,
	edition = {4.0},
	title = {Guide to the {Software} engineering body of knowledge ({SWEBOK} {Guide})},
	url = {https://www.computer.org/education/bodies-of-knowledge/software-engineering/},
	abstract = {A guide to the Software Engineering Body of Knowledge that provides a foundation for training materials and curriculum development.},
	language = {en-US},
	urldate = {2025-05-15},
	publisher = {IEEE Computer Society},
	author = {Washizaki, Hironori},
	year = {2024},
	file = {Snapshot:/Users/kriarm/Zotero/storage/S8896B8F/software-engineering.html:text/html},
}

@misc{poldrack_better_2025,
	type = {Substack newsletter},
	title = {Better code, better science},
	url = {https://russpoldrack.substack.com/p/better-code-better-science},
	abstract = {Introducing a new open-source book project on scientific coding using AI tools},
	urldate = {2025-05-15},
	journal = {Neural Strategies},
	author = {Poldrack, Russ},
	month = may,
	year = {2025},
	file = {Snapshot:/Users/kriarm/Zotero/storage/WGR758I3/better-code-better-science.html:text/html},
}

@article{binder_where_2009,
	title = {Where {Is} the semantic system? {A} critical review and meta-analysis of 120 functional neuroimaging studies},
	volume = {19},
	issn = {1460-2199, 1047-3211},
	shorttitle = {Where {Is} the {Semantic} {System}?},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhp055},
	doi = {10.1093/cercor/bhp055},
	language = {en},
	number = {12},
	urldate = {2025-05-19},
	journal = {Cerebral Cortex},
	author = {Binder, Jeffrey R. and Desai, Rutvik H. and Graves, William W. and Conant, Lisa L.},
	month = dec,
	year = {2009},
	pages = {2767--2796},
}

@article{hardwicke_analytic_2021,
	title = {Analytic reproducibility in articles receiving open data badges at the journal \textit{{Psychological} {Science}} : an observational study},
	volume = {8},
	issn = {2054-5703},
	shorttitle = {Analytic reproducibility in articles receiving open data badges at the journal \textit{{Psychological} {Science}}},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.201494},
	doi = {10.1098/rsos.201494},
	abstract = {For any scientific report, repeating the original analyses upon the original data should yield the original outcomes. We evaluated analytic reproducibility in 25
              Psychological Science
              articles awarded open data badges between 2014 and 2015. Initially, 16 (64\%, 95\% confidence interval [43,81]) articles contained at least one ‘major numerical discrepancy' ({\textgreater}10\% difference) prompting us to request input from original authors. Ultimately, target values were reproducible without author involvement for 9 (36\% [20,59]) articles; reproducible with author involvement for 6 (24\% [8,47]) articles; not fully reproducible with no substantive author response for 3 (12\% [0,35]) articles; and not fully reproducible despite author involvement for 7 (28\% [12,51]) articles. Overall, 37 major numerical discrepancies remained out of 789 checked values (5\% [3,6]), but original conclusions did not appear affected. Non-reproducibility was primarily caused by unclear reporting of analytic procedures. These results highlight that open data alone is not sufficient to ensure analytic reproducibility.},
	language = {en},
	number = {1},
	urldate = {2025-05-19},
	journal = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Bohn, Manuel and MacDonald, Kyle and Hembacher, Emily and Nuijten, Michèle B. and Peloquin, Benjamin N. and deMayo, Benjamin E. and Long, Bria and Yoon, Erica J. and Frank, Michael C.},
	month = jan,
	year = {2021},
	pages = {201494},
}

@article{stodden_toward_2013,
	title = {Toward {Reproducible} {Computational} {Research}: {An} {Empirical} {Analysis} of {Data} and {Code} {Policy} {Adoption} by {Journals}},
	volume = {8},
	issn = {1932-6203},
	shorttitle = {Toward {Reproducible} {Computational} {Research}},
	url = {https://dx.plos.org/10.1371/journal.pone.0067111},
	doi = {10.1371/journal.pone.0067111},
	language = {en},
	number = {6},
	urldate = {2025-05-19},
	journal = {PLoS ONE},
	author = {Stodden, Victoria and Guo, Peixuan and Ma, Zhaokun},
	editor = {Zaykin, Dmitri},
	month = jun,
	year = {2013},
	pages = {e67111},
}

@article{mckiernan_policy_2023,
	title = {Policy recommendations to ensure that research software is openly accessible and reusable},
	volume = {21},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.3002204},
	doi = {10.1371/journal.pbio.3002204},
	language = {en},
	number = {7},
	urldate = {2025-05-19},
	journal = {PLOS Biology},
	author = {McKiernan, Erin C. and Barba, Lorena and Bourne, Philip E. and Carter, Caitlin and Chandler, Zach and Choudhury, Sayeed and Jacobs, Stephen and Katz, Daniel S. and Lieggi, Stefanie and Plale, Beth and Tananbaum, Greg},
	month = jul,
	year = {2023},
	pages = {e3002204},
}

@techreport{hernandez_serrano_identifying_2025,
	title = {Identifying gaps in research software policy: {A} report from {Subgroup} 3/4 of the {ReSA} \& {RDA} {Policies} in {Research} {Organisations} for {Research} {Software} ({PRO4RS}) {Working} {Group}},
	shorttitle = {Identifying {Gaps} in {Research} {Software} {Policy}},
	url = {https://zenodo.org/records/15411757},
	abstract = {This report presents one of the outputs of the Policies in Research Organisations for Research Software (PRO4RS) Working Group, jointly led by the Research Software Alliance (ReSA) and the Research Data Alliance (RDA). It documents the work of Subgroup 3\&4, which focused on defining a common framework for research software policy and identifying critical gaps in current institutional approaches.

As software has become an increasingly important element of research across domains, research-performing organisations are increasingly called upon to develop and align policies that support its recognition, sustainability, and the professionals who develop it. This report analyses 38 institutional policy documents collected by the working group, classifying them based on their direct or indirect treatment of research software and coding them against 15 policy categories identified through community consultation.

The findings show that while many institutions include research software in policies on infrastructure, licensing, or open science, few address areas concerning research assessment reform. The report concludes with a recommendation to further revisit the idea of a fixed common framework and suggest to work on a multilayered approach for policy development. This work is to be advanced through the RDA TIGER cascading project 2025.},
	language = {eng},
	urldate = {2025-05-19},
	institution = {Zenodo},
	author = {Hernández Serrano, Pedro V. and Barker, Michelle and Katz, Daniel S. and Martinez-Ortiz, Carlos and Shanahan, Hugh},
	month = may,
	year = {2025},
	doi = {10.5281/zenodo.15411757},
	keywords = {Policy Analysis, Research Assessment, Research Software Policy, Software Sustainability},
}

@article{gleeson_commitment_2017,
	title = {A commitment to open source in neuroscience},
	volume = {96},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30981-9},
	doi = {10.1016/j.neuron.2017.10.013},
	language = {English},
	number = {5},
	urldate = {2025-05-19},
	journal = {Neuron},
	author = {Gleeson, Padraig and Davison, Andrew P. and Silver, R. Angus and Ascoli, Giorgio A.},
	month = dec,
	year = {2017},
	pmid = {29216458},
	note = {Publisher: Elsevier},
	pages = {964--965},
}

@article{gilmore_progress_2017,
	title = {Progress toward openness, transparency, and reproducibility in cognitive neuroscience},
	volume = {1396},
	issn = {0077-8923},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5545750/},
	doi = {10.1111/nyas.13325},
	abstract = {Accumulating evidence suggests that many findings in psychological science and cognitive neuroscience may prove difficult to reproduce; statistical power in brain imaging studies is low, and has not improved recently; software errors in common analysis tools are common, and can go undetected for many years; and, a few large scale studies notwithstanding, open sharing of data, code, and materials remains the rare exception. At the same time, there is a renewed focus on reproducibility, transparency, and openness as essential core values in cognitive neuroscience. The emergence and rapid growth of data archives, meta-analytic tools, software pipelines, and research groups devoted to improved methodology reflects this new sensibility. We review evidence that the field has begun to embrace new open research practices, and illustrate how these can begin to address problems of reproducibility, statistical power, and transparency in ways that will ultimately accelerate discovery.},
	number = {1},
	urldate = {2025-05-19},
	journal = {Annals of the New York Academy of Sciences},
	author = {Gilmore, Rick O. and Diaz, Michele T. and Wyble, Brad A. and Yarkoni, Tal},
	month = may,
	year = {2017},
	pmid = {28464561},
	pmcid = {PMC5545750},
	pages = {5--18},
}

@article{hardwicke_data_2018,
	title = {Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal \textit{{Cognition}}},
	volume = {5},
	issn = {2054-5703},
	shorttitle = {Data availability, reusability, and analytic reproducibility},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.180448},
	doi = {10.1098/rsos.180448},
	abstract = {Access to data is a critical feature of an efficient, progressive and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data (‘analytic reproducibility’). To investigate this, we conducted an observational evaluation of a mandatory open data policy introduced at the journal
              Cognition
              . Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), although not all data appeared reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). For 35 of the articles determined to have reusable data, we attempted to reproduce 1324 target values. Ultimately, 64 values could not be reproduced within a 10\% margin of error. For 22 articles all target values were reproduced, but 11 of these required author assistance. For 13 articles at least one value could not be reproduced despite author assistance. Importantly, there were no clear indications that original conclusions were seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
	language = {en},
	number = {8},
	urldate = {2025-05-19},
	journal = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Mathur, Maya B. and MacDonald, Kyle and Nilsonne, Gustav and Banks, George C. and Kidwell, Mallory C. and Hofelich Mohr, Alicia and Clayton, Elizabeth and Yoon, Erica J. and Henry Tessler, Michael and Lenne, Richie L. and Altman, Sara and Long, Bria and Frank, Michael C.},
	month = aug,
	year = {2018},
	pages = {180448},
}

@article{nosek_replicability_2022,
	title = {Replicability, robustness, and reproducibility in psychological science},
	volume = {73},
	issn = {0066-4308, 1545-2085},
	url = {https://www.annualreviews.org/content/journals/10.1146/annurev-psych-020821-114157},
	doi = {10.1146/annurev-psych-020821-114157},
	abstract = {Replication—an important, uncommon, and misunderstood practice—is gaining appreciation in psychology. Achieving replicability is important for making research progress. If findings are not replicable, then prediction and theory development are stifled. If findings are replicable, then interrogation of their meaning and validity can advance knowledge. Assessing replicability can be productive for generating and testing hypotheses by actively confronting current understandings to identify weaknesses and spur innovation. For psychology, the 2010s might be characterized as a decade of active confrontation. Systematic and multi-site replication projects assessed current understandings and observed surprising failures to replicate many published findings. Replication efforts highlighted sociocultural challenges such as disincentives to conduct replications and a tendency to frame replication as a personal attack rather than a healthy scientific practice, and they raised awareness that replication contributes to self-correction. Nevertheless, innovation in doing and understanding replication and its cousins, reproducibility and robustness, has positioned psychology to improve research practices and accelerate progress.},
	language = {en},
	number = {Volume 73, 2022},
	urldate = {2025-05-20},
	journal = {Annual Review of Psychology},
	author = {Nosek, Brian A. and Hardwicke, Tom E. and Moshontz, Hannah and Allard, Aurélien and Corker, Katherine S. and Dreber, Anna and Fidler, Fiona and Hilgard, Joe and Struhl, Melissa Kline and Nuijten, Michèle B. and Rohrer, Julia M. and Romero, Felipe and Scheel, Anne M. and Scherer, Laura D. and Schönbrodt, Felix D. and Vazire, Simine},
	month = jan,
	year = {2022},
	note = {Publisher: Annual Reviews},
	pages = {719--748},
}

@article{errington_challenges_2021,
	title = {Challenges for assessing replicability in preclinical cancer biology},
	volume = {10},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.67995},
	doi = {10.7554/eLife.67995},
	abstract = {We conducted the Reproducibility Project: Cancer Biology to investigate the replicability of preclinical research in cancer biology. The initial aim of the project was to repeat 193 experiments from 53 high-impact papers, using an approach in which the experimental protocols and plans for data analysis had to be peer reviewed and accepted for publication before experimental work could begin. However, the various barriers and challenges we encountered while designing and conducting the experiments meant that we were only able to repeat 50 experiments from 23 papers. Here we report these barriers and challenges. First, many original papers failed to report key descriptive and inferential statistics: the data needed to compute effect sizes and conduct power analyses was publicly accessible for just 4 of 193 experiments. Moreover, despite contacting the authors of the original papers, we were unable to obtain these data for 68\% of the experiments. Second, none of the 193 experiments were described in sufficient detail in the original paper to enable us to design protocols to repeat the experiments, so we had to seek clarifications from the original authors. While authors were extremely or very helpful for 41\% of experiments, they were minimally helpful for 9\% of experiments, and not at all helpful (or did not respond to us) for 32\% of experiments. Third, once experimental work started, 67\% of the peer-reviewed protocols required modifications to complete the research and just 41\% of those modifications could be implemented. Cumulatively, these three factors limited the number of experiments that could be repeated. This experience draws attention to a basic and fundamental concern about replication – it is hard to assess whether reported findings are credible.},
	urldate = {2025-05-20},
	journal = {eLife},
	author = {Errington, Timothy M and Denis, Alexandria and Perfito, Nicole and Iorns, Elizabeth and Nosek, Brian A},
	editor = {Rodgers, Peter and Franco, Eduardo},
	month = dec,
	year = {2021},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {open science, reproducibility, preregistration, open data, replication, Reproducibility Project: Cancer Biology},
	pages = {e67995},
}
